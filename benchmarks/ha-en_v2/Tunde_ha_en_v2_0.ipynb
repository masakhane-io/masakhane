{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tunde_ha_en_v2.0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tunde99/masakhane-mt/blob/master/Tunde_ha_en_v2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igc5itf-xMGj"
      },
      "source": [
        "# Masakhane - Reverse Machine Translation for African Languages (Using JoeyNMT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBcyf_DQzCT1"
      },
      "source": [
        "> ## NB\n",
        ">### - The purpose of this Notebook is to build models that translate African languages(target language) *into* English(source language). This will allow us to in future be able to make translations from one African language to the other. If you'd like to translate *from* English, please use [this](https://github.com/masakhane-io/masakhane-mt/blob/master/starter_notebook.ipynb) starter notebook instead.\n",
        "\n",
        ">### - We call this reverse training because normally we build models that make translations from the source language(English) to the target language. But in this case we are doing the reverse; building models that make translations from the target language to the source(English)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4fXCKCf36IK"
      },
      "source": [
        "## Note before beginning:\n",
        "### - The idea is that you should be able to make minimal changes to this in order to get SOME result for your own translation corpus. \n",
        "\n",
        "### - The tl;dr: Go to the **\"TODO\"** comments which will tell you what to update to get up and running\n",
        "\n",
        "### - If you actually want to have a clue what you're doing, read the text and peek at the links\n",
        "\n",
        "### - With 100 epochs, it should take around 7 hours to run in Google Colab\n",
        "\n",
        "### - Once you've gotten a result for your language, please attach and email your notebook that generated it to masakhanetranslation@gmail.com\n",
        "\n",
        "### - If you care enough and get a chance, doing a brief background on your language would be amazing. See examples in  [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l929HimrxS0a"
      },
      "source": [
        "## Retrieve your data & make a parallel corpus\n",
        "\n",
        "If you are wanting to use the JW300 data referenced on the Masakhane website or in our GitHub repo, you can use `opus-tools` to convert the data into a convenient format. `opus_read` from that package provides a convenient tool for reading the native aligned XML files and to convert them to TMX format. The tool can also be used to fetch relevant files from OPUS on the fly and to filter the data as necessary. [Read the documentation](https://pypi.org/project/opustools-pkg/) for more details.\n",
        "\n",
        "Once you have your corpus files in TMX format (an xml structure which will include the sentences in your target language and your source language in a single file), we recommend reading them into a pandas dataframe. Thankfully, Jade wrote a silly `tmx2dataframe` package which converts your tmx file to a pandas dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGRmDELn7Az0",
        "outputId": "244c3a32-8ed3-4639-ac24-4807b7d11314"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3tgQLzUxwn"
      },
      "source": [
        "# TODO: Set your source and target languages. Keep in mind, these traditionally use language codes as found here:\n",
        "# These will also become the suffix's of all vocab and corpus files used throughout\n",
        "import os\n",
        "source_language = \"en\"\n",
        "target_language = \"ha\" \n",
        "lc = False  # If True, lowercase the data.\n",
        "seed = 42  # Random seed for shuffling.\n",
        "tag = \"baseline_v2.0\" # Give a unique name to your folder - this is to ensure you don't rewrite any models you've already submitted\n",
        "\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
        "os.environ[\"tgt\"] = target_language\n",
        "os.environ[\"tag\"] = tag\n",
        "\n",
        "# This will save it to a folder in our gdrive instead!\n",
        "!mkdir -p \"/content/drive/My Drive/masakhane/$tgt-$src-$tag\"\n",
        "os.environ[\"gdrive_path\"] = \"/content/drive/My Drive/masakhane/%s-%s-%s\" % (target_language, source_language, tag)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBSgJHEw7Nvx",
        "outputId": "21a2fa00-eef2-4b5b-b674-3f5d5ec9a11f"
      },
      "source": [
        "!echo $gdrive_path"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masakhane/ha-en-baseline_v2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA75Fs9ys8Y9",
        "outputId": "d6375c04-787f-4a09-ab43-4bf1a403deb2"
      },
      "source": [
        "# Install opus-tools\n",
        "! pip install opustools-pkg"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opustools-pkg\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/9f/e829a0cceccc603450cd18e1ff80807b6237a88d9a8df2c0bb320796e900/opustools_pkg-0.0.52-py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 10.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 61kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 71kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: opustools-pkg\n",
            "Successfully installed opustools-pkg-0.0.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq-tDZVks7ZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a715e878-0a0a-4ccd-d11a-950e157c2fd5"
      },
      "source": [
        "# Downloading our corpus\n",
        "! opus_read -d JW300 -s $src -t $tgt -wm moses -w jw300.$src jw300.$tgt -q\n",
        "\n",
        "# extract the corpus file\n",
        "! gunzip JW300_latest_xml_$src-$tgt.xml.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Alignment file /proj/nlpl/data/OPUS/JW300/latest/xml/en-ha.xml.gz not found. The following files are available for downloading:\n",
            "\n",
            "   3 MB https://object.pouta.csc.fi/OPUS-JW300/v1b/xml/en-ha.xml.gz\n",
            " 263 MB https://object.pouta.csc.fi/OPUS-JW300/v1b/xml/en.zip\n",
            "  24 MB https://object.pouta.csc.fi/OPUS-JW300/v1b/xml/ha.zip\n",
            "\n",
            " 289 MB Total size\n",
            "./JW300_latest_xml_en-ha.xml.gz ... 100% of 3 MB\n",
            "./JW300_latest_xml_en.zip ... 100% of 263 MB\n",
            "./JW300_latest_xml_ha.zip ... 100% of 24 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n48GDRnP8y2G",
        "outputId": "bc8b903d-f9b9-494f-9e95-87fb16151c96"
      },
      "source": [
        "# Download the global test set.\n",
        "! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-any.en\n",
        "  \n",
        "# And the specific test set for this language pair.\n",
        "os.environ[\"trg\"] = target_language \n",
        "os.environ[\"src\"] = source_language \n",
        "\n",
        "# Uncomment the following lines of code if your language pair is part of the global test set\n",
        "# else, create the test set and upload them to this notebook.\n",
        "\n",
        "# ! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-$trg.en \n",
        "# ! mv test.en-$trg.en test.en\n",
        "# ! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-$trg.$trg \n",
        "# ! mv test.en-$trg.$trg test.$trg"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-05 14:16:04--  https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-any.en\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 277791 (271K) [text/plain]\n",
            "Saving to: ‘test.en-any.en’\n",
            "\n",
            "test.en-any.en      100%[===================>] 271.28K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-05 14:16:04 (4.67 MB/s) - ‘test.en-any.en’ saved [277791/277791]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "KVH_dCBY2zhT",
        "outputId": "20e75a1f-8102-40df-e334-595a82c65dd2"
      },
      "source": [
        "# Loading created test sets\n",
        "from google.colab import files\n",
        "upload_files = files.upload()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b85a8eec-6fa3-41f6-973e-ca592c104aa3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b85a8eec-6fa3-41f6-973e-ca592c104aa3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.en to test.en\n",
            "Saving test.ha to test.ha\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqDG-CI28y2L",
        "outputId": "c178b43f-8f2a-40e2-c921-12b1bf47ff6c"
      },
      "source": [
        "# Read the test data to filter from train and dev splits.\n",
        "# Store english portion in set for quick filtering checks.\n",
        "en_test_sents = set()\n",
        "filter_test_sents = \"test.en-any.en\"\n",
        "j = 0\n",
        "with open(filter_test_sents) as f:\n",
        "  for line in f:\n",
        "    en_test_sents.add(line.strip())\n",
        "    j += 1\n",
        "print('Loaded {} global test sentences to filter from the training/dev data.'.format(j))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 3571 global test sentences to filter from the training/dev data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "3CNdwLBCfSIl",
        "outputId": "c8853ba1-66e7-47de-bd0a-d3cc1dbf3ce1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TMX file to dataframe\n",
        "source_file = 'jw300.' + source_language\n",
        "target_file = 'jw300.' + target_language\n",
        "\n",
        "source = []\n",
        "target = []\n",
        "skip_lines = []  # Collect the line numbers of the source portion to skip the same lines for the target portion.\n",
        "with open(source_file) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        # Skip sentences that are contained in the test set.\n",
        "        if line.strip() not in en_test_sents:\n",
        "            source.append(line.strip())\n",
        "        else:\n",
        "            skip_lines.append(i)             \n",
        "with open(target_file) as f:\n",
        "    for j, line in enumerate(f):\n",
        "        # Only add to corpus if corresponding source was not skipped.\n",
        "        if j not in skip_lines:\n",
        "            target.append(line.strip())\n",
        "    \n",
        "print('Loaded data and skipped {}/{} lines since contained in test set.'.format(len(skip_lines), i))\n",
        "    \n",
        "df = pd.DataFrame(zip(source, target), columns=['source_sentence', 'target_sentence'])\n",
        "# if you get TypeError: data argument can't be an iterator is because of your zip version run this below\n",
        "#df = pd.DataFrame(list(zip(source, target)), columns=['source_sentence', 'target_sentence'])\n",
        "df.head(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded data and skipped 5417/237064 lines since contained in test set.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Questions From Readers</td>\n",
              "      <td>Tambayoyi Daga Masu Karatu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How seriously should Christians view an engage...</td>\n",
              "      <td>Yaya ya kamata Kiristoci su ɗauki riƙo ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>An engagement to marry is a cause for happines...</td>\n",
              "      <td>Riƙo dalili ne na farinciki , amma kuma muhimm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No mature Christian should take an engagement ...</td>\n",
              "      <td>Kada wani riƙaƙƙen Kirista ya yi wasa da riƙo ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The period of engagement is also a time for th...</td>\n",
              "      <td>Lokacin riƙo lokaci ne da mutane biyun za su s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>In discussing this topic , we need to realize ...</td>\n",
              "      <td>Cikin tattauna wannan zance , ya kamata mu gan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The Bible illustrates this .</td>\n",
              "      <td>Littafi Mai - Tsarki ya bada misalin wannan .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Lot’s two daughters , who had “ never had inte...</td>\n",
              "      <td>’ Ya’ya mata biyu na Lutu , waɗanda “ ba su sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Lot’s ‘ sons - in - law were to take his daugh...</td>\n",
              "      <td>‘ Surukan Lutu za su aure ’ ya’yansa mata , ’ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Were the daughters adults ?</td>\n",
              "      <td>’ Ya’yansa mata sun yi girma kuwa ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     source_sentence                                    target_sentence\n",
              "0                             Questions From Readers                         Tambayoyi Daga Masu Karatu\n",
              "1  How seriously should Christians view an engage...           Yaya ya kamata Kiristoci su ɗauki riƙo ?\n",
              "2  An engagement to marry is a cause for happines...  Riƙo dalili ne na farinciki , amma kuma muhimm...\n",
              "3  No mature Christian should take an engagement ...  Kada wani riƙaƙƙen Kirista ya yi wasa da riƙo ...\n",
              "4  The period of engagement is also a time for th...  Lokacin riƙo lokaci ne da mutane biyun za su s...\n",
              "5  In discussing this topic , we need to realize ...  Cikin tattauna wannan zance , ya kamata mu gan...\n",
              "6                       The Bible illustrates this .      Littafi Mai - Tsarki ya bada misalin wannan .\n",
              "7  Lot’s two daughters , who had “ never had inte...  ’ Ya’ya mata biyu na Lutu , waɗanda “ ba su sa...\n",
              "8  Lot’s ‘ sons - in - law were to take his daugh...  ‘ Surukan Lutu za su aure ’ ya’yansa mata , ’ ...\n",
              "9                        Were the daughters adults ?                ’ Ya’yansa mata sun yi girma kuwa ?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkuK3B4p2AkN"
      },
      "source": [
        "## Pre-processing and export\n",
        "\n",
        "It is generally a good idea to remove duplicate translations and conflicting translations from the corpus. In practice, these public corpora include some number of these that need to be cleaned.\n",
        "\n",
        "In addition we will split our data into dev/test/train and export to the filesystem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_2ouEOH1_1q",
        "outputId": "59921891-2bd8-405c-ed57-2e34994cc8a3"
      },
      "source": [
        "# drop duplicate translations\n",
        "df_pp = df.drop_duplicates()\n",
        "\n",
        "# drop conflicting translations\n",
        "# (this is optional and something that you might want to comment out \n",
        "# depending on the size of your corpus)\n",
        "df_pp.drop_duplicates(subset='source_sentence', inplace=True)\n",
        "df_pp.drop_duplicates(subset='target_sentence', inplace=True)\n",
        "\n",
        "# Shuffle the data to remove bias in dev set selection.\n",
        "df_pp = df_pp.sample(frac=1, random_state=seed).reset_index(drop=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_1BwAApEtMk",
        "outputId": "6bb22797-89ec-4487-d89b-f3ed997ed451"
      },
      "source": [
        "# Install fuzzy wuzzy to remove \"almost duplicate\" sentences in the\n",
        "# test and training sets.\n",
        "! pip install fuzzywuzzy\n",
        "! pip install python-Levenshtein\n",
        "import time\n",
        "from fuzzywuzzy import process\n",
        "import numpy as np\n",
        "from os import cpu_count\n",
        "from functools import partial\n",
        "from multiprocessing import Pool\n",
        "\n",
        "\n",
        "# reset the index of the training set after previous filtering\n",
        "df_pp.reset_index(drop=False, inplace=True)\n",
        "\n",
        "# Remove samples from the training data set if they \"almost overlap\" with the\n",
        "# samples in the test set.\n",
        "\n",
        "# Filtering function. Adjust pad to narrow down the candidate matches to\n",
        "# within a certain length of characters of the given sample.\n",
        "def fuzzfilter(sample, candidates, pad):\n",
        "  candidates = [x for x in candidates if len(x) <= len(sample)+pad and len(x) >= len(sample)-pad] \n",
        "  if len(candidates) > 0:\n",
        "    return process.extractOne(sample, candidates)[1]\n",
        "  else:\n",
        "    return np.nan"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n",
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (56.0.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149822 sha256=f570be3680135c7aae39caaa64778e8bf2541bc0a68056edf2b4561c6d49e308\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/26/73/4b48503bac73f01cf18e52cd250947049a7f339e940c5df8fc\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92EsgTaY3B4H"
      },
      "source": [
        "# start_time = time.time()\n",
        "# ### iterating over pandas dataframe rows is not recomended, let use multi processing to apply the function\n",
        "\n",
        "# with Pool(cpu_count()-1) as pool:\n",
        "#     scores = pool.map(partial(fuzzfilter, candidates=list(en_test_sents), pad=5), df_pp['source_sentence'])\n",
        "# hours, rem = divmod(time.time() - start_time, 3600)\n",
        "# minutes, seconds = divmod(rem, 60)\n",
        "# print(\"done in {}h:{}min:{}seconds\".format(hours, minutes, seconds))\n",
        "\n",
        "# # Filter out \"almost overlapping samples\"\n",
        "# df_pp = df_pp.assign(scores=scores)\n",
        "# df_pp = df_pp[df_pp['scores'] < 95]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxxBOCA-xXhy",
        "outputId": "aacb5fa8-79bc-4ad2-d906-abff7d092b05"
      },
      "source": [
        "# This section does the split between train/dev for the parallel corpora then saves them as separate files\n",
        "# We use 1000 dev test and the given test set.\n",
        "import csv\n",
        "\n",
        "# Do the split between dev/train and create parallel corpora\n",
        "num_dev_patterns = 1000\n",
        "\n",
        "# Optional: lower case the corpora - this will make it easier to generalize, but without proper casing.\n",
        "if lc:  # Julia: making lowercasing optional\n",
        "    df_pp[\"source_sentence\"] = df_pp[\"source_sentence\"].str.lower()\n",
        "    df_pp[\"target_sentence\"] = df_pp[\"target_sentence\"].str.lower()\n",
        "\n",
        "# Julia: test sets are already generated\n",
        "dev = df_pp.tail(num_dev_patterns) # Herman: Error in original\n",
        "stripped = df_pp.drop(df_pp.tail(num_dev_patterns).index)\n",
        "\n",
        "with open(\"train.\"+source_language, \"w\") as src_file, open(\"train.\"+target_language, \"w\") as trg_file:\n",
        "  for index, row in stripped.iterrows():\n",
        "    src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
        "    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
        "    \n",
        "with open(\"dev.\"+source_language, \"w\") as src_file, open(\"dev.\"+target_language, \"w\") as trg_file:\n",
        "  for index, row in dev.iterrows():\n",
        "    src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
        "    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
        "\n",
        "#stripped[[\"source_sentence\"]].to_csv(\"train.\"+source_language, header=False, index=False)  # Herman: Added `header=False` everywhere\n",
        "#stripped[[\"target_sentence\"]].to_csv(\"train.\"+target_language, header=False, index=False)  # Julia: Problematic handling of quotation marks.\n",
        "\n",
        "#dev[[\"source_sentence\"]].to_csv(\"dev.\"+source_language, header=False, index=False)\n",
        "#dev[[\"target_sentence\"]].to_csv(\"dev.\"+target_language, header=False, index=False)\n",
        "\n",
        "# Doublecheck the format below. There should be no extra quotation marks or weird characters.\n",
        "! head train.*\n",
        "! head dev.*"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> train.en <==\n",
            "“ Preaching in a territory where you meet individuals who are so eager to learn the truth that they want to study the Bible with you every day is such a joy , ” says Stephanie .\n",
            "Where a public reading was forbidden , some sent copies to every member of the church . They wanted no further dealings with false religion !\n",
            "How can couples apply Ephesians 4 : 26 , 27 in their marriage ?\n",
            "Why may we look to the future with confidence ?\n",
            "However , she did what she could , and this can teach us a lesson .\n",
            "Consider what happened just before his arrest , trial , and execution .\n",
            "Many overcame their superstitious fears , and the number attending grew to over 80 .\n",
            "This spectacular display attracts tourists from all over the country .\n",
            "Therefore , beloved ones , since you are awaiting these things , do your utmost to be found finally by him spotless and unblemished and in peace . ”\n",
            "God’s Word , the Bible , foretold that in our time people would be “ self - assuming , haughty . ”\n",
            "\n",
            "==> train.ha <==\n",
            "Stephanie ta ce : “ Yin wa’azi a yankin da za ka haɗu da mutanen da suke son koyan gaskiya da kuma nazarin Littafi Mai Tsarki a kullum abin farin ciki ne .\n",
            "A inda ba a amince da hakan ba , ‘ yan’uwan sukan tura wasiƙa ga kowane memban cocin cewa ba sa son su yi tarayya da addinin ƙarya ko kaɗan !\n",
            "Ta yaya ne ma’aurata za su iya yin amfani da Afisawa 4 : 26 , 27 a aurensu ?\n",
            "Me ya sa ya kamata mu duba gaba da tabbaci ?\n",
            "Amma ta yi iya ƙoƙarinta , kuma hakan ya koya mana darasi .\n",
            "Ka yi la’akari da abin da ya faru kafin a kama shi , a yi masa hukunci , kuma a kashe shi .\n",
            "Mutane da yawa sun ɗauki wannan matakin , kuma adadin waɗanda suke halartar taro ya fi mutane 80 .\n",
            "Wannan yana jawo hankalin masu ziyara daga ko’ina a cikin ƙasar .\n",
            "Domin wannan , ƙaunatattu , tun da kuke sauraron waɗannan al’amura , sai ku ba da anniya a tarar da ku cikin salama , marasa - aibi marasa - laifi a gabansa . ” ( 2 Bit .\n",
            "Kalmar Allah , Littafi Mai Tsarki ta annabta cewa a zamaninmu mutane za su zama “ masu - ruba , masu - girman kai . ”\n",
            "==> dev.en <==\n",
            "They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "* By all means I shall have pity upon him . ”\n",
            "Experts admit that this is why human governments cannot eliminate corruption .\n",
            "In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "Dedication signifies a setting apart , or a separation , for a sacred purpose .\n",
            "The woman mentioned at the outset took the initiative to return to Jehovah and visited a local congregation of Jehovah’s Witnesses .\n",
            "They do not abuse their wives physically or verbally , do not insist on degrading sexual practices , and do not dishonor their wives by flirting with other women or by viewing pornography .\n",
            "JEHOVAH GOD’S Word exhorts us to love “ loving - kindness . ”\n",
            "Will we modestly recognize that Jesus is Head of the congregation and that he works through the body of elders appointed to take the lead ?\n",
            "I really am a fragile ‘ earthen vessel . ’\n",
            "\n",
            "==> dev.ha <==\n",
            "( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "( Yahuda 20 , 21 ) Keɓewa yana nufin a ware , don tsarkaken nufi .\n",
            "Matar da aka ambata a farkon talifin nan ta ɗauki mataki don ta sake soma bauta wa Jehobah kuma ta ziyarci ikilisiyar Shaidun Jehobah da ke inda take da zama .\n",
            "( 1 Bitrus 3 : 7 ) Ba sa wulaƙanta matansu a zahiri ko kuma da baki , ba sa nacewa ga jima’i mai ƙasƙantarwa ba , kuma ba sa raina matansu ta wajen neman wasu mata ko kuma ta wajen kallon hotunan tsirarun mata .\n",
            "KALMAR Jehovah Allah ta aririce mu mu yi ƙauna “ [ ƙauna ta alheri ] . ”\n",
            "Shin cikin filako za mu fahimci cewa Yesu ne Shugaban ikilisiya kuma yana aiki ta wurin rukunin dattawa da aka naɗa su yi shugabanci ?\n",
            "Ainihi ni mace ce marar ƙarfi kamar ‘ tukunyar ƙasa . ’\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epeCydmCyS8X"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Installation of JoeyNMT\n",
        "\n",
        "JoeyNMT is a simple, minimalist NMT package which is useful for learning and teaching. Check out the documentation for JoeyNMT [here](https://joeynmt.readthedocs.io)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBRMm4kMxZ8L",
        "outputId": "e84975f6-eb4e-4fcb-9188-33be5115ba43"
      },
      "source": [
        "# Install JoeyNMT\n",
        "! git clone https://github.com/joeynmt/joeynmt.git\n",
        "! cd joeynmt; pip3 install .\n",
        "# Install Pytorch with GPU support v1.7.1.\n",
        "! pip install torch==1.8.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'joeynmt'...\n",
            "remote: Enumerating objects: 3089, done.\u001b[K\n",
            "remote: Counting objects: 100% (138/138), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 3089 (delta 77), reused 74 (delta 36), pack-reused 2951\u001b[K\n",
            "Receiving objects: 100% (3089/3089), 8.08 MiB | 7.68 MiB/s, done.\n",
            "Resolving deltas: 100% (2106/2106), done.\n",
            "Processing /content/joeynmt\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (7.1.2)\n",
            "Collecting numpy==1.20.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/8a/064b4077e3d793f877e3b77aa64f56fa49a4d37236a53f78ee28be009a16/numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl (15.3MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3MB 353kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (56.0.0)\n",
            "Collecting torch==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/99/5861239a6e1ffe66e120f114a4d67e96e5c4b17c1a785dfc6ca6769585fc/torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5MB 25kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (2.4.1)\n",
            "Collecting torchtext==0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/50/84184d6230686e230c464f0dd4ff32eada2756b4a0b9cefec68b88d1d580/torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 32.8MB/s \n",
            "\u001b[?25hCollecting sacrebleu>=1.3.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n",
            "\u001b[?25hCollecting subword-nmt\n",
            "  Downloading https://files.pythonhosted.org/packages/74/60/6600a7bc09e7ab38bc53a48a20d8cae49b837f93f5842a41fe513a694912/subword_nmt-0.3.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (0.11.1)\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 10.0MB/s \n",
            "\u001b[?25hCollecting pylint\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/f0/9705d6ec002876bc20b6923cbdeeca82569a895fc214211562580e946079/pylint-2.8.2-py3-none-any.whl (357kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 48.7MB/s \n",
            "\u001b[?25hCollecting six==1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "Collecting wrapt==1.11.1\n",
            "  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->joeynmt==1.3) (3.7.4.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (0.4.4)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (0.36.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (1.28.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0->joeynmt==1.3) (4.41.1)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt==1.3) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt==1.3) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt==1.3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt==1.3) (1.3.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn->joeynmt==1.3) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->joeynmt==1.3) (1.4.1)\n",
            "Collecting astroid<2.7,>=2.5.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/82/a61df6c2d68f3ae3ad1afa0d2e5ba5cfb7386eb80cffb453def7c5757271/astroid-2.5.6-py3-none-any.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 51.9MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting isort<6,>=4.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/47/0ec3ec948b7b3a0ba44e62adede4dca8b5985ba6aaee59998bed0916bd17/isort-5.8.0-py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pylint->joeynmt==1.3) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.15->joeynmt==1.3) (3.10.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->joeynmt==1.3) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.3) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.3) (1.24.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.3) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.3) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.3) (0.2.8)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn->joeynmt==1.3) (2018.9)\n",
            "Collecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/b3/573d2f1fecbbe8f82a8d08172e938c247f99abe1be3bef3da2efaa3810bf/typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 47.1MB/s \n",
            "\u001b[?25hCollecting lazy-object-proxy>=1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/b0/f055db25fd68ab4859832a887c8b304274fc12dd5a3f8e83e61250733aeb/lazy_object_proxy-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.15->joeynmt==1.3) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->joeynmt==1.3) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.3) (0.4.8)\n",
            "Building wheels for collected packages: joeynmt, wrapt\n",
            "  Building wheel for joeynmt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for joeynmt: filename=joeynmt-1.3-cp37-none-any.whl size=84842 sha256=243fa4e89fae1724a900549c2cdea220903dfe7160e748a2afcdc4ffd0ea76c0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q8b_dfp4/wheels/db/01/db/751cc9f3e7f6faec127c43644ba250a3ea7ad200594aeda70a\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.11.1-cp37-cp37m-linux_x86_64.whl size=68377 sha256=a38d9a2658152aee0e3acc020df68135a2be292cc4b239d4eaf034f0a62d1dac\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n",
            "Successfully built joeynmt wrapt\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.20.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement wrapt~=1.12.1, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-python-client 1.12.8 has requirement six<2dev,>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-core 1.26.3 has requirement six>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, torch, torchtext, portalocker, sacrebleu, subword-nmt, pyyaml, wrapt, typed-ast, lazy-object-proxy, astroid, mccabe, isort, pylint, six, joeynmt\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchtext 0.9.1\n",
            "    Uninstalling torchtext-0.9.1:\n",
            "      Successfully uninstalled torchtext-0.9.1\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: wrapt 1.12.1\n",
            "    Uninstalling wrapt-1.12.1:\n",
            "      Successfully uninstalled wrapt-1.12.1\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "Successfully installed astroid-2.5.6 isort-5.8.0 joeynmt-1.3 lazy-object-proxy-1.6.0 mccabe-0.6.1 numpy-1.20.1 portalocker-2.0.0 pylint-2.8.2 pyyaml-5.4.1 sacrebleu-1.5.1 six-1.12.0 subword-nmt-0.3.7 torch-1.8.0 torchtext-0.9.0 typed-ast-1.4.3 wrapt-1.11.1\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.8.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (763.5MB)\n",
            "\u001b[K     |████████████████████████████████| 763.5MB 23kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu101) (1.20.1)\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.8.0+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.8.0\n",
            "    Uninstalling torch-1.8.0:\n",
            "      Successfully uninstalled torch-1.8.0\n",
            "Successfully installed torch-1.8.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaE77Tcppex9"
      },
      "source": [
        "# Preprocessing the Data into Subword BPE Tokens\n",
        "\n",
        "- One of the most powerful improvements for agglutinative languages (a feature of most Bantu languages) is using BPE tokenization [ (Sennrich, 2015) ](https://arxiv.org/abs/1508.07909).\n",
        "\n",
        "- It was also shown that by optimizing the umber of BPE codes we significantly improve results for low-resourced languages [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021) [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)\n",
        "\n",
        "- Below we have the scripts for doing BPE tokenization of our data. We use 4000 tokens as recommended by [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021). You do not need to change anything. Simply running the below will be suitable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-TyjtmXB1mL",
        "outputId": "4cae0d94-18d8-4851-dca0-a28f9044bfd1"
      },
      "source": [
        "# One of the huge boosts in NMT performance was to use a different method of tokenizing. \n",
        "# Usually, NMT would tokenize by words. However, using a method called BPE gave amazing boosts to performance\n",
        "\n",
        "# Do subword NMT\n",
        "from os import path\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
        "os.environ[\"tgt\"] = target_language\n",
        "\n",
        "# Learn BPEs on the training data.\n",
        "os.environ[\"data_path\"] = path.join(\"joeynmt\", \"data\",target_language + source_language ) # Herman! \n",
        "! subword-nmt learn-joint-bpe-and-vocab --input train.$src train.$tgt -s 4000 -o bpe.codes.4000 --write-vocabulary vocab.$src vocab.$tgt\n",
        "\n",
        "# Apply BPE splits to the development and test data.\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < train.$src > train.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < train.$tgt > train.bpe.$tgt\n",
        "\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < dev.$src > dev.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < dev.$tgt > dev.bpe.$tgt\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < test.$src > test.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < test.$tgt > test.bpe.$tgt\n",
        "\n",
        "# Create directory, move everyone we care about to the correct location\n",
        "! mkdir -p $data_path\n",
        "! cp train.* $data_path\n",
        "! cp test.* $data_path\n",
        "! cp dev.* $data_path\n",
        "! cp bpe.codes.4000 $data_path\n",
        "! ls $data_path\n",
        "\n",
        "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
        "! cp train.* \"$gdrive_path\"\n",
        "! cp test.* \"$gdrive_path\"\n",
        "! cp dev.* \"$gdrive_path\"\n",
        "! cp bpe.codes.4000 \"$gdrive_path\"\n",
        "! ls \"$gdrive_path\"\n",
        "\n",
        "# Create that vocab using build_vocab\n",
        "! sudo chmod 777 joeynmt/scripts/build_vocab.py\n",
        "# ! joeynmt/scripts/build_vocab.py joeynmt/data/$tgt$src/train.bpe.$src joeynmt/data/$src$tgt/train.bpe.$tgt --output_path joeynmt/data/$src$tgt/vocab.txt\n",
        "! joeynmt/scripts/build_vocab.py joeynmt/data/$tgt$src/train.bpe.$src joeynmt/data/$tgt$src/train.bpe.$tgt --output_path joeynmt/data/$tgt$src/vocab.txt\n",
        "\n",
        "# Some output\n",
        "! echo \"BPE Hausa Sentences\"\n",
        "! tail -n 5 test.bpe.$tgt\n",
        "! echo \"Combined BPE Vocab\"\n",
        "! tail -n 10 joeynmt/data/$tgt$src/vocab.txt  # Herman"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe.codes.4000\tdev.en\t     test.bpe.ha     test.ha\t   train.en\n",
            "dev.bpe.en\tdev.ha\t     test.en\t     train.bpe.en  train.ha\n",
            "dev.bpe.ha\ttest.bpe.en  test.en-any.en  train.bpe.ha\n",
            "bpe.codes.4000\tdev.en\t     test.bpe.ha     test.en-any.en.1  train.bpe.ha\n",
            "dev.bpe.en\tdev.ha\t     test.en\t     test.ha\t       train.en\n",
            "dev.bpe.ha\ttest.bpe.en  test.en-any.en  train.bpe.en      train.ha\n",
            "BPE Hausa Sentences\n",
            "Kada mu zama kamar Ab@@ ner da Ab@@ sal@@ om da suka ci am@@ ana .\n",
            "[ 1 ] ( sa@@ kin la@@ yi na 7 ) An canja wasu sun@@ a@@ ye .\n",
            "Idan muna da aminci da kuma tawali’u , za mu mai da hankali ga abin da Jehobah yake so mu yi , ba abin da muke so ba\n",
            "Idan mu masu aminci ne da kuma kirki , za mu riƙa taimaka wa mutane , kuma za mu bi da su yadda Jehobah yake so\n",
            "Idan muna da aminci da kuma ƙarfin zuciya , za mu yi biyayya ga Jehobah ko da yin hakan yana da wuya ko kuma muna far@@ gabaCombined BPE Vocab\n",
            "ʺ\n",
            "tabl@@\n",
            "ö\n",
            "£\n",
            "ş\n",
            "Ó@@\n",
            "lima\n",
            "refore\n",
            "Ž@@\n",
            "↓\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlMitUHR8Qy-",
        "outputId": "1a422958-fb23-4fc6-f232-4eca8bad87ba"
      },
      "source": [
        "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
        "! cp train.* \"$gdrive_path\"\n",
        "! cp test.* \"$gdrive_path\"\n",
        "! cp dev.* \"$gdrive_path\"\n",
        "! cp bpe.codes.4000 \"$gdrive_path\"\n",
        "! ls \"$gdrive_path\""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe.codes.4000\tdev.en\t     test.bpe.ha     test.en-any.en.1  train.bpe.ha\n",
            "dev.bpe.en\tdev.ha\t     test.en\t     test.ha\t       train.en\n",
            "dev.bpe.ha\ttest.bpe.en  test.en-any.en  train.bpe.en      train.ha\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixmzi60WsUZ8"
      },
      "source": [
        "# Creating the JoeyNMT Config\n",
        "\n",
        "JoeyNMT requires a yaml config. We provide a template below. We've also set a number of defaults with it, that you may play with!\n",
        "\n",
        "- We used Transformer architecture \n",
        "- We set our dropout to reasonably high: 0.3 (recommended in  [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021))\n",
        "\n",
        "Things worth playing with:\n",
        "- The batch size (also recommended to change for low-resourced languages)\n",
        "- The number of epochs (we've set it at 30 just so it runs in about an hour, for testing purposes)\n",
        "- The decoder options (beam_size, alpha)\n",
        "- Evaluation metrics (BLEU versus Crhf4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8TMgv1p3L1z"
      },
      "source": [
        "# This creates the config file for our JoeyNMT system. It might seem overwhelming so we've provided a couple of useful parameters you'll need to update\n",
        "# (You can of course play with all the parameters if you'd like!)\n",
        "\n",
        "name = '%s%s' % (target_language, source_language)\n",
        "# gdrive_path = os.environ[\"gdrive_path\"]\n",
        "\n",
        "# Create the config\n",
        "config = \"\"\"\n",
        "name: \"{target_language}{source_language}_reverse_transformer\"\n",
        "\n",
        "data:\n",
        "    src: \"{target_language}\"\n",
        "    trg: \"{source_language}\"\n",
        "    train: \"data/{name}/train.bpe\"\n",
        "    dev:   \"data/{name}/dev.bpe\"\n",
        "    test:  \"data/{name}/test.bpe\"\n",
        "    level: \"bpe\"\n",
        "    lowercase: False\n",
        "    max_sent_length: 100\n",
        "    src_vocab: \"data/{name}/vocab.txt\"\n",
        "    trg_vocab: \"data/{name}/vocab.txt\"\n",
        "\n",
        "testing:\n",
        "    beam_size: 5\n",
        "    alpha: 1.0\n",
        "\n",
        "training:\n",
        "    #load_model: \"{gdrive_path}/models/{name}_transformer/1.ckpt\" # if uncommented, load a pre-trained model from this checkpoint\n",
        "    random_seed: 42\n",
        "    optimizer: \"adam\"\n",
        "    normalization: \"tokens\"\n",
        "    adam_betas: [0.9, 0.999] \n",
        "    scheduling: \"plateau\"           # TODO: try switching from plateau to Noam scheduling\n",
        "    patience: 5                     # For plateau: decrease learning rate by decrease_factor if validation score has not improved for this many validation rounds.\n",
        "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n",
        "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n",
        "    decrease_factor: 0.7\n",
        "    loss: \"crossentropy\"\n",
        "    learning_rate: 0.0003\n",
        "    learning_rate_min: 0.00000001\n",
        "    weight_decay: 0.0\n",
        "    label_smoothing: 0.1\n",
        "    batch_size: 4096\n",
        "    batch_type: \"token\"\n",
        "    eval_batch_size: 3600\n",
        "    eval_batch_type: \"token\"\n",
        "    batch_multiplier: 1\n",
        "    early_stopping_metric: \"ppl\"\n",
        "    epochs: 30                  # TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\n",
        "    validation_freq: 1000          # TODO: Set to at least once per epoch.\n",
        "    logging_freq: 100\n",
        "    eval_metric: \"bleu\"\n",
        "    model_dir: \"models/{name}_reverse_transformer\"\n",
        "    overwrite: True              # TODO: Set to True if you want to overwrite possibly existing models. \n",
        "    shuffle: True\n",
        "    use_cuda: True\n",
        "    max_output_length: 100\n",
        "    print_valid_sents: [0, 1, 2, 3]\n",
        "    keep_last_ckpts: 3\n",
        "\n",
        "model:\n",
        "    initializer: \"xavier\"\n",
        "    bias_initializer: \"zeros\"\n",
        "    init_gain: 1.0\n",
        "    embed_initializer: \"xavier\"\n",
        "    embed_init_gain: 1.0\n",
        "    tied_embeddings: True\n",
        "    tied_softmax: True\n",
        "    encoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 4             # TODO: Increase to 8 for larger data.\n",
        "        embeddings:\n",
        "            embedding_dim: 256   # TODO: Increase to 512 for larger data.\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 256         # TODO: Increase to 512 for larger data.\n",
        "        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n",
        "        dropout: 0.3\n",
        "    decoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 4              # TODO: Increase to 8 for larger data.\n",
        "        embeddings:\n",
        "            embedding_dim: 256    # TODO: Increase to 512 for larger data.\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 256         # TODO: Increase to 512 for larger data.\n",
        "        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n",
        "        dropout: 0.3\n",
        "\"\"\".format(name=name, gdrive_path=os.environ[\"gdrive_path\"], source_language=source_language, target_language=target_language)\n",
        "with open(\"joeynmt/configs/transformer_reverse_{name}.yaml\".format(name=name),'w') as f:\n",
        "    f.write(config)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEzoJtV2MIpt"
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "This single line of joeynmt runs the training using the config we made above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzbNYNdjLgNb",
        "outputId": "403ecf19-b872-4d0c-e620-edfa2552aeb9"
      },
      "source": [
        "# Train the model\n",
        "# You can press Ctrl-C to stop. And then run the next cell to save your checkpoints! \n",
        "!cd joeynmt; python3 -m joeynmt train configs/transformer_reverse_$tgt$src.yaml"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-05 14:26:21,561 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n",
            "2021-05-05 14:26:21,632 - INFO - joeynmt.data - Loading training data...\n",
            "2021-05-05 14:26:25,027 - INFO - joeynmt.data - Building vocabulary...\n",
            "2021-05-05 14:26:25,307 - INFO - joeynmt.data - Loading dev data...\n",
            "2021-05-05 14:26:25,328 - INFO - joeynmt.data - Loading test data...\n",
            "2021-05-05 14:26:25,998 - INFO - joeynmt.data - Data loaded.\n",
            "2021-05-05 14:26:25,999 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
            "2021-05-05 14:26:26,201 - INFO - joeynmt.model - Enc-dec model built.\n",
            "2021-05-05 14:26:26.374955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-05-05 14:26:28,348 - INFO - joeynmt.training - Total params: 12152320\n",
            "2021-05-05 14:26:30,887 - INFO - joeynmt.helpers - cfg.name                           : haen_reverse_transformer\n",
            "2021-05-05 14:26:30,887 - INFO - joeynmt.helpers - cfg.data.src                       : ha\n",
            "2021-05-05 14:26:30,887 - INFO - joeynmt.helpers - cfg.data.trg                       : en\n",
            "2021-05-05 14:26:30,887 - INFO - joeynmt.helpers - cfg.data.train                     : data/haen/train.bpe\n",
            "2021-05-05 14:26:30,887 - INFO - joeynmt.helpers - cfg.data.dev                       : data/haen/dev.bpe\n",
            "2021-05-05 14:26:30,887 - INFO - joeynmt.helpers - cfg.data.test                      : data/haen/test.bpe\n",
            "2021-05-05 14:26:30,887 - INFO - joeynmt.helpers - cfg.data.level                     : bpe\n",
            "2021-05-05 14:26:30,887 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False\n",
            "2021-05-05 14:26:30,887 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 100\n",
            "2021-05-05 14:26:30,887 - INFO - joeynmt.helpers - cfg.data.src_vocab                 : data/haen/vocab.txt\n",
            "2021-05-05 14:26:30,887 - INFO - joeynmt.helpers - cfg.data.trg_vocab                 : data/haen/vocab.txt\n",
            "2021-05-05 14:26:30,887 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.patience              : 5\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.learning_rate_factor  : 0.5\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.learning_rate_warmup  : 1000\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0003\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.batch_size            : 4096\n",
            "2021-05-05 14:26:30,888 - INFO - joeynmt.helpers - cfg.training.batch_type            : token\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 3600\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.eval_batch_type       : token\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.epochs                : 30\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 1000\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/haen_reverse_transformer\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.overwrite             : True\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.shuffle               : True\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3]\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 3\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier\n",
            "2021-05-05 14:26:30,889 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : True\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 4\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.2\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 256\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 1024\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.3\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6\n",
            "2021-05-05 14:26:30,890 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 4\n",
            "2021-05-05 14:26:30,891 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256\n",
            "2021-05-05 14:26:30,891 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True\n",
            "2021-05-05 14:26:30,891 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.2\n",
            "2021-05-05 14:26:30,891 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 256\n",
            "2021-05-05 14:26:30,891 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 1024\n",
            "2021-05-05 14:26:30,891 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.3\n",
            "2021-05-05 14:26:30,891 - INFO - joeynmt.helpers - Data set sizes: \n",
            "\ttrain 207731,\n",
            "\tvalid 1000,\n",
            "\ttest 3309\n",
            "2021-05-05 14:26:30,891 - INFO - joeynmt.helpers - First training example:\n",
            "\t[SRC] S@@ te@@ p@@ han@@ i@@ e ta ce : “ Yin wa’azi a yan@@ kin da za ka haɗ@@ u da mutanen da suke son ko@@ yan gaskiya da kuma nazarin Littafi Mai Tsarki a kullum abin farin ciki ne .\n",
            "\t[TRG] “ P@@ re@@ aching in a ter@@ rit@@ ory where you meet individuals who are so e@@ ag@@ er to learn the truth that they want to study the Bible with you every day is such a joy , ” says S@@ te@@ p@@ han@@ i@@ e .\n",
            "2021-05-05 14:26:30,891 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) da (7) the (8) a (9) ya\n",
            "2021-05-05 14:26:30,891 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) da (7) the (8) a (9) ya\n",
            "2021-05-05 14:26:30,891 - INFO - joeynmt.helpers - Number of Src words (types): 4266\n",
            "2021-05-05 14:26:30,891 - INFO - joeynmt.helpers - Number of Trg words (types): 4266\n",
            "2021-05-05 14:26:30,892 - INFO - joeynmt.training - Model(\n",
            "\tencoder=TransformerEncoder(num_layers=6, num_heads=4),\n",
            "\tdecoder=TransformerDecoder(num_layers=6, num_heads=4),\n",
            "\tsrc_embed=Embeddings(embedding_dim=256, vocab_size=4266),\n",
            "\ttrg_embed=Embeddings(embedding_dim=256, vocab_size=4266))\n",
            "2021-05-05 14:26:30,895 - INFO - joeynmt.training - Train stats:\n",
            "\tdevice: cuda\n",
            "\tn_gpu: 1\n",
            "\t16-bits training: False\n",
            "\tgradient accumulation: 1\n",
            "\tbatch size per device: 4096\n",
            "\ttotal batch size (w. parallel & accumulation): 4096\n",
            "2021-05-05 14:26:30,895 - INFO - joeynmt.training - EPOCH 1\n",
            "2021-05-05 14:26:41,466 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     5.681585, Tokens per Sec:    20127, Lr: 0.000300\n",
            "2021-05-05 14:26:51,573 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     5.567130, Tokens per Sec:    20489, Lr: 0.000300\n",
            "2021-05-05 14:27:01,822 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     5.275325, Tokens per Sec:    20968, Lr: 0.000300\n",
            "2021-05-05 14:27:11,851 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     4.877353, Tokens per Sec:    20308, Lr: 0.000300\n",
            "2021-05-05 14:27:22,197 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     4.761692, Tokens per Sec:    20249, Lr: 0.000300\n",
            "2021-05-05 14:27:32,518 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     4.859602, Tokens per Sec:    20762, Lr: 0.000300\n",
            "2021-05-05 14:27:42,697 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     4.616446, Tokens per Sec:    20736, Lr: 0.000300\n",
            "2021-05-05 14:27:52,960 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     4.275070, Tokens per Sec:    20749, Lr: 0.000300\n",
            "2021-05-05 14:28:03,185 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     4.466928, Tokens per Sec:    20775, Lr: 0.000300\n",
            "2021-05-05 14:28:13,262 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     4.528721, Tokens per Sec:    20218, Lr: 0.000300\n",
            "2021-05-05 14:28:40,452 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:28:40,452 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:28:40,452 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:28:40,710 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:28:40,711 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:28:41,095 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:28:41,096 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:28:41,096 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:28:41,096 - INFO - joeynmt.training - \tHypothesis: The Bible is not be to be to be to be to be to be to be to be to be to be . ​ — 1 : 1 : 1 .\n",
            "2021-05-05 14:28:41,096 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:28:41,096 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:28:41,096 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:28:41,096 - INFO - joeynmt.training - \tHypothesis: ( Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read Read\n",
            "2021-05-05 14:28:41,096 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:28:41,096 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:28:41,097 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:28:41,097 - INFO - joeynmt.training - \tHypothesis: The Bible is a Bible of the Bible and the Bible and the Bible and the Bible of the Bible and the Bible .\n",
            "2021-05-05 14:28:41,097 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:28:41,097 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:28:41,097 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:28:41,097 - INFO - joeynmt.training - \tHypothesis: The Bible , the Bible , the Bible , the Bible was not been been been been been been been been to be to be to be to be .\n",
            "2021-05-05 14:28:41,097 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     1000: bleu:   0.62, loss: 107511.6562, ppl:  74.9537, duration: 27.8346s\n",
            "2021-05-05 14:28:51,290 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     4.216002, Tokens per Sec:    20462, Lr: 0.000300\n",
            "2021-05-05 14:29:01,474 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     4.214657, Tokens per Sec:    20894, Lr: 0.000300\n",
            "2021-05-05 14:29:11,724 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     4.295056, Tokens per Sec:    20829, Lr: 0.000300\n",
            "2021-05-05 14:29:21,918 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     4.279642, Tokens per Sec:    20553, Lr: 0.000300\n",
            "2021-05-05 14:29:32,192 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.980402, Tokens per Sec:    21123, Lr: 0.000300\n",
            "2021-05-05 14:29:42,328 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     3.433121, Tokens per Sec:    20594, Lr: 0.000300\n",
            "2021-05-05 14:29:52,531 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     4.092504, Tokens per Sec:    20825, Lr: 0.000300\n",
            "2021-05-05 14:30:02,747 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     4.129691, Tokens per Sec:    20711, Lr: 0.000300\n",
            "2021-05-05 14:30:12,742 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     3.991977, Tokens per Sec:    20187, Lr: 0.000300\n",
            "2021-05-05 14:30:22,954 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     4.114347, Tokens per Sec:    20661, Lr: 0.000300\n",
            "2021-05-05 14:30:40,153 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:30:40,153 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:30:40,153 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:30:40,387 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:30:40,387 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:30:40,796 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:30:40,797 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:30:40,797 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:30:40,797 - INFO - joeynmt.training - \tHypothesis: They can be a Christian who have to be a Bible . ​ — Matthew 3 : 1 .\n",
            "2021-05-05 14:30:40,797 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:30:40,797 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:30:40,797 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:30:40,797 - INFO - joeynmt.training - \tHypothesis: Jehovah is not to be a person .\n",
            "2021-05-05 14:30:40,797 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:30:40,798 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:30:40,798 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:30:40,798 - INFO - joeynmt.training - \tHypothesis: The same of the way that he was a person who would be a good news to be a good news .\n",
            "2021-05-05 14:30:40,798 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:30:40,798 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:30:40,798 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:30:40,798 - INFO - joeynmt.training - \tHypothesis: In the apostle Paul , Paul was a example of the apostle Paul , we are to be a good news .\n",
            "2021-05-05 14:30:40,798 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     2000: bleu:   2.94, loss: 93123.5859, ppl:  42.0623, duration: 17.8434s\n",
            "2021-05-05 14:30:50,998 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     4.026615, Tokens per Sec:    20389, Lr: 0.000300\n",
            "2021-05-05 14:31:01,102 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     3.578789, Tokens per Sec:    20327, Lr: 0.000300\n",
            "2021-05-05 14:31:11,314 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.959920, Tokens per Sec:    20762, Lr: 0.000300\n",
            "2021-05-05 14:31:21,543 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     3.664544, Tokens per Sec:    21006, Lr: 0.000300\n",
            "2021-05-05 14:31:31,632 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     3.641086, Tokens per Sec:    20408, Lr: 0.000300\n",
            "2021-05-05 14:31:34,205 - INFO - joeynmt.training - Epoch   1: total training loss 11071.86\n",
            "2021-05-05 14:31:34,205 - INFO - joeynmt.training - EPOCH 2\n",
            "2021-05-05 14:31:42,298 - INFO - joeynmt.training - Epoch   2, Step:     2600, Batch Loss:     3.559630, Tokens per Sec:    20316, Lr: 0.000300\n",
            "2021-05-05 14:31:52,503 - INFO - joeynmt.training - Epoch   2, Step:     2700, Batch Loss:     3.943409, Tokens per Sec:    20850, Lr: 0.000300\n",
            "2021-05-05 14:32:02,569 - INFO - joeynmt.training - Epoch   2, Step:     2800, Batch Loss:     3.507938, Tokens per Sec:    20486, Lr: 0.000300\n",
            "2021-05-05 14:32:12,811 - INFO - joeynmt.training - Epoch   2, Step:     2900, Batch Loss:     3.765672, Tokens per Sec:    20855, Lr: 0.000300\n",
            "2021-05-05 14:32:23,142 - INFO - joeynmt.training - Epoch   2, Step:     3000, Batch Loss:     3.278393, Tokens per Sec:    20938, Lr: 0.000300\n",
            "2021-05-05 14:32:41,662 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:32:41,662 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:32:41,662 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:32:41,911 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:32:41,911 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:32:42,303 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:32:42,304 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:32:42,304 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:32:42,304 - INFO - joeynmt.training - \tHypothesis: And they will be a good news to be a Bible . ​ — Isaiah 5 : 9 .\n",
            "2021-05-05 14:32:42,304 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:32:42,304 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:32:42,304 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:32:42,304 - INFO - joeynmt.training - \tHypothesis: ( a ) Jehovah is a ) to be a result of his disciples .\n",
            "2021-05-05 14:32:42,304 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:32:42,305 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:32:42,305 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:32:42,305 - INFO - joeynmt.training - \tHypothesis: The same way that this is not to be a new world that the world will be a new world will be a new world .\n",
            "2021-05-05 14:32:42,305 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:32:42,305 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:32:42,305 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:32:42,305 - INFO - joeynmt.training - \tHypothesis: In the apostle Paul , Paul was a man of his own life .\n",
            "2021-05-05 14:32:42,305 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     3000: bleu:   4.31, loss: 82444.1328, ppl:  27.3946, duration: 19.1629s\n",
            "2021-05-05 14:32:52,509 - INFO - joeynmt.training - Epoch   2, Step:     3100, Batch Loss:     3.519003, Tokens per Sec:    20781, Lr: 0.000300\n",
            "2021-05-05 14:33:02,663 - INFO - joeynmt.training - Epoch   2, Step:     3200, Batch Loss:     3.265843, Tokens per Sec:    20591, Lr: 0.000300\n",
            "2021-05-05 14:33:12,876 - INFO - joeynmt.training - Epoch   2, Step:     3300, Batch Loss:     3.541854, Tokens per Sec:    20627, Lr: 0.000300\n",
            "2021-05-05 14:33:22,905 - INFO - joeynmt.training - Epoch   2, Step:     3400, Batch Loss:     3.141798, Tokens per Sec:    20569, Lr: 0.000300\n",
            "2021-05-05 14:33:33,094 - INFO - joeynmt.training - Epoch   2, Step:     3500, Batch Loss:     3.113902, Tokens per Sec:    20666, Lr: 0.000300\n",
            "2021-05-05 14:33:43,309 - INFO - joeynmt.training - Epoch   2, Step:     3600, Batch Loss:     3.493656, Tokens per Sec:    20872, Lr: 0.000300\n",
            "2021-05-05 14:33:53,378 - INFO - joeynmt.training - Epoch   2, Step:     3700, Batch Loss:     3.514292, Tokens per Sec:    19961, Lr: 0.000300\n",
            "2021-05-05 14:34:03,584 - INFO - joeynmt.training - Epoch   2, Step:     3800, Batch Loss:     3.621599, Tokens per Sec:    20876, Lr: 0.000300\n",
            "2021-05-05 14:34:13,790 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:     3.575709, Tokens per Sec:    21085, Lr: 0.000300\n",
            "2021-05-05 14:34:23,909 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     2.973704, Tokens per Sec:    20908, Lr: 0.000300\n",
            "2021-05-05 14:34:39,739 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:34:39,739 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:34:39,739 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:34:39,975 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:34:39,976 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:34:40,385 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:34:40,385 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:34:40,385 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:34:40,385 - INFO - joeynmt.training - \tHypothesis: And they will be able to be a Bible principles . ​ — Isaiah 20 : 20 .\n",
            "2021-05-05 14:34:40,385 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:34:40,386 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:34:40,386 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:34:40,386 - INFO - joeynmt.training - \tHypothesis: Jehovah has been a resurrection of his followers .\n",
            "2021-05-05 14:34:40,386 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:34:40,386 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:34:40,386 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:34:40,386 - INFO - joeynmt.training - \tHypothesis: The same way that the world is not a new world that they would be able to be the end of the world .\n",
            "2021-05-05 14:34:40,386 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:34:40,386 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:34:40,386 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:34:40,386 - INFO - joeynmt.training - \tHypothesis: In the following article , Paul wrote the book of the word of us to be a sin .\n",
            "2021-05-05 14:34:40,387 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     4000: bleu:   6.61, loss: 76083.4922, ppl:  21.2201, duration: 16.4775s\n",
            "2021-05-05 14:34:50,514 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     3.298361, Tokens per Sec:    20399, Lr: 0.000300\n",
            "2021-05-05 14:35:00,743 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     3.505230, Tokens per Sec:    20909, Lr: 0.000300\n",
            "2021-05-05 14:35:10,915 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     3.498258, Tokens per Sec:    21178, Lr: 0.000300\n",
            "2021-05-05 14:35:21,032 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     3.386517, Tokens per Sec:    20273, Lr: 0.000300\n",
            "2021-05-05 14:35:31,120 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     2.912143, Tokens per Sec:    20332, Lr: 0.000300\n",
            "2021-05-05 14:35:41,384 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     3.357174, Tokens per Sec:    20990, Lr: 0.000300\n",
            "2021-05-05 14:35:51,579 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     3.492402, Tokens per Sec:    20748, Lr: 0.000300\n",
            "2021-05-05 14:36:01,612 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     3.575296, Tokens per Sec:    20327, Lr: 0.000300\n",
            "2021-05-05 14:36:11,788 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     3.063635, Tokens per Sec:    20746, Lr: 0.000300\n",
            "2021-05-05 14:36:22,026 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     3.184737, Tokens per Sec:    20814, Lr: 0.000300\n",
            "2021-05-05 14:36:35,172 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:36:35,172 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:36:35,172 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:36:35,406 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:36:35,406 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:36:35,819 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:36:35,820 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:36:35,820 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:36:35,820 - INFO - joeynmt.training - \tHypothesis: And they will be determined to be a spiritual principles . ​ — Isaiah 20 : 20 .\n",
            "2021-05-05 14:36:35,820 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:36:35,820 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:36:35,820 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:36:35,820 - INFO - joeynmt.training - \tHypothesis: Jehovah has been the hope of his children .\n",
            "2021-05-05 14:36:35,820 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:36:35,820 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:36:35,820 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:36:35,820 - INFO - joeynmt.training - \tHypothesis: The Levites were not sure that this world would be a new world will not be destroyed in the end of the end of the end of the end .\n",
            "2021-05-05 14:36:35,820 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:36:35,821 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:36:35,821 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:36:35,821 - INFO - joeynmt.training - \tHypothesis: In the book of the book of Paul’s words , Paul described the ransom sacrifice of sin .\n",
            "2021-05-05 14:36:35,821 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     5000: bleu:   9.58, loss: 71687.1719, ppl:  17.7862, duration: 13.7939s\n",
            "2021-05-05 14:36:40,469 - INFO - joeynmt.training - Epoch   2: total training loss 8393.78\n",
            "2021-05-05 14:36:40,469 - INFO - joeynmt.training - EPOCH 3\n",
            "2021-05-05 14:36:46,259 - INFO - joeynmt.training - Epoch   3, Step:     5100, Batch Loss:     3.097313, Tokens per Sec:    19720, Lr: 0.000300\n",
            "2021-05-05 14:36:56,544 - INFO - joeynmt.training - Epoch   3, Step:     5200, Batch Loss:     2.909716, Tokens per Sec:    20998, Lr: 0.000300\n",
            "2021-05-05 14:37:06,620 - INFO - joeynmt.training - Epoch   3, Step:     5300, Batch Loss:     3.066638, Tokens per Sec:    20425, Lr: 0.000300\n",
            "2021-05-05 14:37:16,758 - INFO - joeynmt.training - Epoch   3, Step:     5400, Batch Loss:     3.000197, Tokens per Sec:    20565, Lr: 0.000300\n",
            "2021-05-05 14:37:26,819 - INFO - joeynmt.training - Epoch   3, Step:     5500, Batch Loss:     2.832037, Tokens per Sec:    20498, Lr: 0.000300\n",
            "2021-05-05 14:37:37,050 - INFO - joeynmt.training - Epoch   3, Step:     5600, Batch Loss:     2.736071, Tokens per Sec:    20912, Lr: 0.000300\n",
            "2021-05-05 14:37:47,228 - INFO - joeynmt.training - Epoch   3, Step:     5700, Batch Loss:     2.164996, Tokens per Sec:    20997, Lr: 0.000300\n",
            "2021-05-05 14:37:57,519 - INFO - joeynmt.training - Epoch   3, Step:     5800, Batch Loss:     3.025560, Tokens per Sec:    20996, Lr: 0.000300\n",
            "2021-05-05 14:38:07,685 - INFO - joeynmt.training - Epoch   3, Step:     5900, Batch Loss:     3.017610, Tokens per Sec:    20463, Lr: 0.000300\n",
            "2021-05-05 14:38:17,813 - INFO - joeynmt.training - Epoch   3, Step:     6000, Batch Loss:     3.094609, Tokens per Sec:    21103, Lr: 0.000300\n",
            "2021-05-05 14:38:35,561 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:38:35,561 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:38:35,561 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:38:35,797 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:38:35,797 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:38:36,191 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:38:36,192 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:38:36,192 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:38:36,192 - INFO - joeynmt.training - \tHypothesis: And they will be determined to be clean to the Bible principles . ​ — Isaiah 35 : 18 .\n",
            "2021-05-05 14:38:36,192 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:38:36,192 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:38:36,192 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:38:36,192 - INFO - joeynmt.training - \tHypothesis: Jehovah has made his hope to see his children .\n",
            "2021-05-05 14:38:36,192 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:38:36,192 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:38:36,192 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:38:36,192 - INFO - joeynmt.training - \tHypothesis: The Levites were not to see that this world would be a part of the world that would be destroyed .\n",
            "2021-05-05 14:38:36,193 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:38:36,193 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:38:36,193 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:38:36,193 - INFO - joeynmt.training - \tHypothesis: In the book of Romans 7 , Paul described the Devil , the Devil revealed our sin .\n",
            "2021-05-05 14:38:36,193 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     6000: bleu:  11.53, loss: 68112.6562, ppl:  15.4082, duration: 18.3798s\n",
            "2021-05-05 14:38:46,363 - INFO - joeynmt.training - Epoch   3, Step:     6100, Batch Loss:     2.992851, Tokens per Sec:    20484, Lr: 0.000300\n",
            "2021-05-05 14:38:56,543 - INFO - joeynmt.training - Epoch   3, Step:     6200, Batch Loss:     3.087985, Tokens per Sec:    20682, Lr: 0.000300\n",
            "2021-05-05 14:39:06,673 - INFO - joeynmt.training - Epoch   3, Step:     6300, Batch Loss:     2.688456, Tokens per Sec:    20272, Lr: 0.000300\n",
            "2021-05-05 14:39:16,767 - INFO - joeynmt.training - Epoch   3, Step:     6400, Batch Loss:     2.803199, Tokens per Sec:    20229, Lr: 0.000300\n",
            "2021-05-05 14:39:26,914 - INFO - joeynmt.training - Epoch   3, Step:     6500, Batch Loss:     3.126387, Tokens per Sec:    20821, Lr: 0.000300\n",
            "2021-05-05 14:39:37,065 - INFO - joeynmt.training - Epoch   3, Step:     6600, Batch Loss:     3.064587, Tokens per Sec:    20617, Lr: 0.000300\n",
            "2021-05-05 14:39:47,198 - INFO - joeynmt.training - Epoch   3, Step:     6700, Batch Loss:     2.864856, Tokens per Sec:    20522, Lr: 0.000300\n",
            "2021-05-05 14:39:57,396 - INFO - joeynmt.training - Epoch   3, Step:     6800, Batch Loss:     3.111850, Tokens per Sec:    20640, Lr: 0.000300\n",
            "2021-05-05 14:40:07,509 - INFO - joeynmt.training - Epoch   3, Step:     6900, Batch Loss:     2.844162, Tokens per Sec:    20476, Lr: 0.000300\n",
            "2021-05-05 14:40:17,662 - INFO - joeynmt.training - Epoch   3, Step:     7000, Batch Loss:     3.114116, Tokens per Sec:    20818, Lr: 0.000300\n",
            "2021-05-05 14:40:28,929 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:40:28,929 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:40:28,930 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:40:29,159 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:40:29,159 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:40:29,556 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:40:29,556 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:40:29,556 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:40:29,556 - INFO - joeynmt.training - \tHypothesis: And they will be able to be clean to the Bible . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:40:29,556 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:40:29,556 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:40:29,557 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:40:29,557 - INFO - joeynmt.training - \tHypothesis: Jehovah has been the hope of his children .\n",
            "2021-05-05 14:40:29,557 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:40:29,557 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:40:29,557 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:40:29,557 - INFO - joeynmt.training - \tHypothesis: The Levites were aware that this world is not a part of the world that would be destroyed .\n",
            "2021-05-05 14:40:29,557 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:40:29,557 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:40:29,557 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:40:29,557 - INFO - joeynmt.training - \tHypothesis: In the chapter 7 of Romans 7 , Paul revealed our sins in our own flesh .\n",
            "2021-05-05 14:40:29,557 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     7000: bleu:  13.95, loss: 65488.1328, ppl:  13.8671, duration: 11.8953s\n",
            "2021-05-05 14:40:39,793 - INFO - joeynmt.training - Epoch   3, Step:     7100, Batch Loss:     2.560934, Tokens per Sec:    20671, Lr: 0.000300\n",
            "2021-05-05 14:40:49,957 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:     2.897031, Tokens per Sec:    21166, Lr: 0.000300\n",
            "2021-05-05 14:41:00,183 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:     2.571595, Tokens per Sec:    20912, Lr: 0.000300\n",
            "2021-05-05 14:41:10,369 - INFO - joeynmt.training - Epoch   3, Step:     7400, Batch Loss:     3.077476, Tokens per Sec:    20446, Lr: 0.000300\n",
            "2021-05-05 14:41:20,450 - INFO - joeynmt.training - Epoch   3, Step:     7500, Batch Loss:     2.841223, Tokens per Sec:    20174, Lr: 0.000300\n",
            "2021-05-05 14:41:27,880 - INFO - joeynmt.training - Epoch   3: total training loss 7446.11\n",
            "2021-05-05 14:41:27,881 - INFO - joeynmt.training - EPOCH 4\n",
            "2021-05-05 14:41:30,925 - INFO - joeynmt.training - Epoch   4, Step:     7600, Batch Loss:     2.982694, Tokens per Sec:    18240, Lr: 0.000300\n",
            "2021-05-05 14:41:41,248 - INFO - joeynmt.training - Epoch   4, Step:     7700, Batch Loss:     2.773207, Tokens per Sec:    20928, Lr: 0.000300\n",
            "2021-05-05 14:41:51,390 - INFO - joeynmt.training - Epoch   4, Step:     7800, Batch Loss:     2.840511, Tokens per Sec:    20572, Lr: 0.000300\n",
            "2021-05-05 14:42:01,661 - INFO - joeynmt.training - Epoch   4, Step:     7900, Batch Loss:     2.670493, Tokens per Sec:    20651, Lr: 0.000300\n",
            "2021-05-05 14:42:11,715 - INFO - joeynmt.training - Epoch   4, Step:     8000, Batch Loss:     2.925685, Tokens per Sec:    20154, Lr: 0.000300\n",
            "2021-05-05 14:42:28,889 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:42:28,890 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:42:28,890 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:42:29,129 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:42:29,129 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:42:29,495 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:42:29,496 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:42:29,496 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:42:29,496 - INFO - joeynmt.training - \tHypothesis: And they will have a peace to benefit the Bible . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:42:29,496 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:42:29,496 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:42:29,496 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:42:29,496 - INFO - joeynmt.training - \tHypothesis: Jehovah has seen his children .\n",
            "2021-05-05 14:42:29,496 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:42:29,496 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:42:29,497 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:42:29,497 - INFO - joeynmt.training - \tHypothesis: The Leviticus realized that this is why the government would not bring the end of the end of the end .\n",
            "2021-05-05 14:42:29,497 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:42:29,497 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:42:29,497 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:42:29,497 - INFO - joeynmt.training - \tHypothesis: In the book of Romans 7 , Paul revealed the power of sin .\n",
            "2021-05-05 14:42:29,497 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step     8000: bleu:  15.45, loss: 63095.0703, ppl:  12.5966, duration: 17.7815s\n",
            "2021-05-05 14:42:39,724 - INFO - joeynmt.training - Epoch   4, Step:     8100, Batch Loss:     2.220102, Tokens per Sec:    20435, Lr: 0.000300\n",
            "2021-05-05 14:42:49,845 - INFO - joeynmt.training - Epoch   4, Step:     8200, Batch Loss:     2.666563, Tokens per Sec:    20533, Lr: 0.000300\n",
            "2021-05-05 14:43:00,094 - INFO - joeynmt.training - Epoch   4, Step:     8300, Batch Loss:     2.554771, Tokens per Sec:    20730, Lr: 0.000300\n",
            "2021-05-05 14:43:10,248 - INFO - joeynmt.training - Epoch   4, Step:     8400, Batch Loss:     2.907897, Tokens per Sec:    20740, Lr: 0.000300\n",
            "2021-05-05 14:43:20,460 - INFO - joeynmt.training - Epoch   4, Step:     8500, Batch Loss:     2.568765, Tokens per Sec:    20643, Lr: 0.000300\n",
            "2021-05-05 14:43:30,616 - INFO - joeynmt.training - Epoch   4, Step:     8600, Batch Loss:     2.455713, Tokens per Sec:    20640, Lr: 0.000300\n",
            "2021-05-05 14:43:40,748 - INFO - joeynmt.training - Epoch   4, Step:     8700, Batch Loss:     2.755404, Tokens per Sec:    20608, Lr: 0.000300\n",
            "2021-05-05 14:43:50,867 - INFO - joeynmt.training - Epoch   4, Step:     8800, Batch Loss:     2.909284, Tokens per Sec:    20459, Lr: 0.000300\n",
            "2021-05-05 14:44:01,118 - INFO - joeynmt.training - Epoch   4, Step:     8900, Batch Loss:     2.822856, Tokens per Sec:    20660, Lr: 0.000300\n",
            "2021-05-05 14:44:11,311 - INFO - joeynmt.training - Epoch   4, Step:     9000, Batch Loss:     2.750784, Tokens per Sec:    20720, Lr: 0.000300\n",
            "2021-05-05 14:44:24,220 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:44:24,220 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:44:24,220 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:44:24,450 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:44:24,450 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:44:24,885 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:44:24,885 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:44:24,885 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:44:24,886 - INFO - joeynmt.training - \tHypothesis: And they will enjoy peace with principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:44:24,886 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:44:24,886 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:44:24,886 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:44:24,886 - INFO - joeynmt.training - \tHypothesis: Jehovah has been blessed to see his children .\n",
            "2021-05-05 14:44:24,886 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:44:24,886 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:44:24,887 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:44:24,887 - INFO - joeynmt.training - \tHypothesis: The enemies of this reason why the government of the world can bring to the end of the end of the end .\n",
            "2021-05-05 14:44:24,887 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:44:24,887 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:44:24,887 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:44:24,887 - INFO - joeynmt.training - \tHypothesis: In the chapter 7 , Paul explained that the power of sin is not a perfect human .\n",
            "2021-05-05 14:44:24,887 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step     9000: bleu:  17.06, loss: 60736.2031, ppl:  11.4583, duration: 13.5754s\n",
            "2021-05-05 14:44:35,031 - INFO - joeynmt.training - Epoch   4, Step:     9100, Batch Loss:     2.589952, Tokens per Sec:    20465, Lr: 0.000300\n",
            "2021-05-05 14:44:45,223 - INFO - joeynmt.training - Epoch   4, Step:     9200, Batch Loss:     2.915439, Tokens per Sec:    20876, Lr: 0.000300\n",
            "2021-05-05 14:44:55,351 - INFO - joeynmt.training - Epoch   4, Step:     9300, Batch Loss:     2.691324, Tokens per Sec:    20373, Lr: 0.000300\n",
            "2021-05-05 14:45:05,488 - INFO - joeynmt.training - Epoch   4, Step:     9400, Batch Loss:     2.768152, Tokens per Sec:    20651, Lr: 0.000300\n",
            "2021-05-05 14:45:15,797 - INFO - joeynmt.training - Epoch   4, Step:     9500, Batch Loss:     2.637963, Tokens per Sec:    21095, Lr: 0.000300\n",
            "2021-05-05 14:45:26,014 - INFO - joeynmt.training - Epoch   4, Step:     9600, Batch Loss:     2.598413, Tokens per Sec:    20289, Lr: 0.000300\n",
            "2021-05-05 14:45:36,244 - INFO - joeynmt.training - Epoch   4, Step:     9700, Batch Loss:     2.728482, Tokens per Sec:    21126, Lr: 0.000300\n",
            "2021-05-05 14:45:46,318 - INFO - joeynmt.training - Epoch   4, Step:     9800, Batch Loss:     2.845274, Tokens per Sec:    20594, Lr: 0.000300\n",
            "2021-05-05 14:45:56,485 - INFO - joeynmt.training - Epoch   4, Step:     9900, Batch Loss:     2.485417, Tokens per Sec:    20475, Lr: 0.000300\n",
            "2021-05-05 14:46:06,594 - INFO - joeynmt.training - Epoch   4, Step:    10000, Batch Loss:     2.866108, Tokens per Sec:    20703, Lr: 0.000300\n",
            "2021-05-05 14:46:22,913 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:46:22,914 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:46:22,914 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:46:23,146 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:46:23,146 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:46:23,552 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:46:23,552 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:46:23,552 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:46:23,552 - INFO - joeynmt.training - \tHypothesis: And they will find peace for the Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:46:23,552 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:46:23,553 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:46:23,553 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:46:23,553 - INFO - joeynmt.training - \tHypothesis: Jehovah has been blessed to see his children .\n",
            "2021-05-05 14:46:23,553 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:46:23,553 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:46:23,553 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:46:23,553 - INFO - joeynmt.training - \tHypothesis: The government was not seen that this reason why the government of government can bring the end of the end of the end .\n",
            "2021-05-05 14:46:23,553 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:46:23,553 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:46:23,553 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:46:23,553 - INFO - joeynmt.training - \tHypothesis: In the chapter 7 , Paul explained the power of sin in our own body .\n",
            "2021-05-05 14:46:23,553 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    10000: bleu:  18.14, loss: 59028.2188, ppl:  10.6988, duration: 16.9588s\n",
            "2021-05-05 14:46:33,676 - INFO - joeynmt.training - Epoch   4, Step:    10100, Batch Loss:     2.765474, Tokens per Sec:    20545, Lr: 0.000300\n",
            "2021-05-05 14:46:33,916 - INFO - joeynmt.training - Epoch   4: total training loss 6863.99\n",
            "2021-05-05 14:46:33,917 - INFO - joeynmt.training - EPOCH 5\n",
            "2021-05-05 14:46:44,139 - INFO - joeynmt.training - Epoch   5, Step:    10200, Batch Loss:     2.801028, Tokens per Sec:    19861, Lr: 0.000300\n",
            "2021-05-05 14:46:54,330 - INFO - joeynmt.training - Epoch   5, Step:    10300, Batch Loss:     2.386513, Tokens per Sec:    20313, Lr: 0.000300\n",
            "2021-05-05 14:47:04,538 - INFO - joeynmt.training - Epoch   5, Step:    10400, Batch Loss:     2.485645, Tokens per Sec:    21114, Lr: 0.000300\n",
            "2021-05-05 14:47:14,808 - INFO - joeynmt.training - Epoch   5, Step:    10500, Batch Loss:     2.849835, Tokens per Sec:    20926, Lr: 0.000300\n",
            "2021-05-05 14:47:24,924 - INFO - joeynmt.training - Epoch   5, Step:    10600, Batch Loss:     2.647563, Tokens per Sec:    20372, Lr: 0.000300\n",
            "2021-05-05 14:47:35,079 - INFO - joeynmt.training - Epoch   5, Step:    10700, Batch Loss:     2.430075, Tokens per Sec:    20579, Lr: 0.000300\n",
            "2021-05-05 14:47:45,121 - INFO - joeynmt.training - Epoch   5, Step:    10800, Batch Loss:     2.354947, Tokens per Sec:    20445, Lr: 0.000300\n",
            "2021-05-05 14:47:55,193 - INFO - joeynmt.training - Epoch   5, Step:    10900, Batch Loss:     2.582447, Tokens per Sec:    19936, Lr: 0.000300\n",
            "2021-05-05 14:48:05,372 - INFO - joeynmt.training - Epoch   5, Step:    11000, Batch Loss:     2.529312, Tokens per Sec:    20698, Lr: 0.000300\n",
            "2021-05-05 14:48:22,396 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:48:22,396 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:48:22,396 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:48:22,636 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:48:22,636 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:48:23,045 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:48:23,045 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:48:23,045 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:48:23,045 - INFO - joeynmt.training - \tHypothesis: And they will enjoy peace and follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:48:23,045 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:48:23,045 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:48:23,045 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:48:23,046 - INFO - joeynmt.training - \tHypothesis: Jehovah has seen his children to see his children .\n",
            "2021-05-05 14:48:23,046 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:48:23,046 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:48:23,046 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:48:23,046 - INFO - joeynmt.training - \tHypothesis: The Egyptians have seen that reason why the government of the world can bring the end of the end .\n",
            "2021-05-05 14:48:23,046 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:48:23,046 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:48:23,046 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:48:23,046 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans 7 , Paul revealed the power of sin and death .\n",
            "2021-05-05 14:48:23,046 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    11000: bleu:  18.96, loss: 57990.0703, ppl:  10.2620, duration: 17.6744s\n",
            "2021-05-05 14:48:33,220 - INFO - joeynmt.training - Epoch   5, Step:    11100, Batch Loss:     2.826416, Tokens per Sec:    20713, Lr: 0.000300\n",
            "2021-05-05 14:48:43,395 - INFO - joeynmt.training - Epoch   5, Step:    11200, Batch Loss:     2.386322, Tokens per Sec:    20520, Lr: 0.000300\n",
            "2021-05-05 14:48:53,587 - INFO - joeynmt.training - Epoch   5, Step:    11300, Batch Loss:     2.636374, Tokens per Sec:    20906, Lr: 0.000300\n",
            "2021-05-05 14:49:03,675 - INFO - joeynmt.training - Epoch   5, Step:    11400, Batch Loss:     2.563212, Tokens per Sec:    20352, Lr: 0.000300\n",
            "2021-05-05 14:49:13,946 - INFO - joeynmt.training - Epoch   5, Step:    11500, Batch Loss:     2.638305, Tokens per Sec:    21293, Lr: 0.000300\n",
            "2021-05-05 14:49:24,229 - INFO - joeynmt.training - Epoch   5, Step:    11600, Batch Loss:     2.557803, Tokens per Sec:    20922, Lr: 0.000300\n",
            "2021-05-05 14:49:34,453 - INFO - joeynmt.training - Epoch   5, Step:    11700, Batch Loss:     2.524478, Tokens per Sec:    20170, Lr: 0.000300\n",
            "2021-05-05 14:49:44,557 - INFO - joeynmt.training - Epoch   5, Step:    11800, Batch Loss:     2.403351, Tokens per Sec:    20432, Lr: 0.000300\n",
            "2021-05-05 14:49:54,794 - INFO - joeynmt.training - Epoch   5, Step:    11900, Batch Loss:     2.622497, Tokens per Sec:    21085, Lr: 0.000300\n",
            "2021-05-05 14:50:04,972 - INFO - joeynmt.training - Epoch   5, Step:    12000, Batch Loss:     2.841053, Tokens per Sec:    20685, Lr: 0.000300\n",
            "2021-05-05 14:50:23,396 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:50:23,396 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:50:23,396 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:50:23,625 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:50:23,625 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:50:24,023 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:50:24,024 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:50:24,024 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:50:24,024 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow the Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:50:24,024 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:50:24,024 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:50:24,024 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:50:24,024 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope of his children .\n",
            "2021-05-05 14:50:24,024 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:50:24,024 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:50:24,024 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:50:24,025 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this reason why the government of government can bring the end of the end of the end .\n",
            "2021-05-05 14:50:24,025 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:50:24,025 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:50:24,025 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:50:24,025 - INFO - joeynmt.training - \tHypothesis: In the chapter 7 of Romans , Paul explained the power of sin in our imperfect flesh .\n",
            "2021-05-05 14:50:24,025 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    12000: bleu:  19.35, loss: 56541.0195, ppl:   9.6820, duration: 19.0528s\n",
            "2021-05-05 14:50:34,265 - INFO - joeynmt.training - Epoch   5, Step:    12100, Batch Loss:     2.564928, Tokens per Sec:    20716, Lr: 0.000300\n",
            "2021-05-05 14:50:44,539 - INFO - joeynmt.training - Epoch   5, Step:    12200, Batch Loss:     2.524726, Tokens per Sec:    20649, Lr: 0.000300\n",
            "2021-05-05 14:50:54,658 - INFO - joeynmt.training - Epoch   5, Step:    12300, Batch Loss:     1.951976, Tokens per Sec:    20720, Lr: 0.000300\n",
            "2021-05-05 14:51:04,845 - INFO - joeynmt.training - Epoch   5, Step:    12400, Batch Loss:     2.312740, Tokens per Sec:    20690, Lr: 0.000300\n",
            "2021-05-05 14:51:14,943 - INFO - joeynmt.training - Epoch   5, Step:    12500, Batch Loss:     2.609942, Tokens per Sec:    20733, Lr: 0.000300\n",
            "2021-05-05 14:51:25,153 - INFO - joeynmt.training - Epoch   5, Step:    12600, Batch Loss:     2.491480, Tokens per Sec:    20684, Lr: 0.000300\n",
            "2021-05-05 14:51:28,264 - INFO - joeynmt.training - Epoch   5: total training loss 6474.46\n",
            "2021-05-05 14:51:28,264 - INFO - joeynmt.training - EPOCH 6\n",
            "2021-05-05 14:51:35,561 - INFO - joeynmt.training - Epoch   6, Step:    12700, Batch Loss:     2.205611, Tokens per Sec:    19462, Lr: 0.000300\n",
            "2021-05-05 14:51:45,701 - INFO - joeynmt.training - Epoch   6, Step:    12800, Batch Loss:     2.460260, Tokens per Sec:    20503, Lr: 0.000300\n",
            "2021-05-05 14:51:55,821 - INFO - joeynmt.training - Epoch   6, Step:    12900, Batch Loss:     2.484336, Tokens per Sec:    20583, Lr: 0.000300\n",
            "2021-05-05 14:52:06,088 - INFO - joeynmt.training - Epoch   6, Step:    13000, Batch Loss:     2.697161, Tokens per Sec:    20985, Lr: 0.000300\n",
            "2021-05-05 14:52:18,165 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:52:18,165 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:52:18,165 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:52:18,398 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:52:18,398 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:52:18,808 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:52:18,808 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:52:18,808 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:52:18,808 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to apply Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:52:18,809 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:52:18,809 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:52:18,809 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:52:18,809 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope to see his children .\n",
            "2021-05-05 14:52:18,809 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:52:18,809 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:52:18,809 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:52:18,809 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this reason why the government would not bring the end to the end of the end of the wicked .\n",
            "2021-05-05 14:52:18,809 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:52:18,809 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:52:18,809 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:52:18,809 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul explained the power of sin in our imperfect flesh .\n",
            "2021-05-05 14:52:18,810 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    13000: bleu:  20.68, loss: 55614.2188, ppl:   9.3283, duration: 12.7211s\n",
            "2021-05-05 14:52:29,052 - INFO - joeynmt.training - Epoch   6, Step:    13100, Batch Loss:     2.413819, Tokens per Sec:    20785, Lr: 0.000300\n",
            "2021-05-05 14:52:39,297 - INFO - joeynmt.training - Epoch   6, Step:    13200, Batch Loss:     2.534546, Tokens per Sec:    20872, Lr: 0.000300\n",
            "2021-05-05 14:52:49,397 - INFO - joeynmt.training - Epoch   6, Step:    13300, Batch Loss:     2.237591, Tokens per Sec:    20054, Lr: 0.000300\n",
            "2021-05-05 14:52:59,607 - INFO - joeynmt.training - Epoch   6, Step:    13400, Batch Loss:     1.758759, Tokens per Sec:    20742, Lr: 0.000300\n",
            "2021-05-05 14:53:09,697 - INFO - joeynmt.training - Epoch   6, Step:    13500, Batch Loss:     2.474977, Tokens per Sec:    20380, Lr: 0.000300\n",
            "2021-05-05 14:53:19,801 - INFO - joeynmt.training - Epoch   6, Step:    13600, Batch Loss:     2.637667, Tokens per Sec:    20550, Lr: 0.000300\n",
            "2021-05-05 14:53:29,980 - INFO - joeynmt.training - Epoch   6, Step:    13700, Batch Loss:     2.650578, Tokens per Sec:    20843, Lr: 0.000300\n",
            "2021-05-05 14:53:40,077 - INFO - joeynmt.training - Epoch   6, Step:    13800, Batch Loss:     2.708372, Tokens per Sec:    20729, Lr: 0.000300\n",
            "2021-05-05 14:53:50,225 - INFO - joeynmt.training - Epoch   6, Step:    13900, Batch Loss:     2.482491, Tokens per Sec:    20572, Lr: 0.000300\n",
            "2021-05-05 14:54:00,324 - INFO - joeynmt.training - Epoch   6, Step:    14000, Batch Loss:     2.550943, Tokens per Sec:    20578, Lr: 0.000300\n",
            "2021-05-05 14:54:14,768 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:54:14,769 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:54:14,769 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:54:15,009 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:54:15,009 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:54:15,425 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:54:15,425 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:54:15,425 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:54:15,425 - INFO - joeynmt.training - \tHypothesis: And they will enjoy peace and keep on doing Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:54:15,425 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:54:15,425 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:54:15,425 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:54:15,426 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children .\n",
            "2021-05-05 14:54:15,426 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:54:15,426 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:54:15,426 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:54:15,426 - INFO - joeynmt.training - \tHypothesis: The enemies have seen that reason why the government of the world can bring the end of the end of the wicked system .\n",
            "2021-05-05 14:54:15,426 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:54:15,426 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:54:15,426 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:54:15,426 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans 7 , Paul revealed the power of sin in our imperfect body .\n",
            "2021-05-05 14:54:15,426 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    14000: bleu:  20.28, loss: 54565.4648, ppl:   8.9437, duration: 15.1024s\n",
            "2021-05-05 14:54:25,560 - INFO - joeynmt.training - Epoch   6, Step:    14100, Batch Loss:     2.481776, Tokens per Sec:    20211, Lr: 0.000300\n",
            "2021-05-05 14:54:35,760 - INFO - joeynmt.training - Epoch   6, Step:    14200, Batch Loss:     2.271199, Tokens per Sec:    20881, Lr: 0.000300\n",
            "2021-05-05 14:54:45,865 - INFO - joeynmt.training - Epoch   6, Step:    14300, Batch Loss:     2.501317, Tokens per Sec:    19970, Lr: 0.000300\n",
            "2021-05-05 14:54:56,039 - INFO - joeynmt.training - Epoch   6, Step:    14400, Batch Loss:     2.217742, Tokens per Sec:    20686, Lr: 0.000300\n",
            "2021-05-05 14:55:06,182 - INFO - joeynmt.training - Epoch   6, Step:    14500, Batch Loss:     2.584698, Tokens per Sec:    20691, Lr: 0.000300\n",
            "2021-05-05 14:55:16,354 - INFO - joeynmt.training - Epoch   6, Step:    14600, Batch Loss:     2.487996, Tokens per Sec:    20733, Lr: 0.000300\n",
            "2021-05-05 14:55:26,611 - INFO - joeynmt.training - Epoch   6, Step:    14700, Batch Loss:     2.216404, Tokens per Sec:    21100, Lr: 0.000300\n",
            "2021-05-05 14:55:36,916 - INFO - joeynmt.training - Epoch   6, Step:    14800, Batch Loss:     2.590215, Tokens per Sec:    21645, Lr: 0.000300\n",
            "2021-05-05 14:55:47,112 - INFO - joeynmt.training - Epoch   6, Step:    14900, Batch Loss:     2.122742, Tokens per Sec:    20947, Lr: 0.000300\n",
            "2021-05-05 14:55:57,260 - INFO - joeynmt.training - Epoch   6, Step:    15000, Batch Loss:     2.628980, Tokens per Sec:    20060, Lr: 0.000300\n",
            "2021-05-05 14:56:13,408 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:56:13,408 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:56:13,408 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:56:13,643 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:56:13,643 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:56:14,045 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:56:14,045 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:56:14,045 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:56:14,045 - INFO - joeynmt.training - \tHypothesis: And they will be able to maintain peace for Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:56:14,045 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:56:14,045 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:56:14,045 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:56:14,045 - INFO - joeynmt.training - \tHypothesis: Jehovah has been blessed to see his children .\n",
            "2021-05-05 14:56:14,045 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:56:14,046 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:56:14,046 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:56:14,046 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this reason why the government of the world can bring the end of the end and the end of the wicked .\n",
            "2021-05-05 14:56:14,046 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:56:14,046 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:56:14,046 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:56:14,046 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans 7 , Paul revealed the power of sin in our flesh .\n",
            "2021-05-05 14:56:14,046 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    15000: bleu:  21.19, loss: 53820.8477, ppl:   8.6802, duration: 16.7860s\n",
            "2021-05-05 14:56:24,240 - INFO - joeynmt.training - Epoch   6, Step:    15100, Batch Loss:     2.888860, Tokens per Sec:    21007, Lr: 0.000300\n",
            "2021-05-05 14:56:30,349 - INFO - joeynmt.training - Epoch   6: total training loss 6176.68\n",
            "2021-05-05 14:56:30,349 - INFO - joeynmt.training - EPOCH 7\n",
            "2021-05-05 14:56:34,705 - INFO - joeynmt.training - Epoch   7, Step:    15200, Batch Loss:     2.400423, Tokens per Sec:    18811, Lr: 0.000300\n",
            "2021-05-05 14:56:44,925 - INFO - joeynmt.training - Epoch   7, Step:    15300, Batch Loss:     2.169010, Tokens per Sec:    20867, Lr: 0.000300\n",
            "2021-05-05 14:56:55,114 - INFO - joeynmt.training - Epoch   7, Step:    15400, Batch Loss:     2.532235, Tokens per Sec:    20582, Lr: 0.000300\n",
            "2021-05-05 14:57:05,302 - INFO - joeynmt.training - Epoch   7, Step:    15500, Batch Loss:     2.625748, Tokens per Sec:    20920, Lr: 0.000300\n",
            "2021-05-05 14:57:15,554 - INFO - joeynmt.training - Epoch   7, Step:    15600, Batch Loss:     2.365898, Tokens per Sec:    20857, Lr: 0.000300\n",
            "2021-05-05 14:57:25,870 - INFO - joeynmt.training - Epoch   7, Step:    15700, Batch Loss:     2.575071, Tokens per Sec:    21108, Lr: 0.000300\n",
            "2021-05-05 14:57:36,017 - INFO - joeynmt.training - Epoch   7, Step:    15800, Batch Loss:     2.767734, Tokens per Sec:    20906, Lr: 0.000300\n",
            "2021-05-05 14:57:46,176 - INFO - joeynmt.training - Epoch   7, Step:    15900, Batch Loss:     2.338803, Tokens per Sec:    20985, Lr: 0.000300\n",
            "2021-05-05 14:57:56,324 - INFO - joeynmt.training - Epoch   7, Step:    16000, Batch Loss:     2.211645, Tokens per Sec:    20222, Lr: 0.000300\n",
            "2021-05-05 14:58:12,120 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 14:58:12,120 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 14:58:12,120 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 14:58:12,348 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 14:58:12,349 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 14:58:12,772 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 14:58:12,772 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 14:58:12,772 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:58:12,772 - INFO - joeynmt.training - \tHypothesis: And they will be security for the principles of the Bible . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 14:58:12,772 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 14:58:12,772 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 14:58:12,772 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 14:58:12,772 - INFO - joeynmt.training - \tHypothesis: Jehovah has reached his children .\n",
            "2021-05-05 14:58:12,772 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 14:58:12,773 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 14:58:12,773 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 14:58:12,773 - INFO - joeynmt.training - \tHypothesis: The Egyptians recognized that this reason why the government of the world can bring the end of the wicked and the wicked .\n",
            "2021-05-05 14:58:12,773 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 14:58:12,773 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 14:58:12,773 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 14:58:12,773 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 14:58:12,773 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    16000: bleu:  21.70, loss: 52881.6836, ppl:   8.3590, duration: 16.4490s\n",
            "2021-05-05 14:58:22,925 - INFO - joeynmt.training - Epoch   7, Step:    16100, Batch Loss:     2.449441, Tokens per Sec:    20855, Lr: 0.000300\n",
            "2021-05-05 14:58:33,041 - INFO - joeynmt.training - Epoch   7, Step:    16200, Batch Loss:     2.397615, Tokens per Sec:    20594, Lr: 0.000300\n",
            "2021-05-05 14:58:43,201 - INFO - joeynmt.training - Epoch   7, Step:    16300, Batch Loss:     2.782000, Tokens per Sec:    20553, Lr: 0.000300\n",
            "2021-05-05 14:58:53,520 - INFO - joeynmt.training - Epoch   7, Step:    16400, Batch Loss:     2.564955, Tokens per Sec:    21092, Lr: 0.000300\n",
            "2021-05-05 14:59:03,636 - INFO - joeynmt.training - Epoch   7, Step:    16500, Batch Loss:     2.435678, Tokens per Sec:    20724, Lr: 0.000300\n",
            "2021-05-05 14:59:13,778 - INFO - joeynmt.training - Epoch   7, Step:    16600, Batch Loss:     2.478047, Tokens per Sec:    20342, Lr: 0.000300\n",
            "2021-05-05 14:59:23,899 - INFO - joeynmt.training - Epoch   7, Step:    16700, Batch Loss:     2.533260, Tokens per Sec:    20578, Lr: 0.000300\n",
            "2021-05-05 14:59:34,019 - INFO - joeynmt.training - Epoch   7, Step:    16800, Batch Loss:     2.484440, Tokens per Sec:    20628, Lr: 0.000300\n",
            "2021-05-05 14:59:44,193 - INFO - joeynmt.training - Epoch   7, Step:    16900, Batch Loss:     2.470517, Tokens per Sec:    20733, Lr: 0.000300\n",
            "2021-05-05 14:59:54,408 - INFO - joeynmt.training - Epoch   7, Step:    17000, Batch Loss:     1.947907, Tokens per Sec:    20749, Lr: 0.000300\n",
            "2021-05-05 15:00:08,719 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:00:08,719 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:00:08,719 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:00:08,954 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:00:08,954 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:00:09,381 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:00:09,382 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:00:09,382 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:00:09,382 - INFO - joeynmt.training - \tHypothesis: And they will enjoy peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:00:09,382 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:00:09,382 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:00:09,382 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:00:09,382 - INFO - joeynmt.training - \tHypothesis: Jehovah has hope to see his children .\n",
            "2021-05-05 15:00:09,382 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:00:09,382 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:00:09,383 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:00:09,383 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this reason why the government of the world can bring the end of the end and the sort of sexual immorality .\n",
            "2021-05-05 15:00:09,383 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:00:09,383 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:00:09,383 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:00:09,383 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:00:09,383 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    17000: bleu:  21.92, loss: 52207.1875, ppl:   8.1356, duration: 14.9745s\n",
            "2021-05-05 15:00:19,556 - INFO - joeynmt.training - Epoch   7, Step:    17100, Batch Loss:     2.214309, Tokens per Sec:    20698, Lr: 0.000300\n",
            "2021-05-05 15:00:29,648 - INFO - joeynmt.training - Epoch   7, Step:    17200, Batch Loss:     2.312537, Tokens per Sec:    20620, Lr: 0.000300\n",
            "2021-05-05 15:00:39,776 - INFO - joeynmt.training - Epoch   7, Step:    17300, Batch Loss:     2.127913, Tokens per Sec:    20385, Lr: 0.000300\n",
            "2021-05-05 15:00:50,035 - INFO - joeynmt.training - Epoch   7, Step:    17400, Batch Loss:     2.311611, Tokens per Sec:    21078, Lr: 0.000300\n",
            "2021-05-05 15:01:00,180 - INFO - joeynmt.training - Epoch   7, Step:    17500, Batch Loss:     2.594457, Tokens per Sec:    20148, Lr: 0.000300\n",
            "2021-05-05 15:01:10,317 - INFO - joeynmt.training - Epoch   7, Step:    17600, Batch Loss:     2.250352, Tokens per Sec:    20625, Lr: 0.000300\n",
            "2021-05-05 15:01:18,728 - INFO - joeynmt.training - Epoch   7: total training loss 5935.71\n",
            "2021-05-05 15:01:18,728 - INFO - joeynmt.training - EPOCH 8\n",
            "2021-05-05 15:01:20,781 - INFO - joeynmt.training - Epoch   8, Step:    17700, Batch Loss:     2.050832, Tokens per Sec:    17551, Lr: 0.000300\n",
            "2021-05-05 15:01:31,034 - INFO - joeynmt.training - Epoch   8, Step:    17800, Batch Loss:     2.134123, Tokens per Sec:    20686, Lr: 0.000300\n",
            "2021-05-05 15:01:41,114 - INFO - joeynmt.training - Epoch   8, Step:    17900, Batch Loss:     2.431364, Tokens per Sec:    20116, Lr: 0.000300\n",
            "2021-05-05 15:01:51,291 - INFO - joeynmt.training - Epoch   8, Step:    18000, Batch Loss:     2.376993, Tokens per Sec:    20720, Lr: 0.000300\n",
            "2021-05-05 15:02:04,181 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:02:04,181 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:02:04,181 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:02:04,411 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:02:04,411 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:02:04,842 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:02:04,842 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:02:04,842 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:02:04,842 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:02:04,842 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:02:04,842 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:02:04,843 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:02:04,843 - INFO - joeynmt.training - \tHypothesis: Jehovah has returned to his children .\n",
            "2021-05-05 15:02:04,843 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:02:04,843 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:02:04,843 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:02:04,843 - INFO - joeynmt.training - \tHypothesis: The land saw that this reason why the government of the world can bring the end of the wicked system of things .\n",
            "2021-05-05 15:02:04,843 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:02:04,843 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:02:04,843 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:02:04,843 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect body .\n",
            "2021-05-05 15:02:04,843 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    18000: bleu:  22.48, loss: 51612.8242, ppl:   7.9438, duration: 13.5517s\n",
            "2021-05-05 15:02:15,101 - INFO - joeynmt.training - Epoch   8, Step:    18100, Batch Loss:     2.423686, Tokens per Sec:    20867, Lr: 0.000300\n",
            "2021-05-05 15:02:25,269 - INFO - joeynmt.training - Epoch   8, Step:    18200, Batch Loss:     2.482563, Tokens per Sec:    20537, Lr: 0.000300\n",
            "2021-05-05 15:02:35,527 - INFO - joeynmt.training - Epoch   8, Step:    18300, Batch Loss:     2.284235, Tokens per Sec:    21321, Lr: 0.000300\n",
            "2021-05-05 15:02:45,565 - INFO - joeynmt.training - Epoch   8, Step:    18400, Batch Loss:     2.292057, Tokens per Sec:    19952, Lr: 0.000300\n",
            "2021-05-05 15:02:55,643 - INFO - joeynmt.training - Epoch   8, Step:    18500, Batch Loss:     2.167947, Tokens per Sec:    20226, Lr: 0.000300\n",
            "2021-05-05 15:03:05,895 - INFO - joeynmt.training - Epoch   8, Step:    18600, Batch Loss:     1.372501, Tokens per Sec:    20940, Lr: 0.000300\n",
            "2021-05-05 15:03:16,071 - INFO - joeynmt.training - Epoch   8, Step:    18700, Batch Loss:     2.545148, Tokens per Sec:    20742, Lr: 0.000300\n",
            "2021-05-05 15:03:26,323 - INFO - joeynmt.training - Epoch   8, Step:    18800, Batch Loss:     2.224250, Tokens per Sec:    21039, Lr: 0.000300\n",
            "2021-05-05 15:03:36,571 - INFO - joeynmt.training - Epoch   8, Step:    18900, Batch Loss:     1.710806, Tokens per Sec:    20866, Lr: 0.000300\n",
            "2021-05-05 15:03:46,715 - INFO - joeynmt.training - Epoch   8, Step:    19000, Batch Loss:     1.960313, Tokens per Sec:    20636, Lr: 0.000300\n",
            "2021-05-05 15:04:00,282 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:04:00,282 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:04:00,282 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:04:00,517 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:04:00,517 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:04:00,905 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:04:00,905 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:04:00,905 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:04:00,905 - INFO - joeynmt.training - \tHypothesis: And they will find security for following Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:04:00,906 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:04:00,906 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:04:00,906 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:04:00,906 - INFO - joeynmt.training - \tHypothesis: Jehovah has rewarded his children .\n",
            "2021-05-05 15:04:00,906 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:04:00,906 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:04:00,906 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:04:00,906 - INFO - joeynmt.training - \tHypothesis: The Egyptians recognized that this reason why the government of the world can bring the end of the wicked and the wilderness .\n",
            "2021-05-05 15:04:00,906 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:04:00,906 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:04:00,907 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:04:00,907 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul explained the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:04:00,907 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    19000: bleu:  22.84, loss: 51020.1719, ppl:   7.7570, duration: 14.1909s\n",
            "2021-05-05 15:04:11,228 - INFO - joeynmt.training - Epoch   8, Step:    19100, Batch Loss:     2.216501, Tokens per Sec:    20853, Lr: 0.000300\n",
            "2021-05-05 15:04:21,440 - INFO - joeynmt.training - Epoch   8, Step:    19200, Batch Loss:     2.218793, Tokens per Sec:    20567, Lr: 0.000300\n",
            "2021-05-05 15:04:31,662 - INFO - joeynmt.training - Epoch   8, Step:    19300, Batch Loss:     1.936576, Tokens per Sec:    20826, Lr: 0.000300\n",
            "2021-05-05 15:04:41,796 - INFO - joeynmt.training - Epoch   8, Step:    19400, Batch Loss:     2.315771, Tokens per Sec:    20639, Lr: 0.000300\n",
            "2021-05-05 15:04:51,942 - INFO - joeynmt.training - Epoch   8, Step:    19500, Batch Loss:     2.242632, Tokens per Sec:    20210, Lr: 0.000300\n",
            "2021-05-05 15:05:02,062 - INFO - joeynmt.training - Epoch   8, Step:    19600, Batch Loss:     2.119296, Tokens per Sec:    20526, Lr: 0.000300\n",
            "2021-05-05 15:05:12,335 - INFO - joeynmt.training - Epoch   8, Step:    19700, Batch Loss:     2.280545, Tokens per Sec:    21105, Lr: 0.000300\n",
            "2021-05-05 15:05:22,503 - INFO - joeynmt.training - Epoch   8, Step:    19800, Batch Loss:     2.623717, Tokens per Sec:    20931, Lr: 0.000300\n",
            "2021-05-05 15:05:32,704 - INFO - joeynmt.training - Epoch   8, Step:    19900, Batch Loss:     2.256618, Tokens per Sec:    20241, Lr: 0.000300\n",
            "2021-05-05 15:05:42,853 - INFO - joeynmt.training - Epoch   8, Step:    20000, Batch Loss:     2.343741, Tokens per Sec:    20630, Lr: 0.000300\n",
            "2021-05-05 15:05:57,376 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:05:57,376 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:05:57,376 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:05:57,606 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:05:57,606 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:05:57,989 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:05:57,989 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:05:57,990 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:05:57,990 - INFO - joeynmt.training - \tHypothesis: They will also have peace for their Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:05:57,990 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:05:57,990 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:05:57,990 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:05:57,990 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children .\n",
            "2021-05-05 15:05:57,990 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:05:57,990 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:05:57,990 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:05:57,990 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this reason why the government of the world government cannot bring the end of the wicked and the wilderness .\n",
            "2021-05-05 15:05:57,990 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:05:57,991 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:05:57,991 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:05:57,991 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul explained the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:05:57,991 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    20000: bleu:  23.18, loss: 50282.9258, ppl:   7.5307, duration: 15.1375s\n",
            "2021-05-05 15:06:08,162 - INFO - joeynmt.training - Epoch   8, Step:    20100, Batch Loss:     2.379642, Tokens per Sec:    20822, Lr: 0.000300\n",
            "2021-05-05 15:06:18,297 - INFO - joeynmt.training - Epoch   8, Step:    20200, Batch Loss:     2.089706, Tokens per Sec:    20603, Lr: 0.000300\n",
            "2021-05-05 15:06:18,906 - INFO - joeynmt.training - Epoch   8: total training loss 5756.86\n",
            "2021-05-05 15:06:18,906 - INFO - joeynmt.training - EPOCH 9\n",
            "2021-05-05 15:06:28,696 - INFO - joeynmt.training - Epoch   9, Step:    20300, Batch Loss:     2.309237, Tokens per Sec:    19613, Lr: 0.000300\n",
            "2021-05-05 15:06:38,892 - INFO - joeynmt.training - Epoch   9, Step:    20400, Batch Loss:     2.265640, Tokens per Sec:    20721, Lr: 0.000300\n",
            "2021-05-05 15:06:49,063 - INFO - joeynmt.training - Epoch   9, Step:    20500, Batch Loss:     2.317907, Tokens per Sec:    20273, Lr: 0.000300\n",
            "2021-05-05 15:06:59,318 - INFO - joeynmt.training - Epoch   9, Step:    20600, Batch Loss:     2.341123, Tokens per Sec:    20749, Lr: 0.000300\n",
            "2021-05-05 15:07:09,553 - INFO - joeynmt.training - Epoch   9, Step:    20700, Batch Loss:     2.202319, Tokens per Sec:    20801, Lr: 0.000300\n",
            "2021-05-05 15:07:19,777 - INFO - joeynmt.training - Epoch   9, Step:    20800, Batch Loss:     2.326285, Tokens per Sec:    20628, Lr: 0.000300\n",
            "2021-05-05 15:07:29,867 - INFO - joeynmt.training - Epoch   9, Step:    20900, Batch Loss:     1.940722, Tokens per Sec:    20387, Lr: 0.000300\n",
            "2021-05-05 15:07:40,074 - INFO - joeynmt.training - Epoch   9, Step:    21000, Batch Loss:     2.402725, Tokens per Sec:    20455, Lr: 0.000300\n",
            "2021-05-05 15:07:52,758 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:07:52,758 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:07:52,758 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:07:52,995 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:07:52,996 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:07:53,379 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:07:53,379 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:07:53,379 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:07:53,379 - INFO - joeynmt.training - \tHypothesis: And they will have a security for following Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:07:53,379 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:07:53,379 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:07:53,379 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:07:53,379 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children .\n",
            "2021-05-05 15:07:53,379 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:07:53,380 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:07:53,380 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:07:53,380 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this reason why the government of the world can bring the end of the end of the wicked and the inhabitants .\n",
            "2021-05-05 15:07:53,380 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:07:53,380 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:07:53,380 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:07:53,380 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:07:53,380 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    21000: bleu:  23.45, loss: 49894.4141, ppl:   7.4141, duration: 13.3055s\n",
            "2021-05-05 15:08:03,557 - INFO - joeynmt.training - Epoch   9, Step:    21100, Batch Loss:     2.195216, Tokens per Sec:    21093, Lr: 0.000300\n",
            "2021-05-05 15:08:13,698 - INFO - joeynmt.training - Epoch   9, Step:    21200, Batch Loss:     2.398654, Tokens per Sec:    20548, Lr: 0.000300\n",
            "2021-05-05 15:08:23,853 - INFO - joeynmt.training - Epoch   9, Step:    21300, Batch Loss:     2.233518, Tokens per Sec:    20627, Lr: 0.000300\n",
            "2021-05-05 15:08:34,052 - INFO - joeynmt.training - Epoch   9, Step:    21400, Batch Loss:     2.289579, Tokens per Sec:    20548, Lr: 0.000300\n",
            "2021-05-05 15:08:44,315 - INFO - joeynmt.training - Epoch   9, Step:    21500, Batch Loss:     2.271782, Tokens per Sec:    21097, Lr: 0.000300\n",
            "2021-05-05 15:08:54,564 - INFO - joeynmt.training - Epoch   9, Step:    21600, Batch Loss:     2.423133, Tokens per Sec:    21155, Lr: 0.000300\n",
            "2021-05-05 15:09:04,762 - INFO - joeynmt.training - Epoch   9, Step:    21700, Batch Loss:     2.178541, Tokens per Sec:    20955, Lr: 0.000300\n",
            "2021-05-05 15:09:15,005 - INFO - joeynmt.training - Epoch   9, Step:    21800, Batch Loss:     2.079108, Tokens per Sec:    20832, Lr: 0.000300\n",
            "2021-05-05 15:09:25,142 - INFO - joeynmt.training - Epoch   9, Step:    21900, Batch Loss:     2.268817, Tokens per Sec:    20248, Lr: 0.000300\n",
            "2021-05-05 15:09:35,343 - INFO - joeynmt.training - Epoch   9, Step:    22000, Batch Loss:     2.119617, Tokens per Sec:    20763, Lr: 0.000300\n",
            "2021-05-05 15:09:51,088 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:09:51,089 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:09:51,089 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:09:51,320 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:09:51,320 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:09:51,709 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:09:51,709 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:09:51,709 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:09:51,709 - INFO - joeynmt.training - \tHypothesis: And they will have peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:09:51,709 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:09:51,709 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:09:51,709 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:09:51,709 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope of refuge .\n",
            "2021-05-05 15:09:51,710 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:09:51,710 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:09:51,710 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:09:51,710 - INFO - joeynmt.training - \tHypothesis: The Egyptian had seen that this is why the government of the world cannot bring the end of the wicked and the harvest .\n",
            "2021-05-05 15:09:51,710 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:09:51,710 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:09:51,710 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:09:51,710 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul explained the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:09:51,710 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    22000: bleu:  23.21, loss: 49703.7031, ppl:   7.3576, duration: 16.3672s\n",
            "2021-05-05 15:10:01,908 - INFO - joeynmt.training - Epoch   9, Step:    22100, Batch Loss:     2.490168, Tokens per Sec:    20774, Lr: 0.000300\n",
            "2021-05-05 15:10:12,181 - INFO - joeynmt.training - Epoch   9, Step:    22200, Batch Loss:     2.214425, Tokens per Sec:    20797, Lr: 0.000300\n",
            "2021-05-05 15:10:22,284 - INFO - joeynmt.training - Epoch   9, Step:    22300, Batch Loss:     2.694502, Tokens per Sec:    20700, Lr: 0.000300\n",
            "2021-05-05 15:10:32,436 - INFO - joeynmt.training - Epoch   9, Step:    22400, Batch Loss:     2.547145, Tokens per Sec:    20742, Lr: 0.000300\n",
            "2021-05-05 15:10:42,543 - INFO - joeynmt.training - Epoch   9, Step:    22500, Batch Loss:     2.298532, Tokens per Sec:    20418, Lr: 0.000300\n",
            "2021-05-05 15:10:52,752 - INFO - joeynmt.training - Epoch   9, Step:    22600, Batch Loss:     2.167499, Tokens per Sec:    20584, Lr: 0.000300\n",
            "2021-05-05 15:11:02,943 - INFO - joeynmt.training - Epoch   9, Step:    22700, Batch Loss:     2.235498, Tokens per Sec:    20564, Lr: 0.000300\n",
            "2021-05-05 15:11:05,830 - INFO - joeynmt.training - Epoch   9: total training loss 5605.20\n",
            "2021-05-05 15:11:05,830 - INFO - joeynmt.training - EPOCH 10\n",
            "2021-05-05 15:11:13,437 - INFO - joeynmt.training - Epoch  10, Step:    22800, Batch Loss:     2.150594, Tokens per Sec:    19666, Lr: 0.000300\n",
            "2021-05-05 15:11:23,625 - INFO - joeynmt.training - Epoch  10, Step:    22900, Batch Loss:     2.194996, Tokens per Sec:    20942, Lr: 0.000300\n",
            "2021-05-05 15:11:33,752 - INFO - joeynmt.training - Epoch  10, Step:    23000, Batch Loss:     2.087667, Tokens per Sec:    20268, Lr: 0.000300\n",
            "2021-05-05 15:11:48,528 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:11:48,528 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:11:48,528 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:11:48,758 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:11:48,758 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:11:49,143 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:11:49,144 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:11:49,144 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:11:49,144 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:11:49,144 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:11:49,144 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:11:49,144 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:11:49,144 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children .\n",
            "2021-05-05 15:11:49,144 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:11:49,144 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:11:49,145 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:11:49,145 - INFO - joeynmt.training - \tHypothesis: The Egyptians recognize that this reason why the government of the world governments cannot bring the end of the end of the sexual immorality and the disaster .\n",
            "2021-05-05 15:11:49,145 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:11:49,145 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:11:49,145 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:11:49,145 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:11:49,145 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    23000: bleu:  24.34, loss: 49025.6797, ppl:   7.1600, duration: 15.3927s\n",
            "2021-05-05 15:11:59,360 - INFO - joeynmt.training - Epoch  10, Step:    23100, Batch Loss:     2.078420, Tokens per Sec:    20668, Lr: 0.000300\n",
            "2021-05-05 15:12:09,567 - INFO - joeynmt.training - Epoch  10, Step:    23200, Batch Loss:     2.356550, Tokens per Sec:    20402, Lr: 0.000300\n",
            "2021-05-05 15:12:19,743 - INFO - joeynmt.training - Epoch  10, Step:    23300, Batch Loss:     2.360526, Tokens per Sec:    20633, Lr: 0.000300\n",
            "2021-05-05 15:12:29,857 - INFO - joeynmt.training - Epoch  10, Step:    23400, Batch Loss:     2.042729, Tokens per Sec:    20161, Lr: 0.000300\n",
            "2021-05-05 15:12:40,005 - INFO - joeynmt.training - Epoch  10, Step:    23500, Batch Loss:     2.292405, Tokens per Sec:    21182, Lr: 0.000300\n",
            "2021-05-05 15:12:50,183 - INFO - joeynmt.training - Epoch  10, Step:    23600, Batch Loss:     2.313953, Tokens per Sec:    20804, Lr: 0.000300\n",
            "2021-05-05 15:13:00,407 - INFO - joeynmt.training - Epoch  10, Step:    23700, Batch Loss:     2.279972, Tokens per Sec:    20666, Lr: 0.000300\n",
            "2021-05-05 15:13:10,704 - INFO - joeynmt.training - Epoch  10, Step:    23800, Batch Loss:     2.198378, Tokens per Sec:    21002, Lr: 0.000300\n",
            "2021-05-05 15:13:20,965 - INFO - joeynmt.training - Epoch  10, Step:    23900, Batch Loss:     2.256237, Tokens per Sec:    20972, Lr: 0.000300\n",
            "2021-05-05 15:13:31,139 - INFO - joeynmt.training - Epoch  10, Step:    24000, Batch Loss:     2.193167, Tokens per Sec:    20508, Lr: 0.000300\n",
            "2021-05-05 15:13:45,539 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:13:45,539 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:13:45,540 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:13:45,770 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:13:45,770 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:13:46,143 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:13:46,144 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:13:46,144 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:13:46,144 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:13:46,144 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:13:46,144 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:13:46,144 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:13:46,144 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children .\n",
            "2021-05-05 15:13:46,144 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:13:46,144 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:13:46,145 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:13:46,145 - INFO - joeynmt.training - \tHypothesis: The Egyptians recognize that this reason why the government of the world cannot bring the end of the sort and the disaster .\n",
            "2021-05-05 15:13:46,145 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:13:46,145 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:13:46,145 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:13:46,145 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul explained the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:13:46,145 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    24000: bleu:  24.24, loss: 48637.1250, ppl:   7.0491, duration: 15.0055s\n",
            "2021-05-05 15:13:56,330 - INFO - joeynmt.training - Epoch  10, Step:    24100, Batch Loss:     1.919417, Tokens per Sec:    20586, Lr: 0.000300\n",
            "2021-05-05 15:14:06,585 - INFO - joeynmt.training - Epoch  10, Step:    24200, Batch Loss:     2.406012, Tokens per Sec:    21104, Lr: 0.000300\n",
            "2021-05-05 15:14:16,754 - INFO - joeynmt.training - Epoch  10, Step:    24300, Batch Loss:     2.292081, Tokens per Sec:    20545, Lr: 0.000300\n",
            "2021-05-05 15:14:26,928 - INFO - joeynmt.training - Epoch  10, Step:    24400, Batch Loss:     1.861922, Tokens per Sec:    20708, Lr: 0.000300\n",
            "2021-05-05 15:14:37,050 - INFO - joeynmt.training - Epoch  10, Step:    24500, Batch Loss:     2.042529, Tokens per Sec:    20931, Lr: 0.000300\n",
            "2021-05-05 15:14:47,194 - INFO - joeynmt.training - Epoch  10, Step:    24600, Batch Loss:     2.404278, Tokens per Sec:    20829, Lr: 0.000300\n",
            "2021-05-05 15:14:57,328 - INFO - joeynmt.training - Epoch  10, Step:    24700, Batch Loss:     2.570491, Tokens per Sec:    20254, Lr: 0.000300\n",
            "2021-05-05 15:15:07,537 - INFO - joeynmt.training - Epoch  10, Step:    24800, Batch Loss:     2.372739, Tokens per Sec:    20502, Lr: 0.000300\n",
            "2021-05-05 15:15:17,732 - INFO - joeynmt.training - Epoch  10, Step:    24900, Batch Loss:     2.148890, Tokens per Sec:    20670, Lr: 0.000300\n",
            "2021-05-05 15:15:27,865 - INFO - joeynmt.training - Epoch  10, Step:    25000, Batch Loss:     2.210927, Tokens per Sec:    20661, Lr: 0.000300\n",
            "2021-05-05 15:15:41,811 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:15:41,811 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:15:41,811 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:15:42,038 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:15:42,039 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:15:42,451 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:15:42,452 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:15:42,452 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:15:42,452 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:15:42,452 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:15:42,452 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:15:42,452 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:15:42,452 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children .\n",
            "2021-05-05 15:15:42,452 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:15:42,452 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:15:42,452 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:15:42,452 - INFO - joeynmt.training - \tHypothesis: The Egyptians found that this is why the governments of the world cannot bring the end of the sexual immorality and the smoking .\n",
            "2021-05-05 15:15:42,453 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:15:42,453 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:15:42,453 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:15:42,453 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:15:42,453 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    25000: bleu:  24.27, loss: 48401.1406, ppl:   6.9827, duration: 14.5876s\n",
            "2021-05-05 15:15:52,587 - INFO - joeynmt.training - Epoch  10, Step:    25100, Batch Loss:     2.094977, Tokens per Sec:    20721, Lr: 0.000300\n",
            "2021-05-05 15:16:02,816 - INFO - joeynmt.training - Epoch  10, Step:    25200, Batch Loss:     2.310442, Tokens per Sec:    20707, Lr: 0.000300\n",
            "2021-05-05 15:16:07,914 - INFO - joeynmt.training - Epoch  10: total training loss 5485.26\n",
            "2021-05-05 15:16:07,914 - INFO - joeynmt.training - EPOCH 11\n",
            "2021-05-05 15:16:13,213 - INFO - joeynmt.training - Epoch  11, Step:    25300, Batch Loss:     2.128777, Tokens per Sec:    19273, Lr: 0.000300\n",
            "2021-05-05 15:16:23,429 - INFO - joeynmt.training - Epoch  11, Step:    25400, Batch Loss:     2.209286, Tokens per Sec:    20465, Lr: 0.000300\n",
            "2021-05-05 15:16:33,558 - INFO - joeynmt.training - Epoch  11, Step:    25500, Batch Loss:     2.479450, Tokens per Sec:    20953, Lr: 0.000300\n",
            "2021-05-05 15:16:43,801 - INFO - joeynmt.training - Epoch  11, Step:    25600, Batch Loss:     2.217427, Tokens per Sec:    21009, Lr: 0.000300\n",
            "2021-05-05 15:16:54,014 - INFO - joeynmt.training - Epoch  11, Step:    25700, Batch Loss:     2.130921, Tokens per Sec:    20794, Lr: 0.000300\n",
            "2021-05-05 15:17:04,113 - INFO - joeynmt.training - Epoch  11, Step:    25800, Batch Loss:     1.919772, Tokens per Sec:    20164, Lr: 0.000300\n",
            "2021-05-05 15:17:14,217 - INFO - joeynmt.training - Epoch  11, Step:    25900, Batch Loss:     2.131867, Tokens per Sec:    20581, Lr: 0.000300\n",
            "2021-05-05 15:17:24,359 - INFO - joeynmt.training - Epoch  11, Step:    26000, Batch Loss:     2.168873, Tokens per Sec:    20666, Lr: 0.000300\n",
            "2021-05-05 15:17:36,573 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:17:36,573 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:17:36,573 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:17:36,800 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:17:36,800 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:17:37,175 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:17:37,175 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:17:37,175 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:17:37,175 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:17:37,175 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:17:37,175 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:17:37,175 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:17:37,175 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope to see his children .\n",
            "2021-05-05 15:17:37,176 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:17:37,176 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:17:37,176 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:17:37,176 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this is why the government of the world government cannot bring the end of the sexual immorality and the disaster .\n",
            "2021-05-05 15:17:37,176 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:17:37,176 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:17:37,176 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:17:37,176 - INFO - joeynmt.training - \tHypothesis: In chapter 7 , Paul explained the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:17:37,176 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    26000: bleu:  24.33, loss: 47966.6016, ppl:   6.8619, duration: 12.8165s\n",
            "2021-05-05 15:17:47,438 - INFO - joeynmt.training - Epoch  11, Step:    26100, Batch Loss:     2.204619, Tokens per Sec:    20685, Lr: 0.000300\n",
            "2021-05-05 15:17:57,595 - INFO - joeynmt.training - Epoch  11, Step:    26200, Batch Loss:     1.993731, Tokens per Sec:    20805, Lr: 0.000300\n",
            "2021-05-05 15:18:07,758 - INFO - joeynmt.training - Epoch  11, Step:    26300, Batch Loss:     2.120211, Tokens per Sec:    20432, Lr: 0.000300\n",
            "2021-05-05 15:18:17,916 - INFO - joeynmt.training - Epoch  11, Step:    26400, Batch Loss:     2.013277, Tokens per Sec:    20706, Lr: 0.000300\n",
            "2021-05-05 15:18:27,959 - INFO - joeynmt.training - Epoch  11, Step:    26500, Batch Loss:     1.990066, Tokens per Sec:    20069, Lr: 0.000300\n",
            "2021-05-05 15:18:38,065 - INFO - joeynmt.training - Epoch  11, Step:    26600, Batch Loss:     2.864516, Tokens per Sec:    20348, Lr: 0.000300\n",
            "2021-05-05 15:18:48,192 - INFO - joeynmt.training - Epoch  11, Step:    26700, Batch Loss:     1.748297, Tokens per Sec:    20369, Lr: 0.000300\n",
            "2021-05-05 15:18:58,325 - INFO - joeynmt.training - Epoch  11, Step:    26800, Batch Loss:     2.183895, Tokens per Sec:    20325, Lr: 0.000300\n",
            "2021-05-05 15:19:08,514 - INFO - joeynmt.training - Epoch  11, Step:    26900, Batch Loss:     2.193323, Tokens per Sec:    20498, Lr: 0.000300\n",
            "2021-05-05 15:19:18,823 - INFO - joeynmt.training - Epoch  11, Step:    27000, Batch Loss:     2.322568, Tokens per Sec:    20973, Lr: 0.000300\n",
            "2021-05-05 15:19:31,151 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:19:31,151 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:19:31,151 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:19:31,382 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:19:31,382 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:19:31,756 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:19:31,756 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:19:31,756 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:19:31,756 - INFO - joeynmt.training - \tHypothesis: And they will find security for following Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:19:31,756 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:19:31,757 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:19:31,757 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:19:31,757 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 15:19:31,757 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:19:31,757 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:19:31,757 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:19:31,757 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this is why the government of the world governments cannot bring the end of the sexual immorality and the sort of distress .\n",
            "2021-05-05 15:19:31,757 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:19:31,757 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:19:31,757 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:19:31,758 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:19:31,758 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    27000: bleu:  24.64, loss: 47488.1172, ppl:   6.7313, duration: 12.9345s\n",
            "2021-05-05 15:19:41,976 - INFO - joeynmt.training - Epoch  11, Step:    27100, Batch Loss:     2.076771, Tokens per Sec:    20759, Lr: 0.000300\n",
            "2021-05-05 15:19:52,174 - INFO - joeynmt.training - Epoch  11, Step:    27200, Batch Loss:     2.116742, Tokens per Sec:    20474, Lr: 0.000300\n",
            "2021-05-05 15:20:02,429 - INFO - joeynmt.training - Epoch  11, Step:    27300, Batch Loss:     2.249727, Tokens per Sec:    20808, Lr: 0.000300\n",
            "2021-05-05 15:20:12,640 - INFO - joeynmt.training - Epoch  11, Step:    27400, Batch Loss:     1.903233, Tokens per Sec:    20630, Lr: 0.000300\n",
            "2021-05-05 15:20:22,948 - INFO - joeynmt.training - Epoch  11, Step:    27500, Batch Loss:     2.176923, Tokens per Sec:    21201, Lr: 0.000300\n",
            "2021-05-05 15:20:33,186 - INFO - joeynmt.training - Epoch  11, Step:    27600, Batch Loss:     2.082209, Tokens per Sec:    20730, Lr: 0.000300\n",
            "2021-05-05 15:20:43,382 - INFO - joeynmt.training - Epoch  11, Step:    27700, Batch Loss:     1.868185, Tokens per Sec:    20903, Lr: 0.000300\n",
            "2021-05-05 15:20:51,084 - INFO - joeynmt.training - Epoch  11: total training loss 5384.73\n",
            "2021-05-05 15:20:51,084 - INFO - joeynmt.training - EPOCH 12\n",
            "2021-05-05 15:20:53,951 - INFO - joeynmt.training - Epoch  12, Step:    27800, Batch Loss:     2.003284, Tokens per Sec:    18944, Lr: 0.000300\n",
            "2021-05-05 15:21:04,084 - INFO - joeynmt.training - Epoch  12, Step:    27900, Batch Loss:     2.279544, Tokens per Sec:    20152, Lr: 0.000300\n",
            "2021-05-05 15:21:14,185 - INFO - joeynmt.training - Epoch  12, Step:    28000, Batch Loss:     2.362531, Tokens per Sec:    20563, Lr: 0.000300\n",
            "2021-05-05 15:21:25,621 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:21:25,622 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:21:25,622 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:21:25,855 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:21:25,855 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:21:26,242 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:21:26,243 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:21:26,243 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:21:26,243 - INFO - joeynmt.training - \tHypothesis: They will also find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:21:26,243 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:21:26,243 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:21:26,243 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:21:26,243 - INFO - joeynmt.training - \tHypothesis: Jehovah has the prospect of reaching his children .\n",
            "2021-05-05 15:21:26,243 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:21:26,243 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:21:26,243 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:21:26,244 - INFO - joeynmt.training - \tHypothesis: The Egyptians realized that this is why the government of the world governments cannot bring the end of the sexual immorality and distress .\n",
            "2021-05-05 15:21:26,244 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:21:26,244 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:21:26,244 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:21:26,244 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:21:26,244 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    28000: bleu:  24.77, loss: 47183.8359, ppl:   6.6496, duration: 12.0582s\n",
            "2021-05-05 15:21:36,477 - INFO - joeynmt.training - Epoch  12, Step:    28100, Batch Loss:     2.183773, Tokens per Sec:    21042, Lr: 0.000300\n",
            "2021-05-05 15:21:46,689 - INFO - joeynmt.training - Epoch  12, Step:    28200, Batch Loss:     1.992308, Tokens per Sec:    20668, Lr: 0.000300\n",
            "2021-05-05 15:21:56,910 - INFO - joeynmt.training - Epoch  12, Step:    28300, Batch Loss:     2.095957, Tokens per Sec:    20692, Lr: 0.000300\n",
            "2021-05-05 15:22:07,060 - INFO - joeynmt.training - Epoch  12, Step:    28400, Batch Loss:     1.745573, Tokens per Sec:    21045, Lr: 0.000300\n",
            "2021-05-05 15:22:17,082 - INFO - joeynmt.training - Epoch  12, Step:    28500, Batch Loss:     2.290831, Tokens per Sec:    20170, Lr: 0.000300\n",
            "2021-05-05 15:22:27,313 - INFO - joeynmt.training - Epoch  12, Step:    28600, Batch Loss:     2.098658, Tokens per Sec:    20795, Lr: 0.000300\n",
            "2021-05-05 15:22:37,526 - INFO - joeynmt.training - Epoch  12, Step:    28700, Batch Loss:     1.896962, Tokens per Sec:    20429, Lr: 0.000300\n",
            "2021-05-05 15:22:47,629 - INFO - joeynmt.training - Epoch  12, Step:    28800, Batch Loss:     2.069053, Tokens per Sec:    20673, Lr: 0.000300\n",
            "2021-05-05 15:22:57,810 - INFO - joeynmt.training - Epoch  12, Step:    28900, Batch Loss:     1.976696, Tokens per Sec:    20975, Lr: 0.000300\n",
            "2021-05-05 15:23:07,923 - INFO - joeynmt.training - Epoch  12, Step:    29000, Batch Loss:     2.117199, Tokens per Sec:    20645, Lr: 0.000300\n",
            "2021-05-05 15:23:20,748 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:23:20,748 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:23:20,748 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:23:20,978 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:23:20,978 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:23:21,367 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:23:21,367 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:23:21,367 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:23:21,367 - INFO - joeynmt.training - \tHypothesis: They will also find security for following Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:23:21,367 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:23:21,368 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:23:21,368 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:23:21,368 - INFO - joeynmt.training - \tHypothesis: Jehovah has the prospect to see his children .\n",
            "2021-05-05 15:23:21,368 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:23:21,368 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:23:21,368 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:23:21,368 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this is why the government of the world government cannot bring the end of the sexual immorality and distractions .\n",
            "2021-05-05 15:23:21,368 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:23:21,368 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:23:21,368 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:23:21,369 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:23:21,369 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    29000: bleu:  25.22, loss: 46732.7461, ppl:   6.5302, duration: 13.4453s\n",
            "2021-05-05 15:23:31,483 - INFO - joeynmt.training - Epoch  12, Step:    29100, Batch Loss:     2.139340, Tokens per Sec:    20478, Lr: 0.000300\n",
            "2021-05-05 15:23:41,771 - INFO - joeynmt.training - Epoch  12, Step:    29200, Batch Loss:     2.207575, Tokens per Sec:    20959, Lr: 0.000300\n",
            "2021-05-05 15:23:51,816 - INFO - joeynmt.training - Epoch  12, Step:    29300, Batch Loss:     2.035972, Tokens per Sec:    20450, Lr: 0.000300\n",
            "2021-05-05 15:24:01,935 - INFO - joeynmt.training - Epoch  12, Step:    29400, Batch Loss:     2.104605, Tokens per Sec:    20527, Lr: 0.000300\n",
            "2021-05-05 15:24:12,172 - INFO - joeynmt.training - Epoch  12, Step:    29500, Batch Loss:     2.000288, Tokens per Sec:    20898, Lr: 0.000300\n",
            "2021-05-05 15:24:22,299 - INFO - joeynmt.training - Epoch  12, Step:    29600, Batch Loss:     2.110698, Tokens per Sec:    20515, Lr: 0.000300\n",
            "2021-05-05 15:24:32,502 - INFO - joeynmt.training - Epoch  12, Step:    29700, Batch Loss:     2.199560, Tokens per Sec:    20863, Lr: 0.000300\n",
            "2021-05-05 15:24:42,699 - INFO - joeynmt.training - Epoch  12, Step:    29800, Batch Loss:     2.011193, Tokens per Sec:    20427, Lr: 0.000300\n",
            "2021-05-05 15:24:52,882 - INFO - joeynmt.training - Epoch  12, Step:    29900, Batch Loss:     2.321497, Tokens per Sec:    20997, Lr: 0.000300\n",
            "2021-05-05 15:25:03,099 - INFO - joeynmt.training - Epoch  12, Step:    30000, Batch Loss:     2.045542, Tokens per Sec:    20695, Lr: 0.000300\n",
            "2021-05-05 15:25:15,577 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:25:15,577 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:25:15,577 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:25:15,806 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:25:15,806 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:25:16,191 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:25:16,192 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:25:16,192 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:25:16,192 - INFO - joeynmt.training - \tHypothesis: And they will have a security to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:25:16,192 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:25:16,192 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:25:16,192 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:25:16,192 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope to see his children .\n",
            "2021-05-05 15:25:16,192 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:25:16,192 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:25:16,192 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:25:16,192 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this is why the government of the world cannot bring the end of the sexual immorality and the disaster .\n",
            "2021-05-05 15:25:16,193 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:25:16,193 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:25:16,193 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:25:16,193 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:25:16,193 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    30000: bleu:  25.30, loss: 46699.3008, ppl:   6.5215, duration: 13.0930s\n",
            "2021-05-05 15:25:26,355 - INFO - joeynmt.training - Epoch  12, Step:    30100, Batch Loss:     2.173098, Tokens per Sec:    20229, Lr: 0.000300\n",
            "2021-05-05 15:25:36,540 - INFO - joeynmt.training - Epoch  12, Step:    30200, Batch Loss:     2.145588, Tokens per Sec:    20619, Lr: 0.000300\n",
            "2021-05-05 15:25:46,672 - INFO - joeynmt.training - Epoch  12, Step:    30300, Batch Loss:     1.691286, Tokens per Sec:    20777, Lr: 0.000300\n",
            "2021-05-05 15:25:47,000 - INFO - joeynmt.training - Epoch  12: total training loss 5296.22\n",
            "2021-05-05 15:25:47,000 - INFO - joeynmt.training - EPOCH 13\n",
            "2021-05-05 15:25:57,123 - INFO - joeynmt.training - Epoch  13, Step:    30400, Batch Loss:     2.210616, Tokens per Sec:    19920, Lr: 0.000300\n",
            "2021-05-05 15:26:07,238 - INFO - joeynmt.training - Epoch  13, Step:    30500, Batch Loss:     1.962196, Tokens per Sec:    20478, Lr: 0.000300\n",
            "2021-05-05 15:26:17,376 - INFO - joeynmt.training - Epoch  13, Step:    30600, Batch Loss:     2.010484, Tokens per Sec:    20545, Lr: 0.000300\n",
            "2021-05-05 15:26:27,551 - INFO - joeynmt.training - Epoch  13, Step:    30700, Batch Loss:     1.998773, Tokens per Sec:    20379, Lr: 0.000300\n",
            "2021-05-05 15:26:37,646 - INFO - joeynmt.training - Epoch  13, Step:    30800, Batch Loss:     2.069238, Tokens per Sec:    19981, Lr: 0.000300\n",
            "2021-05-05 15:26:47,877 - INFO - joeynmt.training - Epoch  13, Step:    30900, Batch Loss:     1.492253, Tokens per Sec:    20977, Lr: 0.000300\n",
            "2021-05-05 15:26:57,980 - INFO - joeynmt.training - Epoch  13, Step:    31000, Batch Loss:     2.213833, Tokens per Sec:    20630, Lr: 0.000300\n",
            "2021-05-05 15:27:11,362 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:27:11,362 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:27:11,362 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:27:11,591 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:27:11,591 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:27:11,961 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:27:11,961 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:27:11,961 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:27:11,962 - INFO - joeynmt.training - \tHypothesis: And they will find security for following Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:27:11,962 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:27:11,962 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:27:11,962 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:27:11,962 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 15:27:11,962 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:27:11,962 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:27:11,962 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:27:11,962 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this is why the government of the world cannot bring the end of the sexual immorality and the entertainment .\n",
            "2021-05-05 15:27:11,962 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:27:11,962 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:27:11,962 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:27:11,963 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:27:11,963 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    31000: bleu:  25.41, loss: 46287.3555, ppl:   6.4145, duration: 13.9820s\n",
            "2021-05-05 15:27:22,192 - INFO - joeynmt.training - Epoch  13, Step:    31100, Batch Loss:     2.129187, Tokens per Sec:    20930, Lr: 0.000300\n",
            "2021-05-05 15:27:32,412 - INFO - joeynmt.training - Epoch  13, Step:    31200, Batch Loss:     2.025320, Tokens per Sec:    20523, Lr: 0.000300\n",
            "2021-05-05 15:27:42,685 - INFO - joeynmt.training - Epoch  13, Step:    31300, Batch Loss:     2.099583, Tokens per Sec:    21240, Lr: 0.000300\n",
            "2021-05-05 15:27:52,879 - INFO - joeynmt.training - Epoch  13, Step:    31400, Batch Loss:     2.056799, Tokens per Sec:    20651, Lr: 0.000300\n",
            "2021-05-05 15:28:03,134 - INFO - joeynmt.training - Epoch  13, Step:    31500, Batch Loss:     2.162569, Tokens per Sec:    20944, Lr: 0.000300\n",
            "2021-05-05 15:28:13,363 - INFO - joeynmt.training - Epoch  13, Step:    31600, Batch Loss:     2.123505, Tokens per Sec:    21057, Lr: 0.000300\n",
            "2021-05-05 15:28:23,381 - INFO - joeynmt.training - Epoch  13, Step:    31700, Batch Loss:     2.050752, Tokens per Sec:    20489, Lr: 0.000300\n",
            "2021-05-05 15:28:33,596 - INFO - joeynmt.training - Epoch  13, Step:    31800, Batch Loss:     1.867346, Tokens per Sec:    20294, Lr: 0.000300\n",
            "2021-05-05 15:28:43,790 - INFO - joeynmt.training - Epoch  13, Step:    31900, Batch Loss:     2.098445, Tokens per Sec:    20669, Lr: 0.000300\n",
            "2021-05-05 15:28:53,898 - INFO - joeynmt.training - Epoch  13, Step:    32000, Batch Loss:     2.285930, Tokens per Sec:    20547, Lr: 0.000300\n",
            "2021-05-05 15:29:07,952 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:29:07,953 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:29:07,953 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:29:08,183 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:29:08,183 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:29:08,533 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:29:08,533 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:29:08,533 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:29:08,533 - INFO - joeynmt.training - \tHypothesis: And they will find security in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:29:08,534 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:29:08,534 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:29:08,534 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:29:08,534 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 15:29:08,534 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:29:08,534 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:29:08,534 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:29:08,534 - INFO - joeynmt.training - \tHypothesis: The Egyptians realized that this is why the government of the world cannot bring the end of the corruption and disturbed .\n",
            "2021-05-05 15:29:08,534 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:29:08,535 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:29:08,535 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:29:08,535 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:29:08,535 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    32000: bleu:  25.79, loss: 46124.1211, ppl:   6.3726, duration: 14.6361s\n",
            "2021-05-05 15:29:18,794 - INFO - joeynmt.training - Epoch  13, Step:    32100, Batch Loss:     2.052707, Tokens per Sec:    20212, Lr: 0.000300\n",
            "2021-05-05 15:29:29,140 - INFO - joeynmt.training - Epoch  13, Step:    32200, Batch Loss:     1.785654, Tokens per Sec:    20677, Lr: 0.000300\n",
            "2021-05-05 15:29:39,410 - INFO - joeynmt.training - Epoch  13, Step:    32300, Batch Loss:     2.158499, Tokens per Sec:    20704, Lr: 0.000300\n",
            "2021-05-05 15:29:49,679 - INFO - joeynmt.training - Epoch  13, Step:    32400, Batch Loss:     1.684513, Tokens per Sec:    20522, Lr: 0.000300\n",
            "2021-05-05 15:29:59,948 - INFO - joeynmt.training - Epoch  13, Step:    32500, Batch Loss:     2.056143, Tokens per Sec:    20625, Lr: 0.000300\n",
            "2021-05-05 15:30:10,108 - INFO - joeynmt.training - Epoch  13, Step:    32600, Batch Loss:     2.201648, Tokens per Sec:    20514, Lr: 0.000300\n",
            "2021-05-05 15:30:20,393 - INFO - joeynmt.training - Epoch  13, Step:    32700, Batch Loss:     2.209119, Tokens per Sec:    20759, Lr: 0.000300\n",
            "2021-05-05 15:30:30,497 - INFO - joeynmt.training - Epoch  13, Step:    32800, Batch Loss:     2.066471, Tokens per Sec:    20539, Lr: 0.000300\n",
            "2021-05-05 15:30:33,340 - INFO - joeynmt.training - Epoch  13: total training loss 5210.63\n",
            "2021-05-05 15:30:33,340 - INFO - joeynmt.training - EPOCH 14\n",
            "2021-05-05 15:30:41,116 - INFO - joeynmt.training - Epoch  14, Step:    32900, Batch Loss:     2.046525, Tokens per Sec:    19884, Lr: 0.000300\n",
            "2021-05-05 15:30:51,405 - INFO - joeynmt.training - Epoch  14, Step:    33000, Batch Loss:     2.181381, Tokens per Sec:    21210, Lr: 0.000300\n",
            "2021-05-05 15:31:06,514 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:31:06,514 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:31:06,514 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:31:06,745 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:31:06,746 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:31:07,137 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:31:07,137 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:31:07,137 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:31:07,137 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:31:07,137 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:31:07,137 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:31:07,137 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:31:07,138 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope to see his children .\n",
            "2021-05-05 15:31:07,138 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:31:07,138 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:31:07,138 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:31:07,138 - INFO - joeynmt.training - \tHypothesis: The Egyptians realized that this is why the government of the world cannot bring the end of the corruption and the distortion of the world .\n",
            "2021-05-05 15:31:07,138 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:31:07,138 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:31:07,138 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:31:07,138 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul explained the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:31:07,138 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    33000: bleu:  25.53, loss: 45938.1016, ppl:   6.3251, duration: 15.7334s\n",
            "2021-05-05 15:31:17,307 - INFO - joeynmt.training - Epoch  14, Step:    33100, Batch Loss:     2.512331, Tokens per Sec:    20570, Lr: 0.000300\n",
            "2021-05-05 15:31:27,483 - INFO - joeynmt.training - Epoch  14, Step:    33200, Batch Loss:     2.216143, Tokens per Sec:    20715, Lr: 0.000300\n",
            "2021-05-05 15:31:37,635 - INFO - joeynmt.training - Epoch  14, Step:    33300, Batch Loss:     1.905010, Tokens per Sec:    20427, Lr: 0.000300\n",
            "2021-05-05 15:31:47,668 - INFO - joeynmt.training - Epoch  14, Step:    33400, Batch Loss:     2.001669, Tokens per Sec:    20162, Lr: 0.000300\n",
            "2021-05-05 15:31:57,846 - INFO - joeynmt.training - Epoch  14, Step:    33500, Batch Loss:     2.195112, Tokens per Sec:    20691, Lr: 0.000300\n",
            "2021-05-05 15:32:07,950 - INFO - joeynmt.training - Epoch  14, Step:    33600, Batch Loss:     1.845354, Tokens per Sec:    20278, Lr: 0.000300\n",
            "2021-05-05 15:32:18,095 - INFO - joeynmt.training - Epoch  14, Step:    33700, Batch Loss:     2.095777, Tokens per Sec:    20590, Lr: 0.000300\n",
            "2021-05-05 15:32:28,328 - INFO - joeynmt.training - Epoch  14, Step:    33800, Batch Loss:     1.910983, Tokens per Sec:    20737, Lr: 0.000300\n",
            "2021-05-05 15:32:38,615 - INFO - joeynmt.training - Epoch  14, Step:    33900, Batch Loss:     2.098912, Tokens per Sec:    20696, Lr: 0.000300\n",
            "2021-05-05 15:32:48,779 - INFO - joeynmt.training - Epoch  14, Step:    34000, Batch Loss:     2.151536, Tokens per Sec:    20785, Lr: 0.000300\n",
            "2021-05-05 15:33:01,423 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:33:01,424 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:33:01,424 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:33:01,652 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:33:01,652 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:33:02,027 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:33:02,027 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:33:02,027 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:33:02,027 - INFO - joeynmt.training - \tHypothesis: And they will find security to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:33:02,027 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:33:02,028 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:33:02,028 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:33:02,028 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope to see his children .\n",
            "2021-05-05 15:33:02,028 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:33:02,028 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:33:02,028 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:33:02,028 - INFO - joeynmt.training - \tHypothesis: The Egyptians recognized that this is why the government of the world cannot bring the end of the corruption and the deception .\n",
            "2021-05-05 15:33:02,028 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:33:02,028 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:33:02,029 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:33:02,029 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:33:02,029 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    34000: bleu:  25.62, loss: 45809.9961, ppl:   6.2927, duration: 13.2490s\n",
            "2021-05-05 15:33:12,084 - INFO - joeynmt.training - Epoch  14, Step:    34100, Batch Loss:     2.053606, Tokens per Sec:    20660, Lr: 0.000300\n",
            "2021-05-05 15:33:22,284 - INFO - joeynmt.training - Epoch  14, Step:    34200, Batch Loss:     2.191331, Tokens per Sec:    20716, Lr: 0.000300\n",
            "2021-05-05 15:33:32,561 - INFO - joeynmt.training - Epoch  14, Step:    34300, Batch Loss:     2.069368, Tokens per Sec:    20947, Lr: 0.000300\n",
            "2021-05-05 15:33:42,753 - INFO - joeynmt.training - Epoch  14, Step:    34400, Batch Loss:     2.008122, Tokens per Sec:    20388, Lr: 0.000300\n",
            "2021-05-05 15:33:52,945 - INFO - joeynmt.training - Epoch  14, Step:    34500, Batch Loss:     1.748134, Tokens per Sec:    20975, Lr: 0.000300\n",
            "2021-05-05 15:34:03,193 - INFO - joeynmt.training - Epoch  14, Step:    34600, Batch Loss:     1.904870, Tokens per Sec:    20901, Lr: 0.000300\n",
            "2021-05-05 15:34:13,348 - INFO - joeynmt.training - Epoch  14, Step:    34700, Batch Loss:     1.814098, Tokens per Sec:    20513, Lr: 0.000300\n",
            "2021-05-05 15:34:23,408 - INFO - joeynmt.training - Epoch  14, Step:    34800, Batch Loss:     2.123799, Tokens per Sec:    20293, Lr: 0.000300\n",
            "2021-05-05 15:34:33,725 - INFO - joeynmt.training - Epoch  14, Step:    34900, Batch Loss:     2.047039, Tokens per Sec:    21151, Lr: 0.000300\n",
            "2021-05-05 15:34:43,872 - INFO - joeynmt.training - Epoch  14, Step:    35000, Batch Loss:     1.719931, Tokens per Sec:    20455, Lr: 0.000300\n",
            "2021-05-05 15:34:53,903 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:34:53,903 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:34:53,904 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:34:54,134 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:34:54,134 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:34:54,523 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:34:54,523 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:34:54,523 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:34:54,523 - INFO - joeynmt.training - \tHypothesis: And they will be security for following Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:34:54,523 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:34:54,523 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:34:54,523 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:34:54,524 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope to see his children again .\n",
            "2021-05-05 15:34:54,524 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:34:54,524 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:34:54,524 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:34:54,524 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this is why the world governments cannot bring the end of the harmful and distress .\n",
            "2021-05-05 15:34:54,524 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:34:54,524 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:34:54,524 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:34:54,524 - INFO - joeynmt.training - \tHypothesis: In chapter 7 , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:34:54,524 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    35000: bleu:  25.74, loss: 45435.4062, ppl:   6.1988, duration: 10.6521s\n",
            "2021-05-05 15:35:04,658 - INFO - joeynmt.training - Epoch  14, Step:    35100, Batch Loss:     2.015966, Tokens per Sec:    20263, Lr: 0.000300\n",
            "2021-05-05 15:35:14,803 - INFO - joeynmt.training - Epoch  14, Step:    35200, Batch Loss:     1.602262, Tokens per Sec:    20573, Lr: 0.000300\n",
            "2021-05-05 15:35:25,071 - INFO - joeynmt.training - Epoch  14, Step:    35300, Batch Loss:     2.099957, Tokens per Sec:    21089, Lr: 0.000300\n",
            "2021-05-05 15:35:30,177 - INFO - joeynmt.training - Epoch  14: total training loss 5142.01\n",
            "2021-05-05 15:35:30,177 - INFO - joeynmt.training - EPOCH 15\n",
            "2021-05-05 15:35:35,619 - INFO - joeynmt.training - Epoch  15, Step:    35400, Batch Loss:     1.985455, Tokens per Sec:    19216, Lr: 0.000300\n",
            "2021-05-05 15:35:45,756 - INFO - joeynmt.training - Epoch  15, Step:    35500, Batch Loss:     1.964110, Tokens per Sec:    21033, Lr: 0.000300\n",
            "2021-05-05 15:35:55,912 - INFO - joeynmt.training - Epoch  15, Step:    35600, Batch Loss:     2.066253, Tokens per Sec:    20445, Lr: 0.000300\n",
            "2021-05-05 15:36:06,081 - INFO - joeynmt.training - Epoch  15, Step:    35700, Batch Loss:     2.030159, Tokens per Sec:    20870, Lr: 0.000300\n",
            "2021-05-05 15:36:16,301 - INFO - joeynmt.training - Epoch  15, Step:    35800, Batch Loss:     2.229966, Tokens per Sec:    20764, Lr: 0.000300\n",
            "2021-05-05 15:36:26,497 - INFO - joeynmt.training - Epoch  15, Step:    35900, Batch Loss:     2.042396, Tokens per Sec:    20520, Lr: 0.000300\n",
            "2021-05-05 15:36:36,733 - INFO - joeynmt.training - Epoch  15, Step:    36000, Batch Loss:     2.060270, Tokens per Sec:    20688, Lr: 0.000300\n",
            "2021-05-05 15:36:47,155 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:36:47,155 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:36:47,155 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:36:47,379 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:36:47,379 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:36:47,745 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:36:47,745 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:36:47,745 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:36:47,745 - INFO - joeynmt.training - \tHypothesis: And they will be secure in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:36:47,746 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:36:47,746 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:36:47,746 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:36:47,746 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope to see his children .\n",
            "2021-05-05 15:36:47,746 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:36:47,746 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:36:47,746 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:36:47,746 - INFO - joeynmt.training - \tHypothesis: The Egyptians recognized that this is why the world governments cannot bring the end of the sexual immorality .\n",
            "2021-05-05 15:36:47,746 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:36:47,747 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:36:47,747 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:36:47,747 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of the Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:36:47,747 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    36000: bleu:  25.98, loss: 45297.3477, ppl:   6.1645, duration: 11.0137s\n",
            "2021-05-05 15:36:57,874 - INFO - joeynmt.training - Epoch  15, Step:    36100, Batch Loss:     1.606914, Tokens per Sec:    20817, Lr: 0.000300\n",
            "2021-05-05 15:37:08,022 - INFO - joeynmt.training - Epoch  15, Step:    36200, Batch Loss:     2.169239, Tokens per Sec:    20918, Lr: 0.000300\n",
            "2021-05-05 15:37:18,168 - INFO - joeynmt.training - Epoch  15, Step:    36300, Batch Loss:     2.014823, Tokens per Sec:    20614, Lr: 0.000300\n",
            "2021-05-05 15:37:28,339 - INFO - joeynmt.training - Epoch  15, Step:    36400, Batch Loss:     2.032017, Tokens per Sec:    20672, Lr: 0.000300\n",
            "2021-05-05 15:37:38,584 - INFO - joeynmt.training - Epoch  15, Step:    36500, Batch Loss:     2.200186, Tokens per Sec:    20851, Lr: 0.000300\n",
            "2021-05-05 15:37:48,757 - INFO - joeynmt.training - Epoch  15, Step:    36600, Batch Loss:     2.052533, Tokens per Sec:    20329, Lr: 0.000300\n",
            "2021-05-05 15:37:58,996 - INFO - joeynmt.training - Epoch  15, Step:    36700, Batch Loss:     2.192648, Tokens per Sec:    20481, Lr: 0.000300\n",
            "2021-05-05 15:38:09,111 - INFO - joeynmt.training - Epoch  15, Step:    36800, Batch Loss:     1.952217, Tokens per Sec:    20087, Lr: 0.000300\n",
            "2021-05-05 15:38:19,303 - INFO - joeynmt.training - Epoch  15, Step:    36900, Batch Loss:     2.218196, Tokens per Sec:    20542, Lr: 0.000300\n",
            "2021-05-05 15:38:29,492 - INFO - joeynmt.training - Epoch  15, Step:    37000, Batch Loss:     2.141462, Tokens per Sec:    20904, Lr: 0.000300\n",
            "2021-05-05 15:38:39,157 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:38:39,157 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:38:39,157 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:38:39,388 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:38:39,389 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:38:39,781 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:38:39,782 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:38:39,782 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:38:39,782 - INFO - joeynmt.training - \tHypothesis: And they will find security in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:38:39,782 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:38:39,782 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:38:39,782 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:38:39,782 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope to see his children .\n",
            "2021-05-05 15:38:39,782 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:38:39,782 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:38:39,782 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:38:39,782 - INFO - joeynmt.training - \tHypothesis: The Egyptians recognize that this is why the world governments cannot bring the end of the corruption and distress .\n",
            "2021-05-05 15:38:39,783 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:38:39,783 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:38:39,783 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:38:39,783 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:38:39,783 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    37000: bleu:  25.98, loss: 45123.2383, ppl:   6.1215, duration: 10.2907s\n",
            "2021-05-05 15:38:49,871 - INFO - joeynmt.training - Epoch  15, Step:    37100, Batch Loss:     1.559484, Tokens per Sec:    20226, Lr: 0.000300\n",
            "2021-05-05 15:39:00,119 - INFO - joeynmt.training - Epoch  15, Step:    37200, Batch Loss:     2.084576, Tokens per Sec:    21030, Lr: 0.000300\n",
            "2021-05-05 15:39:10,357 - INFO - joeynmt.training - Epoch  15, Step:    37300, Batch Loss:     1.965484, Tokens per Sec:    21123, Lr: 0.000300\n",
            "2021-05-05 15:39:20,456 - INFO - joeynmt.training - Epoch  15, Step:    37400, Batch Loss:     2.075130, Tokens per Sec:    20419, Lr: 0.000300\n",
            "2021-05-05 15:39:30,691 - INFO - joeynmt.training - Epoch  15, Step:    37500, Batch Loss:     2.075301, Tokens per Sec:    21065, Lr: 0.000300\n",
            "2021-05-05 15:39:40,907 - INFO - joeynmt.training - Epoch  15, Step:    37600, Batch Loss:     2.146127, Tokens per Sec:    20854, Lr: 0.000300\n",
            "2021-05-05 15:39:51,124 - INFO - joeynmt.training - Epoch  15, Step:    37700, Batch Loss:     2.016732, Tokens per Sec:    20766, Lr: 0.000300\n",
            "2021-05-05 15:40:01,279 - INFO - joeynmt.training - Epoch  15, Step:    37800, Batch Loss:     1.875584, Tokens per Sec:    20422, Lr: 0.000300\n",
            "2021-05-05 15:40:08,571 - INFO - joeynmt.training - Epoch  15: total training loss 5077.71\n",
            "2021-05-05 15:40:08,571 - INFO - joeynmt.training - EPOCH 16\n",
            "2021-05-05 15:40:11,796 - INFO - joeynmt.training - Epoch  16, Step:    37900, Batch Loss:     1.967384, Tokens per Sec:    19110, Lr: 0.000300\n",
            "2021-05-05 15:40:21,991 - INFO - joeynmt.training - Epoch  16, Step:    38000, Batch Loss:     1.849451, Tokens per Sec:    20704, Lr: 0.000300\n",
            "2021-05-05 15:40:34,061 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:40:34,061 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:40:34,062 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:40:34,288 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:40:34,288 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:40:34,667 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:40:34,668 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:40:34,668 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:40:34,668 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to apply Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:40:34,668 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:40:34,668 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:40:34,668 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:40:34,668 - INFO - joeynmt.training - \tHypothesis: Jehovah has the prospect of returning to his children .\n",
            "2021-05-05 15:40:34,668 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:40:34,668 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:40:34,669 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:40:34,669 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this is why the world governments cannot bring the end of the corruption and the corruption .\n",
            "2021-05-05 15:40:34,669 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:40:34,669 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:40:34,669 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:40:34,669 - INFO - joeynmt.training - \tHypothesis: In chapter 7 , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:40:34,669 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    38000: bleu:  26.35, loss: 44857.5586, ppl:   6.0566, duration: 12.6781s\n",
            "2021-05-05 15:40:44,837 - INFO - joeynmt.training - Epoch  16, Step:    38100, Batch Loss:     1.946476, Tokens per Sec:    20716, Lr: 0.000300\n",
            "2021-05-05 15:40:55,006 - INFO - joeynmt.training - Epoch  16, Step:    38200, Batch Loss:     1.969044, Tokens per Sec:    20774, Lr: 0.000300\n",
            "2021-05-05 15:41:05,221 - INFO - joeynmt.training - Epoch  16, Step:    38300, Batch Loss:     2.003992, Tokens per Sec:    20779, Lr: 0.000300\n",
            "2021-05-05 15:41:15,428 - INFO - joeynmt.training - Epoch  16, Step:    38400, Batch Loss:     2.188446, Tokens per Sec:    20346, Lr: 0.000300\n",
            "2021-05-05 15:41:25,616 - INFO - joeynmt.training - Epoch  16, Step:    38500, Batch Loss:     1.857321, Tokens per Sec:    20916, Lr: 0.000300\n",
            "2021-05-05 15:41:35,674 - INFO - joeynmt.training - Epoch  16, Step:    38600, Batch Loss:     2.163087, Tokens per Sec:    20340, Lr: 0.000300\n",
            "2021-05-05 15:41:45,743 - INFO - joeynmt.training - Epoch  16, Step:    38700, Batch Loss:     1.926603, Tokens per Sec:    20187, Lr: 0.000300\n",
            "2021-05-05 15:41:56,023 - INFO - joeynmt.training - Epoch  16, Step:    38800, Batch Loss:     1.524598, Tokens per Sec:    20918, Lr: 0.000300\n",
            "2021-05-05 15:42:06,209 - INFO - joeynmt.training - Epoch  16, Step:    38900, Batch Loss:     1.903393, Tokens per Sec:    20629, Lr: 0.000300\n",
            "2021-05-05 15:42:16,454 - INFO - joeynmt.training - Epoch  16, Step:    39000, Batch Loss:     2.012220, Tokens per Sec:    20878, Lr: 0.000300\n",
            "2021-05-05 15:42:27,330 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:42:27,330 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:42:27,330 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:42:27,555 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:42:27,556 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:42:27,967 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:42:27,968 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:42:27,968 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:42:27,968 - INFO - joeynmt.training - \tHypothesis: They will also find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:42:27,968 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:42:27,968 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:42:27,968 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:42:27,968 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope to see his children again .\n",
            "2021-05-05 15:42:27,968 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:42:27,968 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:42:27,969 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:42:27,969 - INFO - joeynmt.training - \tHypothesis: The Egyptians realized that this is why the world governments cannot bring the end of the injustice and the deception .\n",
            "2021-05-05 15:42:27,969 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:42:27,969 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:42:27,969 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:42:27,969 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:42:27,969 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    39000: bleu:  26.40, loss: 44583.8047, ppl:   5.9904, duration: 11.5149s\n",
            "2021-05-05 15:42:38,230 - INFO - joeynmt.training - Epoch  16, Step:    39100, Batch Loss:     1.858459, Tokens per Sec:    20522, Lr: 0.000300\n",
            "2021-05-05 15:42:48,345 - INFO - joeynmt.training - Epoch  16, Step:    39200, Batch Loss:     2.134050, Tokens per Sec:    20632, Lr: 0.000300\n",
            "2021-05-05 15:42:58,599 - INFO - joeynmt.training - Epoch  16, Step:    39300, Batch Loss:     2.217319, Tokens per Sec:    20663, Lr: 0.000300\n",
            "2021-05-05 15:43:08,830 - INFO - joeynmt.training - Epoch  16, Step:    39400, Batch Loss:     2.161424, Tokens per Sec:    20898, Lr: 0.000300\n",
            "2021-05-05 15:43:19,014 - INFO - joeynmt.training - Epoch  16, Step:    39500, Batch Loss:     2.024460, Tokens per Sec:    20743, Lr: 0.000300\n",
            "2021-05-05 15:43:29,186 - INFO - joeynmt.training - Epoch  16, Step:    39600, Batch Loss:     1.576363, Tokens per Sec:    20375, Lr: 0.000300\n",
            "2021-05-05 15:43:39,340 - INFO - joeynmt.training - Epoch  16, Step:    39700, Batch Loss:     2.162270, Tokens per Sec:    20353, Lr: 0.000300\n",
            "2021-05-05 15:43:49,540 - INFO - joeynmt.training - Epoch  16, Step:    39800, Batch Loss:     2.025788, Tokens per Sec:    20755, Lr: 0.000300\n",
            "2021-05-05 15:43:59,759 - INFO - joeynmt.training - Epoch  16, Step:    39900, Batch Loss:     1.664825, Tokens per Sec:    20988, Lr: 0.000300\n",
            "2021-05-05 15:44:09,950 - INFO - joeynmt.training - Epoch  16, Step:    40000, Batch Loss:     1.843305, Tokens per Sec:    20983, Lr: 0.000300\n",
            "2021-05-05 15:44:20,717 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:44:20,717 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:44:20,717 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:44:20,946 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:44:20,946 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:44:21,319 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:44:21,319 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:44:21,319 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:44:21,319 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:44:21,319 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:44:21,319 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:44:21,319 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:44:21,319 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope to see his children again .\n",
            "2021-05-05 15:44:21,320 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:44:21,320 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:44:21,320 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:44:21,320 - INFO - joeynmt.training - \tHypothesis: The Egyptians realized that this is why the world governments cannot bring the end of the harm and the corruption .\n",
            "2021-05-05 15:44:21,320 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:44:21,320 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:44:21,320 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:44:21,320 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of the book of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:44:21,320 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    40000: bleu:  26.62, loss: 44459.1641, ppl:   5.9605, duration: 11.3702s\n",
            "2021-05-05 15:44:31,506 - INFO - joeynmt.training - Epoch  16, Step:    40100, Batch Loss:     2.127126, Tokens per Sec:    20888, Lr: 0.000300\n",
            "2021-05-05 15:44:41,749 - INFO - joeynmt.training - Epoch  16, Step:    40200, Batch Loss:     1.983367, Tokens per Sec:    21002, Lr: 0.000300\n",
            "2021-05-05 15:44:51,948 - INFO - joeynmt.training - Epoch  16, Step:    40300, Batch Loss:     1.891163, Tokens per Sec:    20579, Lr: 0.000300\n",
            "2021-05-05 15:45:00,849 - INFO - joeynmt.training - Epoch  16: total training loss 5006.36\n",
            "2021-05-05 15:45:00,850 - INFO - joeynmt.training - EPOCH 17\n",
            "2021-05-05 15:45:02,527 - INFO - joeynmt.training - Epoch  17, Step:    40400, Batch Loss:     2.083379, Tokens per Sec:    16579, Lr: 0.000300\n",
            "2021-05-05 15:45:12,587 - INFO - joeynmt.training - Epoch  17, Step:    40500, Batch Loss:     1.923060, Tokens per Sec:    20306, Lr: 0.000300\n",
            "2021-05-05 15:45:22,752 - INFO - joeynmt.training - Epoch  17, Step:    40600, Batch Loss:     1.846662, Tokens per Sec:    20860, Lr: 0.000300\n",
            "2021-05-05 15:45:32,897 - INFO - joeynmt.training - Epoch  17, Step:    40700, Batch Loss:     2.018114, Tokens per Sec:    20594, Lr: 0.000300\n",
            "2021-05-05 15:45:43,056 - INFO - joeynmt.training - Epoch  17, Step:    40800, Batch Loss:     2.073908, Tokens per Sec:    20453, Lr: 0.000300\n",
            "2021-05-05 15:45:53,226 - INFO - joeynmt.training - Epoch  17, Step:    40900, Batch Loss:     2.040910, Tokens per Sec:    21015, Lr: 0.000300\n",
            "2021-05-05 15:46:03,383 - INFO - joeynmt.training - Epoch  17, Step:    41000, Batch Loss:     1.631164, Tokens per Sec:    20580, Lr: 0.000300\n",
            "2021-05-05 15:46:14,887 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:46:14,887 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:46:14,887 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:46:15,131 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:46:15,131 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:46:15,489 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:46:15,489 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:46:15,489 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:46:15,489 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:46:15,489 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:46:15,490 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:46:15,490 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:46:15,490 - INFO - joeynmt.training - \tHypothesis: Jehovah is the hope of returning to his children .\n",
            "2021-05-05 15:46:15,490 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:46:15,490 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:46:15,490 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:46:15,490 - INFO - joeynmt.training - \tHypothesis: The Egyptians realized that this is why the world government governments cannot end the end of the corruption and corruption .\n",
            "2021-05-05 15:46:15,490 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:46:15,490 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:46:15,490 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:46:15,491 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:46:15,491 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    41000: bleu:  26.41, loss: 44285.7461, ppl:   5.9191, duration: 12.1073s\n",
            "2021-05-05 15:46:25,680 - INFO - joeynmt.training - Epoch  17, Step:    41100, Batch Loss:     1.860434, Tokens per Sec:    20997, Lr: 0.000300\n",
            "2021-05-05 15:46:35,892 - INFO - joeynmt.training - Epoch  17, Step:    41200, Batch Loss:     2.208565, Tokens per Sec:    20665, Lr: 0.000300\n",
            "2021-05-05 15:46:46,217 - INFO - joeynmt.training - Epoch  17, Step:    41300, Batch Loss:     1.884324, Tokens per Sec:    21352, Lr: 0.000300\n",
            "2021-05-05 15:46:56,444 - INFO - joeynmt.training - Epoch  17, Step:    41400, Batch Loss:     2.121862, Tokens per Sec:    20949, Lr: 0.000300\n",
            "2021-05-05 15:47:06,572 - INFO - joeynmt.training - Epoch  17, Step:    41500, Batch Loss:     1.817058, Tokens per Sec:    20611, Lr: 0.000300\n",
            "2021-05-05 15:47:16,754 - INFO - joeynmt.training - Epoch  17, Step:    41600, Batch Loss:     1.945379, Tokens per Sec:    20141, Lr: 0.000300\n",
            "2021-05-05 15:47:26,838 - INFO - joeynmt.training - Epoch  17, Step:    41700, Batch Loss:     2.036801, Tokens per Sec:    20571, Lr: 0.000300\n",
            "2021-05-05 15:47:36,976 - INFO - joeynmt.training - Epoch  17, Step:    41800, Batch Loss:     2.071798, Tokens per Sec:    20494, Lr: 0.000300\n",
            "2021-05-05 15:47:47,005 - INFO - joeynmt.training - Epoch  17, Step:    41900, Batch Loss:     2.089725, Tokens per Sec:    20148, Lr: 0.000300\n",
            "2021-05-05 15:47:57,149 - INFO - joeynmt.training - Epoch  17, Step:    42000, Batch Loss:     1.923141, Tokens per Sec:    20633, Lr: 0.000300\n",
            "2021-05-05 15:48:08,092 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:48:08,092 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:48:08,092 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:48:08,319 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:48:08,319 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:48:08,710 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:48:08,710 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:48:08,710 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:48:08,710 - INFO - joeynmt.training - \tHypothesis: And they will find security for following Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:48:08,710 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:48:08,711 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:48:08,711 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:48:08,711 - INFO - joeynmt.training - \tHypothesis: Jehovah has the prospect of seeing his children .\n",
            "2021-05-05 15:48:08,711 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:48:08,711 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:48:08,711 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:48:08,711 - INFO - joeynmt.training - \tHypothesis: The Egyptians realized that this is why the world governments cannot bring the end of the harmful and the corruption .\n",
            "2021-05-05 15:48:08,711 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:48:08,711 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:48:08,711 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:48:08,711 - INFO - joeynmt.training - \tHypothesis: In chapter 7 , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:48:08,711 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    42000: bleu:  26.69, loss: 44149.5742, ppl:   5.8868, duration: 11.5621s\n",
            "2021-05-05 15:48:18,932 - INFO - joeynmt.training - Epoch  17, Step:    42100, Batch Loss:     1.903627, Tokens per Sec:    20699, Lr: 0.000300\n",
            "2021-05-05 15:48:29,185 - INFO - joeynmt.training - Epoch  17, Step:    42200, Batch Loss:     2.205766, Tokens per Sec:    20691, Lr: 0.000300\n",
            "2021-05-05 15:48:39,394 - INFO - joeynmt.training - Epoch  17, Step:    42300, Batch Loss:     1.788193, Tokens per Sec:    20828, Lr: 0.000300\n",
            "2021-05-05 15:48:49,605 - INFO - joeynmt.training - Epoch  17, Step:    42400, Batch Loss:     1.991643, Tokens per Sec:    20553, Lr: 0.000300\n",
            "2021-05-05 15:48:59,758 - INFO - joeynmt.training - Epoch  17, Step:    42500, Batch Loss:     2.049981, Tokens per Sec:    20511, Lr: 0.000300\n",
            "2021-05-05 15:49:09,884 - INFO - joeynmt.training - Epoch  17, Step:    42600, Batch Loss:     2.203511, Tokens per Sec:    20551, Lr: 0.000300\n",
            "2021-05-05 15:49:20,068 - INFO - joeynmt.training - Epoch  17, Step:    42700, Batch Loss:     1.892432, Tokens per Sec:    20934, Lr: 0.000300\n",
            "2021-05-05 15:49:30,242 - INFO - joeynmt.training - Epoch  17, Step:    42800, Batch Loss:     1.995713, Tokens per Sec:    20579, Lr: 0.000300\n",
            "2021-05-05 15:49:40,454 - INFO - joeynmt.training - Epoch  17, Step:    42900, Batch Loss:     1.735316, Tokens per Sec:    21113, Lr: 0.000300\n",
            "2021-05-05 15:49:41,637 - INFO - joeynmt.training - Epoch  17: total training loss 4973.53\n",
            "2021-05-05 15:49:41,638 - INFO - joeynmt.training - EPOCH 18\n",
            "2021-05-05 15:49:51,097 - INFO - joeynmt.training - Epoch  18, Step:    43000, Batch Loss:     1.994467, Tokens per Sec:    20056, Lr: 0.000300\n",
            "2021-05-05 15:50:01,677 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:50:01,678 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:50:01,678 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:50:01,914 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:50:01,914 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:50:02,304 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:50:02,304 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:50:02,304 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:50:02,304 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:50:02,305 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:50:02,305 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:50:02,305 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:50:02,305 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 15:50:02,305 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:50:02,305 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:50:02,305 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:50:02,305 - INFO - joeynmt.training - \tHypothesis: The Masters recognize that this is why the world government governments cannot bring the end of immorality and distress .\n",
            "2021-05-05 15:50:02,305 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:50:02,305 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:50:02,305 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:50:02,305 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:50:02,306 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    43000: bleu:  26.81, loss: 44102.2188, ppl:   5.8757, duration: 11.2083s\n",
            "2021-05-05 15:50:12,514 - INFO - joeynmt.training - Epoch  18, Step:    43100, Batch Loss:     2.023713, Tokens per Sec:    20409, Lr: 0.000300\n",
            "2021-05-05 15:50:22,621 - INFO - joeynmt.training - Epoch  18, Step:    43200, Batch Loss:     2.061728, Tokens per Sec:    20170, Lr: 0.000300\n",
            "2021-05-05 15:50:32,785 - INFO - joeynmt.training - Epoch  18, Step:    43300, Batch Loss:     2.069674, Tokens per Sec:    20647, Lr: 0.000300\n",
            "2021-05-05 15:50:42,952 - INFO - joeynmt.training - Epoch  18, Step:    43400, Batch Loss:     2.030033, Tokens per Sec:    20559, Lr: 0.000300\n",
            "2021-05-05 15:50:53,181 - INFO - joeynmt.training - Epoch  18, Step:    43500, Batch Loss:     1.832007, Tokens per Sec:    20878, Lr: 0.000300\n",
            "2021-05-05 15:51:03,336 - INFO - joeynmt.training - Epoch  18, Step:    43600, Batch Loss:     2.003995, Tokens per Sec:    20694, Lr: 0.000300\n",
            "2021-05-05 15:51:13,545 - INFO - joeynmt.training - Epoch  18, Step:    43700, Batch Loss:     2.157188, Tokens per Sec:    20550, Lr: 0.000300\n",
            "2021-05-05 15:51:23,672 - INFO - joeynmt.training - Epoch  18, Step:    43800, Batch Loss:     1.734097, Tokens per Sec:    20144, Lr: 0.000300\n",
            "2021-05-05 15:51:33,838 - INFO - joeynmt.training - Epoch  18, Step:    43900, Batch Loss:     2.035573, Tokens per Sec:    20521, Lr: 0.000300\n",
            "2021-05-05 15:51:44,107 - INFO - joeynmt.training - Epoch  18, Step:    44000, Batch Loss:     2.201709, Tokens per Sec:    20992, Lr: 0.000300\n",
            "2021-05-05 15:51:54,832 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:51:54,833 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:51:54,833 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:51:55,070 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:51:55,070 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:51:55,459 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:51:55,459 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:51:55,459 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:51:55,459 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:51:55,459 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:51:55,460 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:51:55,460 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:51:55,460 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 15:51:55,460 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:51:55,460 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:51:55,460 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:51:55,460 - INFO - joeynmt.training - \tHypothesis: The Egyptian observes realized that this is why the world governments cannot bring the end of the corrupt and corrupt .\n",
            "2021-05-05 15:51:55,460 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:51:55,460 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:51:55,461 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:51:55,461 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of the book of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:51:55,461 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    44000: bleu:  26.96, loss: 44005.0195, ppl:   5.8528, duration: 11.3531s\n",
            "2021-05-05 15:52:05,706 - INFO - joeynmt.training - Epoch  18, Step:    44100, Batch Loss:     2.279133, Tokens per Sec:    20770, Lr: 0.000300\n",
            "2021-05-05 15:52:15,913 - INFO - joeynmt.training - Epoch  18, Step:    44200, Batch Loss:     1.948836, Tokens per Sec:    20600, Lr: 0.000300\n",
            "2021-05-05 15:52:26,197 - INFO - joeynmt.training - Epoch  18, Step:    44300, Batch Loss:     1.980603, Tokens per Sec:    20622, Lr: 0.000300\n",
            "2021-05-05 15:52:36,443 - INFO - joeynmt.training - Epoch  18, Step:    44400, Batch Loss:     1.801702, Tokens per Sec:    20370, Lr: 0.000300\n",
            "2021-05-05 15:52:46,581 - INFO - joeynmt.training - Epoch  18, Step:    44500, Batch Loss:     1.914123, Tokens per Sec:    20389, Lr: 0.000300\n",
            "2021-05-05 15:52:56,863 - INFO - joeynmt.training - Epoch  18, Step:    44600, Batch Loss:     2.173644, Tokens per Sec:    20472, Lr: 0.000300\n",
            "2021-05-05 15:53:07,096 - INFO - joeynmt.training - Epoch  18, Step:    44700, Batch Loss:     2.296193, Tokens per Sec:    20741, Lr: 0.000300\n",
            "2021-05-05 15:53:17,287 - INFO - joeynmt.training - Epoch  18, Step:    44800, Batch Loss:     1.968680, Tokens per Sec:    20657, Lr: 0.000300\n",
            "2021-05-05 15:53:27,436 - INFO - joeynmt.training - Epoch  18, Step:    44900, Batch Loss:     1.857027, Tokens per Sec:    20490, Lr: 0.000300\n",
            "2021-05-05 15:53:37,520 - INFO - joeynmt.training - Epoch  18, Step:    45000, Batch Loss:     1.860636, Tokens per Sec:    20365, Lr: 0.000300\n",
            "2021-05-05 15:53:47,680 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:53:47,680 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:53:47,680 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:53:47,907 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:53:47,907 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:53:48,327 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:53:48,328 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:53:48,328 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:53:48,328 - INFO - joeynmt.training - \tHypothesis: And they will find security in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:53:48,328 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:53:48,328 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:53:48,328 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:53:48,328 - INFO - joeynmt.training - \tHypothesis: Jehovah has the hope to see his children again .\n",
            "2021-05-05 15:53:48,328 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:53:48,328 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:53:48,328 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:53:48,328 - INFO - joeynmt.training - \tHypothesis: The Egyptians realized that this is why the world governments cannot bring the end of corruption and corruption .\n",
            "2021-05-05 15:53:48,329 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:53:48,329 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:53:48,329 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:53:48,329 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul explained the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:53:48,329 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    45000: bleu:  26.82, loss: 43944.0234, ppl:   5.8385, duration: 10.8086s\n",
            "2021-05-05 15:53:58,603 - INFO - joeynmt.training - Epoch  18, Step:    45100, Batch Loss:     1.792911, Tokens per Sec:    20657, Lr: 0.000300\n",
            "2021-05-05 15:54:08,760 - INFO - joeynmt.training - Epoch  18, Step:    45200, Batch Loss:     1.794336, Tokens per Sec:    20653, Lr: 0.000300\n",
            "2021-05-05 15:54:18,958 - INFO - joeynmt.training - Epoch  18, Step:    45300, Batch Loss:     1.973867, Tokens per Sec:    20816, Lr: 0.000300\n",
            "2021-05-05 15:54:29,166 - INFO - joeynmt.training - Epoch  18, Step:    45400, Batch Loss:     2.089018, Tokens per Sec:    20669, Lr: 0.000300\n",
            "2021-05-05 15:54:33,287 - INFO - joeynmt.training - Epoch  18: total training loss 4941.11\n",
            "2021-05-05 15:54:33,287 - INFO - joeynmt.training - EPOCH 19\n",
            "2021-05-05 15:54:39,740 - INFO - joeynmt.training - Epoch  19, Step:    45500, Batch Loss:     1.948612, Tokens per Sec:    19118, Lr: 0.000300\n",
            "2021-05-05 15:54:49,948 - INFO - joeynmt.training - Epoch  19, Step:    45600, Batch Loss:     2.046697, Tokens per Sec:    20947, Lr: 0.000300\n",
            "2021-05-05 15:55:00,087 - INFO - joeynmt.training - Epoch  19, Step:    45700, Batch Loss:     1.643164, Tokens per Sec:    20279, Lr: 0.000300\n",
            "2021-05-05 15:55:10,370 - INFO - joeynmt.training - Epoch  19, Step:    45800, Batch Loss:     1.982432, Tokens per Sec:    20609, Lr: 0.000300\n",
            "2021-05-05 15:55:20,523 - INFO - joeynmt.training - Epoch  19, Step:    45900, Batch Loss:     1.999519, Tokens per Sec:    20660, Lr: 0.000300\n",
            "2021-05-05 15:55:30,695 - INFO - joeynmt.training - Epoch  19, Step:    46000, Batch Loss:     1.977669, Tokens per Sec:    20481, Lr: 0.000300\n",
            "2021-05-05 15:55:41,202 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:55:41,202 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:55:41,202 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:55:41,443 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:55:41,443 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:55:41,834 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:55:41,834 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:55:41,834 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:55:41,835 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:55:41,835 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:55:41,835 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:55:41,835 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:55:41,835 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 15:55:41,835 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:55:41,835 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:55:41,835 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:55:41,835 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this is why the world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 15:55:41,835 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:55:41,835 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:55:41,836 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:55:41,836 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:55:41,836 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    46000: bleu:  27.30, loss: 43548.1836, ppl:   5.7464, duration: 11.1400s\n",
            "2021-05-05 15:55:52,071 - INFO - joeynmt.training - Epoch  19, Step:    46100, Batch Loss:     2.014075, Tokens per Sec:    20543, Lr: 0.000300\n",
            "2021-05-05 15:56:02,236 - INFO - joeynmt.training - Epoch  19, Step:    46200, Batch Loss:     1.963977, Tokens per Sec:    20791, Lr: 0.000300\n",
            "2021-05-05 15:56:12,372 - INFO - joeynmt.training - Epoch  19, Step:    46300, Batch Loss:     2.036461, Tokens per Sec:    20264, Lr: 0.000300\n",
            "2021-05-05 15:56:22,625 - INFO - joeynmt.training - Epoch  19, Step:    46400, Batch Loss:     1.973148, Tokens per Sec:    21005, Lr: 0.000300\n",
            "2021-05-05 15:56:32,823 - INFO - joeynmt.training - Epoch  19, Step:    46500, Batch Loss:     2.019601, Tokens per Sec:    20266, Lr: 0.000300\n",
            "2021-05-05 15:56:43,049 - INFO - joeynmt.training - Epoch  19, Step:    46600, Batch Loss:     2.050827, Tokens per Sec:    20924, Lr: 0.000300\n",
            "2021-05-05 15:56:53,172 - INFO - joeynmt.training - Epoch  19, Step:    46700, Batch Loss:     2.206175, Tokens per Sec:    20137, Lr: 0.000300\n",
            "2021-05-05 15:57:03,432 - INFO - joeynmt.training - Epoch  19, Step:    46800, Batch Loss:     2.108743, Tokens per Sec:    20596, Lr: 0.000300\n",
            "2021-05-05 15:57:13,525 - INFO - joeynmt.training - Epoch  19, Step:    46900, Batch Loss:     2.154904, Tokens per Sec:    20583, Lr: 0.000300\n",
            "2021-05-05 15:57:23,731 - INFO - joeynmt.training - Epoch  19, Step:    47000, Batch Loss:     1.925337, Tokens per Sec:    20225, Lr: 0.000300\n",
            "2021-05-05 15:57:34,597 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:57:34,597 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:57:34,597 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:57:34,846 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 15:57:34,846 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 15:57:35,244 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:57:35,244 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:57:35,244 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:57:35,244 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:57:35,244 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:57:35,244 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:57:35,244 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:57:35,245 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 15:57:35,245 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:57:35,245 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:57:35,245 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:57:35,245 - INFO - joeynmt.training - \tHypothesis: The Mass realized that this is why the world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 15:57:35,245 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:57:35,245 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:57:35,245 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:57:35,245 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:57:35,245 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    47000: bleu:  27.15, loss: 43542.8047, ppl:   5.7451, duration: 11.5139s\n",
            "2021-05-05 15:57:45,541 - INFO - joeynmt.training - Epoch  19, Step:    47100, Batch Loss:     1.908609, Tokens per Sec:    20563, Lr: 0.000300\n",
            "2021-05-05 15:57:55,696 - INFO - joeynmt.training - Epoch  19, Step:    47200, Batch Loss:     1.985133, Tokens per Sec:    20553, Lr: 0.000300\n",
            "2021-05-05 15:58:05,852 - INFO - joeynmt.training - Epoch  19, Step:    47300, Batch Loss:     1.752931, Tokens per Sec:    20155, Lr: 0.000300\n",
            "2021-05-05 15:58:16,206 - INFO - joeynmt.training - Epoch  19, Step:    47400, Batch Loss:     2.044492, Tokens per Sec:    20852, Lr: 0.000300\n",
            "2021-05-05 15:58:26,411 - INFO - joeynmt.training - Epoch  19, Step:    47500, Batch Loss:     1.753019, Tokens per Sec:    20550, Lr: 0.000300\n",
            "2021-05-05 15:58:36,396 - INFO - joeynmt.training - Epoch  19, Step:    47600, Batch Loss:     2.071457, Tokens per Sec:    19697, Lr: 0.000300\n",
            "2021-05-05 15:58:46,625 - INFO - joeynmt.training - Epoch  19, Step:    47700, Batch Loss:     2.042719, Tokens per Sec:    20874, Lr: 0.000300\n",
            "2021-05-05 15:58:56,847 - INFO - joeynmt.training - Epoch  19, Step:    47800, Batch Loss:     2.104014, Tokens per Sec:    20996, Lr: 0.000300\n",
            "2021-05-05 15:59:07,087 - INFO - joeynmt.training - Epoch  19, Step:    47900, Batch Loss:     2.108780, Tokens per Sec:    20753, Lr: 0.000300\n",
            "2021-05-05 15:59:14,711 - INFO - joeynmt.training - Epoch  19: total training loss 4915.06\n",
            "2021-05-05 15:59:14,712 - INFO - joeynmt.training - EPOCH 20\n",
            "2021-05-05 15:59:17,585 - INFO - joeynmt.training - Epoch  20, Step:    48000, Batch Loss:     1.685398, Tokens per Sec:    18412, Lr: 0.000300\n",
            "2021-05-05 15:59:28,376 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 15:59:28,376 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 15:59:28,376 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 15:59:28,996 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 15:59:28,997 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 15:59:28,997 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:59:28,997 - INFO - joeynmt.training - \tHypothesis: And they will find security in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 15:59:28,997 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 15:59:28,997 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 15:59:28,997 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 15:59:28,997 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 15:59:28,997 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 15:59:28,997 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 15:59:28,997 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 15:59:28,998 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this is why the world government will not bring an end to the end of the corruption and disturbing .\n",
            "2021-05-05 15:59:28,998 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 15:59:28,998 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 15:59:28,998 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 15:59:28,998 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 15:59:28,998 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    48000: bleu:  27.43, loss: 43565.4258, ppl:   5.7504, duration: 11.4122s\n",
            "2021-05-05 15:59:39,267 - INFO - joeynmt.training - Epoch  20, Step:    48100, Batch Loss:     1.869690, Tokens per Sec:    20736, Lr: 0.000300\n",
            "2021-05-05 15:59:49,500 - INFO - joeynmt.training - Epoch  20, Step:    48200, Batch Loss:     1.755008, Tokens per Sec:    20642, Lr: 0.000300\n",
            "2021-05-05 15:59:59,699 - INFO - joeynmt.training - Epoch  20, Step:    48300, Batch Loss:     1.775925, Tokens per Sec:    20810, Lr: 0.000300\n",
            "2021-05-05 16:00:09,850 - INFO - joeynmt.training - Epoch  20, Step:    48400, Batch Loss:     1.840963, Tokens per Sec:    20704, Lr: 0.000300\n",
            "2021-05-05 16:00:20,182 - INFO - joeynmt.training - Epoch  20, Step:    48500, Batch Loss:     1.933099, Tokens per Sec:    20739, Lr: 0.000300\n",
            "2021-05-05 16:00:30,338 - INFO - joeynmt.training - Epoch  20, Step:    48600, Batch Loss:     1.981171, Tokens per Sec:    20471, Lr: 0.000300\n",
            "2021-05-05 16:00:40,532 - INFO - joeynmt.training - Epoch  20, Step:    48700, Batch Loss:     1.999070, Tokens per Sec:    20477, Lr: 0.000300\n",
            "2021-05-05 16:00:50,694 - INFO - joeynmt.training - Epoch  20, Step:    48800, Batch Loss:     1.792394, Tokens per Sec:    20425, Lr: 0.000300\n",
            "2021-05-05 16:01:00,941 - INFO - joeynmt.training - Epoch  20, Step:    48900, Batch Loss:     1.347239, Tokens per Sec:    20782, Lr: 0.000300\n",
            "2021-05-05 16:01:11,142 - INFO - joeynmt.training - Epoch  20, Step:    49000, Batch Loss:     1.840139, Tokens per Sec:    20672, Lr: 0.000300\n",
            "2021-05-05 16:01:21,970 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:01:21,971 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:01:21,971 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:01:22,200 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:01:22,201 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:01:22,640 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:01:22,640 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:01:22,640 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:01:22,640 - INFO - joeynmt.training - \tHypothesis: They will also find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:01:22,640 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:01:22,641 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:01:22,641 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:01:22,641 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 16:01:22,641 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:01:22,641 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:01:22,641 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:01:22,641 - INFO - joeynmt.training - \tHypothesis: The Egyptians realized that this is why the world governments cannot bring the end of the corruption and the corruption .\n",
            "2021-05-05 16:01:22,641 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:01:22,641 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:01:22,641 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:01:22,642 - INFO - joeynmt.training - \tHypothesis: In chapter 7 , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:01:22,642 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    49000: bleu:  27.15, loss: 43180.8438, ppl:   5.6623, duration: 11.4992s\n",
            "2021-05-05 16:01:32,802 - INFO - joeynmt.training - Epoch  20, Step:    49100, Batch Loss:     1.918253, Tokens per Sec:    20250, Lr: 0.000300\n",
            "2021-05-05 16:01:43,044 - INFO - joeynmt.training - Epoch  20, Step:    49200, Batch Loss:     1.978357, Tokens per Sec:    20388, Lr: 0.000300\n",
            "2021-05-05 16:01:53,275 - INFO - joeynmt.training - Epoch  20, Step:    49300, Batch Loss:     2.117944, Tokens per Sec:    20716, Lr: 0.000300\n",
            "2021-05-05 16:02:03,422 - INFO - joeynmt.training - Epoch  20, Step:    49400, Batch Loss:     1.859635, Tokens per Sec:    19999, Lr: 0.000300\n",
            "2021-05-05 16:02:13,676 - INFO - joeynmt.training - Epoch  20, Step:    49500, Batch Loss:     1.827885, Tokens per Sec:    20962, Lr: 0.000300\n",
            "2021-05-05 16:02:23,928 - INFO - joeynmt.training - Epoch  20, Step:    49600, Batch Loss:     2.067888, Tokens per Sec:    20450, Lr: 0.000300\n",
            "2021-05-05 16:02:33,961 - INFO - joeynmt.training - Epoch  20, Step:    49700, Batch Loss:     1.430322, Tokens per Sec:    20114, Lr: 0.000300\n",
            "2021-05-05 16:02:44,174 - INFO - joeynmt.training - Epoch  20, Step:    49800, Batch Loss:     2.017284, Tokens per Sec:    20547, Lr: 0.000300\n",
            "2021-05-05 16:02:54,464 - INFO - joeynmt.training - Epoch  20, Step:    49900, Batch Loss:     2.192338, Tokens per Sec:    21038, Lr: 0.000300\n",
            "2021-05-05 16:03:04,647 - INFO - joeynmt.training - Epoch  20, Step:    50000, Batch Loss:     1.826197, Tokens per Sec:    20828, Lr: 0.000300\n",
            "2021-05-05 16:03:15,148 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:03:15,149 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:03:15,149 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:03:15,376 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:03:15,376 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:03:15,759 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:03:15,759 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:03:15,759 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:03:15,759 - INFO - joeynmt.training - \tHypothesis: And they will find security in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:03:15,759 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:03:15,759 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:03:15,759 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:03:15,759 - INFO - joeynmt.training - \tHypothesis: Jehovah is hope to see his children again .\n",
            "2021-05-05 16:03:15,759 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:03:15,760 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:03:15,760 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:03:15,760 - INFO - joeynmt.training - \tHypothesis: The Mass realize that this is why the government of the world cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:03:15,760 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:03:15,760 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:03:15,760 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:03:15,760 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:03:15,761 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    50000: bleu:  27.35, loss: 43158.9492, ppl:   5.6573, duration: 11.1128s\n",
            "2021-05-05 16:03:26,000 - INFO - joeynmt.training - Epoch  20, Step:    50100, Batch Loss:     1.980397, Tokens per Sec:    20960, Lr: 0.000300\n",
            "2021-05-05 16:03:36,175 - INFO - joeynmt.training - Epoch  20, Step:    50200, Batch Loss:     1.883516, Tokens per Sec:    20501, Lr: 0.000300\n",
            "2021-05-05 16:03:46,398 - INFO - joeynmt.training - Epoch  20, Step:    50300, Batch Loss:     1.965698, Tokens per Sec:    20673, Lr: 0.000300\n",
            "2021-05-05 16:03:56,694 - INFO - joeynmt.training - Epoch  20, Step:    50400, Batch Loss:     1.937914, Tokens per Sec:    20786, Lr: 0.000300\n",
            "2021-05-05 16:04:06,506 - INFO - joeynmt.training - Epoch  20: total training loss 4843.93\n",
            "2021-05-05 16:04:06,506 - INFO - joeynmt.training - EPOCH 21\n",
            "2021-05-05 16:04:07,269 - INFO - joeynmt.training - Epoch  21, Step:    50500, Batch Loss:     1.615443, Tokens per Sec:    11806, Lr: 0.000300\n",
            "2021-05-05 16:04:17,377 - INFO - joeynmt.training - Epoch  21, Step:    50600, Batch Loss:     2.040576, Tokens per Sec:    20491, Lr: 0.000300\n",
            "2021-05-05 16:04:27,562 - INFO - joeynmt.training - Epoch  21, Step:    50700, Batch Loss:     1.765379, Tokens per Sec:    19987, Lr: 0.000300\n",
            "2021-05-05 16:04:37,769 - INFO - joeynmt.training - Epoch  21, Step:    50800, Batch Loss:     1.045107, Tokens per Sec:    20227, Lr: 0.000300\n",
            "2021-05-05 16:04:48,054 - INFO - joeynmt.training - Epoch  21, Step:    50900, Batch Loss:     1.913451, Tokens per Sec:    20784, Lr: 0.000300\n",
            "2021-05-05 16:04:58,335 - INFO - joeynmt.training - Epoch  21, Step:    51000, Batch Loss:     1.793985, Tokens per Sec:    20550, Lr: 0.000300\n",
            "2021-05-05 16:05:08,963 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:05:08,964 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:05:08,964 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:05:09,192 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:05:09,192 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:05:09,606 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:05:09,606 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:05:09,606 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:05:09,606 - INFO - joeynmt.training - \tHypothesis: And they will find peace in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:05:09,606 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:05:09,606 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:05:09,606 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:05:09,606 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 16:05:09,607 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:05:09,607 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:05:09,607 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:05:09,607 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this is why the world governments cannot bring the end of the corruption and corruption .\n",
            "2021-05-05 16:05:09,607 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:05:09,607 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:05:09,607 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:05:09,607 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:05:09,607 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    51000: bleu:  27.24, loss: 43019.7031, ppl:   5.6257, duration: 11.2718s\n",
            "2021-05-05 16:05:19,685 - INFO - joeynmt.training - Epoch  21, Step:    51100, Batch Loss:     2.079113, Tokens per Sec:    20461, Lr: 0.000300\n",
            "2021-05-05 16:05:29,896 - INFO - joeynmt.training - Epoch  21, Step:    51200, Batch Loss:     1.895966, Tokens per Sec:    20896, Lr: 0.000300\n",
            "2021-05-05 16:05:40,048 - INFO - joeynmt.training - Epoch  21, Step:    51300, Batch Loss:     1.986800, Tokens per Sec:    20006, Lr: 0.000300\n",
            "2021-05-05 16:05:50,277 - INFO - joeynmt.training - Epoch  21, Step:    51400, Batch Loss:     1.982148, Tokens per Sec:    20644, Lr: 0.000300\n",
            "2021-05-05 16:06:00,634 - INFO - joeynmt.training - Epoch  21, Step:    51500, Batch Loss:     1.446589, Tokens per Sec:    20264, Lr: 0.000300\n",
            "2021-05-05 16:06:10,927 - INFO - joeynmt.training - Epoch  21, Step:    51600, Batch Loss:     1.907694, Tokens per Sec:    21532, Lr: 0.000300\n",
            "2021-05-05 16:06:21,166 - INFO - joeynmt.training - Epoch  21, Step:    51700, Batch Loss:     2.052419, Tokens per Sec:    20927, Lr: 0.000300\n",
            "2021-05-05 16:06:31,397 - INFO - joeynmt.training - Epoch  21, Step:    51800, Batch Loss:     2.002226, Tokens per Sec:    20414, Lr: 0.000300\n",
            "2021-05-05 16:06:41,757 - INFO - joeynmt.training - Epoch  21, Step:    51900, Batch Loss:     1.954969, Tokens per Sec:    21061, Lr: 0.000300\n",
            "2021-05-05 16:06:51,749 - INFO - joeynmt.training - Epoch  21, Step:    52000, Batch Loss:     2.037460, Tokens per Sec:    20408, Lr: 0.000300\n",
            "2021-05-05 16:07:02,258 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:07:02,258 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:07:02,258 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:07:02,909 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:07:02,910 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:07:02,910 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:07:02,910 - INFO - joeynmt.training - \tHypothesis: And they will find security in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:07:02,910 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:07:02,910 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:07:02,910 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:07:02,910 - INFO - joeynmt.training - \tHypothesis: Jehovah is the prospect of seeing his children .\n",
            "2021-05-05 16:07:02,910 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:07:02,911 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:07:02,911 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:07:02,911 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this is why the world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:07:02,911 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:07:02,911 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:07:02,911 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:07:02,911 - INFO - joeynmt.training - \tHypothesis: In chapter 7 , the book of Romans , Paul reveals the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:07:02,911 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    52000: bleu:  27.25, loss: 43065.7148, ppl:   5.6361, duration: 11.1615s\n",
            "2021-05-05 16:07:13,178 - INFO - joeynmt.training - Epoch  21, Step:    52100, Batch Loss:     1.938941, Tokens per Sec:    20609, Lr: 0.000300\n",
            "2021-05-05 16:07:23,353 - INFO - joeynmt.training - Epoch  21, Step:    52200, Batch Loss:     1.822986, Tokens per Sec:    20316, Lr: 0.000300\n",
            "2021-05-05 16:07:33,556 - INFO - joeynmt.training - Epoch  21, Step:    52300, Batch Loss:     1.913460, Tokens per Sec:    20598, Lr: 0.000300\n",
            "2021-05-05 16:07:43,730 - INFO - joeynmt.training - Epoch  21, Step:    52400, Batch Loss:     1.939156, Tokens per Sec:    20411, Lr: 0.000300\n",
            "2021-05-05 16:07:53,881 - INFO - joeynmt.training - Epoch  21, Step:    52500, Batch Loss:     1.836609, Tokens per Sec:    20536, Lr: 0.000300\n",
            "2021-05-05 16:08:04,078 - INFO - joeynmt.training - Epoch  21, Step:    52600, Batch Loss:     1.297246, Tokens per Sec:    20338, Lr: 0.000300\n",
            "2021-05-05 16:08:14,304 - INFO - joeynmt.training - Epoch  21, Step:    52700, Batch Loss:     1.826281, Tokens per Sec:    20462, Lr: 0.000300\n",
            "2021-05-05 16:08:24,535 - INFO - joeynmt.training - Epoch  21, Step:    52800, Batch Loss:     1.956455, Tokens per Sec:    20968, Lr: 0.000300\n",
            "2021-05-05 16:08:34,776 - INFO - joeynmt.training - Epoch  21, Step:    52900, Batch Loss:     1.788591, Tokens per Sec:    20973, Lr: 0.000300\n",
            "2021-05-05 16:08:44,972 - INFO - joeynmt.training - Epoch  21, Step:    53000, Batch Loss:     2.140627, Tokens per Sec:    20721, Lr: 0.000300\n",
            "2021-05-05 16:08:55,909 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:08:55,909 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:08:55,909 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:08:56,140 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:08:56,140 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:08:56,620 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:08:56,621 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:08:56,621 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:08:56,621 - INFO - joeynmt.training - \tHypothesis: And they will find security in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:08:56,621 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:08:56,621 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:08:56,621 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:08:56,621 - INFO - joeynmt.training - \tHypothesis: Jehovah is hope to see his children again .\n",
            "2021-05-05 16:08:56,621 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:08:56,621 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:08:56,621 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:08:56,621 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why the world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:08:56,622 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:08:56,622 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:08:56,622 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:08:56,622 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:08:56,622 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    53000: bleu:  27.60, loss: 42805.4414, ppl:   5.5775, duration: 11.6494s\n",
            "2021-05-05 16:08:58,814 - INFO - joeynmt.training - Epoch  21: total training loss 4818.36\n",
            "2021-05-05 16:08:58,814 - INFO - joeynmt.training - EPOCH 22\n",
            "2021-05-05 16:09:07,215 - INFO - joeynmt.training - Epoch  22, Step:    53100, Batch Loss:     1.527420, Tokens per Sec:    19759, Lr: 0.000300\n",
            "2021-05-05 16:09:17,325 - INFO - joeynmt.training - Epoch  22, Step:    53200, Batch Loss:     1.523082, Tokens per Sec:    20984, Lr: 0.000300\n",
            "2021-05-05 16:09:27,660 - INFO - joeynmt.training - Epoch  22, Step:    53300, Batch Loss:     1.888877, Tokens per Sec:    20658, Lr: 0.000300\n",
            "2021-05-05 16:09:37,859 - INFO - joeynmt.training - Epoch  22, Step:    53400, Batch Loss:     1.921796, Tokens per Sec:    20392, Lr: 0.000300\n",
            "2021-05-05 16:09:48,153 - INFO - joeynmt.training - Epoch  22, Step:    53500, Batch Loss:     1.906057, Tokens per Sec:    21025, Lr: 0.000300\n",
            "2021-05-05 16:09:58,446 - INFO - joeynmt.training - Epoch  22, Step:    53600, Batch Loss:     1.730790, Tokens per Sec:    20804, Lr: 0.000300\n",
            "2021-05-05 16:10:08,740 - INFO - joeynmt.training - Epoch  22, Step:    53700, Batch Loss:     1.627326, Tokens per Sec:    20901, Lr: 0.000300\n",
            "2021-05-05 16:10:18,903 - INFO - joeynmt.training - Epoch  22, Step:    53800, Batch Loss:     2.055778, Tokens per Sec:    20523, Lr: 0.000300\n",
            "2021-05-05 16:10:29,185 - INFO - joeynmt.training - Epoch  22, Step:    53900, Batch Loss:     1.888854, Tokens per Sec:    20644, Lr: 0.000300\n",
            "2021-05-05 16:10:39,356 - INFO - joeynmt.training - Epoch  22, Step:    54000, Batch Loss:     1.952386, Tokens per Sec:    20860, Lr: 0.000300\n",
            "2021-05-05 16:10:50,053 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:10:50,053 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:10:50,053 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:10:50,289 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:10:50,289 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:10:50,718 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:10:50,719 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:10:50,719 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:10:50,719 - INFO - joeynmt.training - \tHypothesis: And they will find security in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:10:50,719 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:10:50,719 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:10:50,719 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:10:50,719 - INFO - joeynmt.training - \tHypothesis: Jehovah is hope to see his children again .\n",
            "2021-05-05 16:10:50,719 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:10:50,719 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:10:50,720 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:10:50,720 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why the world governments cannot bring an end to the corrupt and corruption .\n",
            "2021-05-05 16:10:50,720 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:10:50,720 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:10:50,720 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:10:50,720 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:10:50,720 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    54000: bleu:  28.25, loss: 42680.5312, ppl:   5.5496, duration: 11.3639s\n",
            "2021-05-05 16:11:00,962 - INFO - joeynmt.training - Epoch  22, Step:    54100, Batch Loss:     1.637937, Tokens per Sec:    20522, Lr: 0.000300\n",
            "2021-05-05 16:11:11,157 - INFO - joeynmt.training - Epoch  22, Step:    54200, Batch Loss:     2.024105, Tokens per Sec:    20931, Lr: 0.000300\n",
            "2021-05-05 16:11:21,377 - INFO - joeynmt.training - Epoch  22, Step:    54300, Batch Loss:     1.972150, Tokens per Sec:    20556, Lr: 0.000300\n",
            "2021-05-05 16:11:31,520 - INFO - joeynmt.training - Epoch  22, Step:    54400, Batch Loss:     1.894223, Tokens per Sec:    20360, Lr: 0.000300\n",
            "2021-05-05 16:11:41,783 - INFO - joeynmt.training - Epoch  22, Step:    54500, Batch Loss:     2.092747, Tokens per Sec:    20810, Lr: 0.000300\n",
            "2021-05-05 16:11:51,854 - INFO - joeynmt.training - Epoch  22, Step:    54600, Batch Loss:     1.915298, Tokens per Sec:    20388, Lr: 0.000300\n",
            "2021-05-05 16:12:01,993 - INFO - joeynmt.training - Epoch  22, Step:    54700, Batch Loss:     2.069425, Tokens per Sec:    20428, Lr: 0.000300\n",
            "2021-05-05 16:12:12,147 - INFO - joeynmt.training - Epoch  22, Step:    54800, Batch Loss:     2.072610, Tokens per Sec:    20215, Lr: 0.000300\n",
            "2021-05-05 16:12:22,360 - INFO - joeynmt.training - Epoch  22, Step:    54900, Batch Loss:     1.990772, Tokens per Sec:    20451, Lr: 0.000300\n",
            "2021-05-05 16:12:32,541 - INFO - joeynmt.training - Epoch  22, Step:    55000, Batch Loss:     2.002398, Tokens per Sec:    20639, Lr: 0.000300\n",
            "2021-05-05 16:12:43,265 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:12:43,266 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:12:43,266 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:12:43,516 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:12:43,517 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:12:43,934 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:12:43,935 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:12:43,935 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:12:43,935 - INFO - joeynmt.training - \tHypothesis: And they will find security in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:12:43,935 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:12:43,935 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:12:43,935 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:12:43,935 - INFO - joeynmt.training - \tHypothesis: Jehovah is hoped to see his children again .\n",
            "2021-05-05 16:12:43,935 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:12:43,936 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:12:43,936 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:12:43,936 - INFO - joeynmt.training - \tHypothesis: The Egyptians realized that this is why the world governments cannot end the end of the corruption and corruption .\n",
            "2021-05-05 16:12:43,936 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:12:43,936 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:12:43,936 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:12:43,936 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:12:43,936 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    55000: bleu:  28.00, loss: 42595.0273, ppl:   5.5306, duration: 11.3951s\n",
            "2021-05-05 16:12:54,143 - INFO - joeynmt.training - Epoch  22, Step:    55100, Batch Loss:     1.973591, Tokens per Sec:    20521, Lr: 0.000300\n",
            "2021-05-05 16:13:04,362 - INFO - joeynmt.training - Epoch  22, Step:    55200, Batch Loss:     1.865746, Tokens per Sec:    20591, Lr: 0.000300\n",
            "2021-05-05 16:13:14,502 - INFO - joeynmt.training - Epoch  22, Step:    55300, Batch Loss:     1.967923, Tokens per Sec:    20553, Lr: 0.000300\n",
            "2021-05-05 16:13:24,638 - INFO - joeynmt.training - Epoch  22, Step:    55400, Batch Loss:     1.441733, Tokens per Sec:    20029, Lr: 0.000300\n",
            "2021-05-05 16:13:34,889 - INFO - joeynmt.training - Epoch  22, Step:    55500, Batch Loss:     1.844335, Tokens per Sec:    20755, Lr: 0.000300\n",
            "2021-05-05 16:13:39,412 - INFO - joeynmt.training - Epoch  22: total training loss 4780.12\n",
            "2021-05-05 16:13:39,413 - INFO - joeynmt.training - EPOCH 23\n",
            "2021-05-05 16:13:45,442 - INFO - joeynmt.training - Epoch  23, Step:    55600, Batch Loss:     1.954811, Tokens per Sec:    19588, Lr: 0.000300\n",
            "2021-05-05 16:13:55,578 - INFO - joeynmt.training - Epoch  23, Step:    55700, Batch Loss:     1.842526, Tokens per Sec:    20941, Lr: 0.000300\n",
            "2021-05-05 16:14:05,730 - INFO - joeynmt.training - Epoch  23, Step:    55800, Batch Loss:     1.915394, Tokens per Sec:    20323, Lr: 0.000300\n",
            "2021-05-05 16:14:15,977 - INFO - joeynmt.training - Epoch  23, Step:    55900, Batch Loss:     1.603243, Tokens per Sec:    20976, Lr: 0.000300\n",
            "2021-05-05 16:14:26,180 - INFO - joeynmt.training - Epoch  23, Step:    56000, Batch Loss:     1.792574, Tokens per Sec:    21062, Lr: 0.000300\n",
            "2021-05-05 16:14:36,640 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:14:36,641 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:14:36,641 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:14:36,870 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:14:36,871 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:14:37,254 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:14:37,254 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:14:37,254 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:14:37,254 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:14:37,254 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:14:37,254 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:14:37,254 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:14:37,254 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 16:14:37,254 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:14:37,255 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:14:37,255 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:14:37,255 - INFO - joeynmt.training - \tHypothesis: The Egyptians saw that this is why the world governments cannot bring an end to the corruption and corruption .\n",
            "2021-05-05 16:14:37,255 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:14:37,255 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:14:37,255 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:14:37,255 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul explained the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:14:37,255 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    56000: bleu:  27.66, loss: 42516.8945, ppl:   5.5133, duration: 11.0745s\n",
            "2021-05-05 16:14:47,466 - INFO - joeynmt.training - Epoch  23, Step:    56100, Batch Loss:     2.111414, Tokens per Sec:    20476, Lr: 0.000300\n",
            "2021-05-05 16:14:57,726 - INFO - joeynmt.training - Epoch  23, Step:    56200, Batch Loss:     1.902441, Tokens per Sec:    21040, Lr: 0.000300\n",
            "2021-05-05 16:15:07,914 - INFO - joeynmt.training - Epoch  23, Step:    56300, Batch Loss:     1.943517, Tokens per Sec:    20206, Lr: 0.000300\n",
            "2021-05-05 16:15:18,144 - INFO - joeynmt.training - Epoch  23, Step:    56400, Batch Loss:     1.647367, Tokens per Sec:    20720, Lr: 0.000300\n",
            "2021-05-05 16:15:28,289 - INFO - joeynmt.training - Epoch  23, Step:    56500, Batch Loss:     1.541215, Tokens per Sec:    20542, Lr: 0.000300\n",
            "2021-05-05 16:15:38,607 - INFO - joeynmt.training - Epoch  23, Step:    56600, Batch Loss:     1.960233, Tokens per Sec:    21085, Lr: 0.000300\n",
            "2021-05-05 16:15:48,841 - INFO - joeynmt.training - Epoch  23, Step:    56700, Batch Loss:     1.960032, Tokens per Sec:    20730, Lr: 0.000300\n",
            "2021-05-05 16:15:59,110 - INFO - joeynmt.training - Epoch  23, Step:    56800, Batch Loss:     1.607303, Tokens per Sec:    20687, Lr: 0.000300\n",
            "2021-05-05 16:16:09,253 - INFO - joeynmt.training - Epoch  23, Step:    56900, Batch Loss:     2.185741, Tokens per Sec:    20552, Lr: 0.000300\n",
            "2021-05-05 16:16:19,391 - INFO - joeynmt.training - Epoch  23, Step:    57000, Batch Loss:     2.043275, Tokens per Sec:    20496, Lr: 0.000300\n",
            "2021-05-05 16:16:30,072 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:16:30,072 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:16:30,072 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:16:30,300 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:16:30,301 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:16:30,718 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:16:30,719 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:16:30,719 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:16:30,719 - INFO - joeynmt.training - \tHypothesis: And they will find security in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:16:30,719 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:16:30,719 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:16:30,719 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:16:30,719 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 16:16:30,719 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:16:30,719 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:16:30,719 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:16:30,719 - INFO - joeynmt.training - \tHypothesis: The Egyptians realized that this is why the world governments cannot bring an end to the corruption and corruption .\n",
            "2021-05-05 16:16:30,720 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:16:30,720 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:16:30,720 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:16:30,720 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:16:30,720 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    57000: bleu:  27.86, loss: 42291.8711, ppl:   5.4637, duration: 11.3286s\n",
            "2021-05-05 16:16:40,968 - INFO - joeynmt.training - Epoch  23, Step:    57100, Batch Loss:     1.614551, Tokens per Sec:    20350, Lr: 0.000300\n",
            "2021-05-05 16:16:51,016 - INFO - joeynmt.training - Epoch  23, Step:    57200, Batch Loss:     2.167791, Tokens per Sec:    20692, Lr: 0.000300\n",
            "2021-05-05 16:17:01,303 - INFO - joeynmt.training - Epoch  23, Step:    57300, Batch Loss:     1.906653, Tokens per Sec:    21122, Lr: 0.000300\n",
            "2021-05-05 16:17:11,525 - INFO - joeynmt.training - Epoch  23, Step:    57400, Batch Loss:     1.855070, Tokens per Sec:    20036, Lr: 0.000300\n",
            "2021-05-05 16:17:21,714 - INFO - joeynmt.training - Epoch  23, Step:    57500, Batch Loss:     1.829240, Tokens per Sec:    20453, Lr: 0.000300\n",
            "2021-05-05 16:17:31,956 - INFO - joeynmt.training - Epoch  23, Step:    57600, Batch Loss:     1.905918, Tokens per Sec:    20885, Lr: 0.000300\n",
            "2021-05-05 16:17:42,144 - INFO - joeynmt.training - Epoch  23, Step:    57700, Batch Loss:     2.027484, Tokens per Sec:    20487, Lr: 0.000300\n",
            "2021-05-05 16:17:52,352 - INFO - joeynmt.training - Epoch  23, Step:    57800, Batch Loss:     2.113019, Tokens per Sec:    20387, Lr: 0.000300\n",
            "2021-05-05 16:18:02,586 - INFO - joeynmt.training - Epoch  23, Step:    57900, Batch Loss:     1.797981, Tokens per Sec:    20957, Lr: 0.000300\n",
            "2021-05-05 16:18:12,783 - INFO - joeynmt.training - Epoch  23, Step:    58000, Batch Loss:     1.862306, Tokens per Sec:    20917, Lr: 0.000300\n",
            "2021-05-05 16:18:23,508 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:18:23,508 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:18:23,508 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:18:24,145 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:18:24,145 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:18:24,145 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:18:24,146 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:18:24,146 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:18:24,146 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:18:24,146 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:18:24,146 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 16:18:24,146 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:18:24,146 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:18:24,146 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:18:24,146 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why the world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:18:24,146 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:18:24,147 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:18:24,147 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:18:24,147 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:18:24,147 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    58000: bleu:  28.23, loss: 42379.5977, ppl:   5.4830, duration: 11.3630s\n",
            "2021-05-05 16:18:30,338 - INFO - joeynmt.training - Epoch  23: total training loss 4735.95\n",
            "2021-05-05 16:18:30,339 - INFO - joeynmt.training - EPOCH 24\n",
            "2021-05-05 16:18:34,692 - INFO - joeynmt.training - Epoch  24, Step:    58100, Batch Loss:     1.618492, Tokens per Sec:    18676, Lr: 0.000300\n",
            "2021-05-05 16:18:44,920 - INFO - joeynmt.training - Epoch  24, Step:    58200, Batch Loss:     1.816227, Tokens per Sec:    20876, Lr: 0.000300\n",
            "2021-05-05 16:18:55,076 - INFO - joeynmt.training - Epoch  24, Step:    58300, Batch Loss:     1.854237, Tokens per Sec:    20754, Lr: 0.000300\n",
            "2021-05-05 16:19:05,340 - INFO - joeynmt.training - Epoch  24, Step:    58400, Batch Loss:     1.960505, Tokens per Sec:    21020, Lr: 0.000300\n",
            "2021-05-05 16:19:15,472 - INFO - joeynmt.training - Epoch  24, Step:    58500, Batch Loss:     1.804644, Tokens per Sec:    20169, Lr: 0.000300\n",
            "2021-05-05 16:19:25,769 - INFO - joeynmt.training - Epoch  24, Step:    58600, Batch Loss:     2.174892, Tokens per Sec:    21042, Lr: 0.000300\n",
            "2021-05-05 16:19:36,068 - INFO - joeynmt.training - Epoch  24, Step:    58700, Batch Loss:     2.120807, Tokens per Sec:    20819, Lr: 0.000300\n",
            "2021-05-05 16:19:46,091 - INFO - joeynmt.training - Epoch  24, Step:    58800, Batch Loss:     1.813957, Tokens per Sec:    20156, Lr: 0.000300\n",
            "2021-05-05 16:19:56,434 - INFO - joeynmt.training - Epoch  24, Step:    58900, Batch Loss:     1.986815, Tokens per Sec:    20862, Lr: 0.000300\n",
            "2021-05-05 16:20:06,606 - INFO - joeynmt.training - Epoch  24, Step:    59000, Batch Loss:     1.945622, Tokens per Sec:    20649, Lr: 0.000300\n",
            "2021-05-05 16:20:17,423 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:20:17,423 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:20:17,423 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:20:17,657 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:20:17,658 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:20:18,111 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:20:18,111 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:20:18,111 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:20:18,111 - INFO - joeynmt.training - \tHypothesis: And they will find security in order to follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:20:18,111 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:20:18,112 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:20:18,112 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:20:18,112 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 16:20:18,112 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:20:18,112 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:20:18,112 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:20:18,112 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why the world governments cannot bring an end to the corruption and corruption .\n",
            "2021-05-05 16:20:18,112 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:20:18,112 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:20:18,112 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:20:18,112 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:20:18,113 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    59000: bleu:  28.30, loss: 42166.5469, ppl:   5.4363, duration: 11.5059s\n",
            "2021-05-05 16:20:28,399 - INFO - joeynmt.training - Epoch  24, Step:    59100, Batch Loss:     1.799007, Tokens per Sec:    20773, Lr: 0.000300\n",
            "2021-05-05 16:20:38,544 - INFO - joeynmt.training - Epoch  24, Step:    59200, Batch Loss:     2.041987, Tokens per Sec:    20620, Lr: 0.000300\n",
            "2021-05-05 16:20:48,787 - INFO - joeynmt.training - Epoch  24, Step:    59300, Batch Loss:     2.080348, Tokens per Sec:    20491, Lr: 0.000300\n",
            "2021-05-05 16:20:58,960 - INFO - joeynmt.training - Epoch  24, Step:    59400, Batch Loss:     1.864903, Tokens per Sec:    20464, Lr: 0.000300\n",
            "2021-05-05 16:21:09,188 - INFO - joeynmt.training - Epoch  24, Step:    59500, Batch Loss:     2.137839, Tokens per Sec:    20482, Lr: 0.000300\n",
            "2021-05-05 16:21:19,402 - INFO - joeynmt.training - Epoch  24, Step:    59600, Batch Loss:     1.962371, Tokens per Sec:    20584, Lr: 0.000300\n",
            "2021-05-05 16:21:29,548 - INFO - joeynmt.training - Epoch  24, Step:    59700, Batch Loss:     2.012782, Tokens per Sec:    20555, Lr: 0.000300\n",
            "2021-05-05 16:21:39,781 - INFO - joeynmt.training - Epoch  24, Step:    59800, Batch Loss:     1.910045, Tokens per Sec:    20629, Lr: 0.000300\n",
            "2021-05-05 16:21:50,010 - INFO - joeynmt.training - Epoch  24, Step:    59900, Batch Loss:     1.921139, Tokens per Sec:    20466, Lr: 0.000300\n",
            "2021-05-05 16:22:00,076 - INFO - joeynmt.training - Epoch  24, Step:    60000, Batch Loss:     1.756592, Tokens per Sec:    20063, Lr: 0.000300\n",
            "2021-05-05 16:22:10,828 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:22:10,828 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:22:10,829 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:22:11,065 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:22:11,066 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:22:11,474 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:22:11,475 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:22:11,475 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:22:11,475 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:22:11,475 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:22:11,475 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:22:11,475 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:22:11,475 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 16:22:11,475 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:22:11,475 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:22:11,475 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:22:11,475 - INFO - joeynmt.training - \tHypothesis: The Masana realized that this is why world governments cannot end the end of the corruption and corruption .\n",
            "2021-05-05 16:22:11,475 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:22:11,476 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:22:11,476 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:22:11,476 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul explained the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:22:11,476 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    60000: bleu:  28.28, loss: 42118.5547, ppl:   5.4258, duration: 11.3995s\n",
            "2021-05-05 16:22:21,713 - INFO - joeynmt.training - Epoch  24, Step:    60100, Batch Loss:     1.932452, Tokens per Sec:    20568, Lr: 0.000300\n",
            "2021-05-05 16:22:31,855 - INFO - joeynmt.training - Epoch  24, Step:    60200, Batch Loss:     1.985114, Tokens per Sec:    20012, Lr: 0.000300\n",
            "2021-05-05 16:22:42,128 - INFO - joeynmt.training - Epoch  24, Step:    60300, Batch Loss:     1.963353, Tokens per Sec:    20932, Lr: 0.000300\n",
            "2021-05-05 16:22:52,290 - INFO - joeynmt.training - Epoch  24, Step:    60400, Batch Loss:     1.902102, Tokens per Sec:    20369, Lr: 0.000300\n",
            "2021-05-05 16:23:02,517 - INFO - joeynmt.training - Epoch  24, Step:    60500, Batch Loss:     1.970742, Tokens per Sec:    20530, Lr: 0.000300\n",
            "2021-05-05 16:23:11,482 - INFO - joeynmt.training - Epoch  24: total training loss 4726.91\n",
            "2021-05-05 16:23:11,483 - INFO - joeynmt.training - EPOCH 25\n",
            "2021-05-05 16:23:13,184 - INFO - joeynmt.training - Epoch  25, Step:    60600, Batch Loss:     2.159620, Tokens per Sec:    16591, Lr: 0.000300\n",
            "2021-05-05 16:23:23,489 - INFO - joeynmt.training - Epoch  25, Step:    60700, Batch Loss:     1.816773, Tokens per Sec:    20638, Lr: 0.000300\n",
            "2021-05-05 16:23:33,786 - INFO - joeynmt.training - Epoch  25, Step:    60800, Batch Loss:     1.762386, Tokens per Sec:    20590, Lr: 0.000300\n",
            "2021-05-05 16:23:44,056 - INFO - joeynmt.training - Epoch  25, Step:    60900, Batch Loss:     1.773802, Tokens per Sec:    20787, Lr: 0.000300\n",
            "2021-05-05 16:23:54,316 - INFO - joeynmt.training - Epoch  25, Step:    61000, Batch Loss:     1.970864, Tokens per Sec:    20681, Lr: 0.000300\n",
            "2021-05-05 16:24:05,577 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:24:05,578 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:24:05,578 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:24:05,815 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:24:05,815 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:24:06,243 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:24:06,243 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:24:06,243 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:24:06,243 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:24:06,243 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:24:06,244 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:24:06,244 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:24:06,244 - INFO - joeynmt.training - \tHypothesis: Jehovah is eager to see his children again .\n",
            "2021-05-05 16:24:06,244 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:24:06,244 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:24:06,244 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:24:06,244 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why the world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:24:06,244 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:24:06,245 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:24:06,245 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:24:06,245 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:24:06,245 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    61000: bleu:  28.06, loss: 41985.3984, ppl:   5.3969, duration: 11.9283s\n",
            "2021-05-05 16:24:16,396 - INFO - joeynmt.training - Epoch  25, Step:    61100, Batch Loss:     1.901122, Tokens per Sec:    20309, Lr: 0.000300\n",
            "2021-05-05 16:24:26,551 - INFO - joeynmt.training - Epoch  25, Step:    61200, Batch Loss:     1.731628, Tokens per Sec:    20572, Lr: 0.000300\n",
            "2021-05-05 16:24:36,777 - INFO - joeynmt.training - Epoch  25, Step:    61300, Batch Loss:     1.850319, Tokens per Sec:    20700, Lr: 0.000300\n",
            "2021-05-05 16:24:46,984 - INFO - joeynmt.training - Epoch  25, Step:    61400, Batch Loss:     1.649306, Tokens per Sec:    20486, Lr: 0.000300\n",
            "2021-05-05 16:24:57,124 - INFO - joeynmt.training - Epoch  25, Step:    61500, Batch Loss:     1.719062, Tokens per Sec:    20536, Lr: 0.000300\n",
            "2021-05-05 16:25:07,392 - INFO - joeynmt.training - Epoch  25, Step:    61600, Batch Loss:     2.038852, Tokens per Sec:    20895, Lr: 0.000300\n",
            "2021-05-05 16:25:17,581 - INFO - joeynmt.training - Epoch  25, Step:    61700, Batch Loss:     2.219180, Tokens per Sec:    20559, Lr: 0.000300\n",
            "2021-05-05 16:25:27,854 - INFO - joeynmt.training - Epoch  25, Step:    61800, Batch Loss:     2.025429, Tokens per Sec:    20508, Lr: 0.000300\n",
            "2021-05-05 16:25:37,977 - INFO - joeynmt.training - Epoch  25, Step:    61900, Batch Loss:     1.921931, Tokens per Sec:    20237, Lr: 0.000300\n",
            "2021-05-05 16:25:48,240 - INFO - joeynmt.training - Epoch  25, Step:    62000, Batch Loss:     1.715781, Tokens per Sec:    20894, Lr: 0.000300\n",
            "2021-05-05 16:25:58,909 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:25:58,910 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:25:58,910 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:25:59,140 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:25:59,140 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:25:59,555 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:25:59,555 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:25:59,555 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:25:59,555 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:25:59,556 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:25:59,556 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:25:59,556 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:25:59,556 - INFO - joeynmt.training - \tHypothesis: Jehovah is hope to see his children again .\n",
            "2021-05-05 16:25:59,556 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:25:59,556 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:25:59,556 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:25:59,556 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why the world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:25:59,556 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:25:59,556 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:25:59,557 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:25:59,557 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of the book of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:25:59,557 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    62000: bleu:  28.18, loss: 41922.5391, ppl:   5.3833, duration: 11.3163s\n",
            "2021-05-05 16:26:09,775 - INFO - joeynmt.training - Epoch  25, Step:    62100, Batch Loss:     1.974749, Tokens per Sec:    20549, Lr: 0.000300\n",
            "2021-05-05 16:26:19,983 - INFO - joeynmt.training - Epoch  25, Step:    62200, Batch Loss:     1.976457, Tokens per Sec:    20615, Lr: 0.000300\n",
            "2021-05-05 16:26:30,169 - INFO - joeynmt.training - Epoch  25, Step:    62300, Batch Loss:     1.112337, Tokens per Sec:    20759, Lr: 0.000300\n",
            "2021-05-05 16:26:40,432 - INFO - joeynmt.training - Epoch  25, Step:    62400, Batch Loss:     1.807733, Tokens per Sec:    20463, Lr: 0.000300\n",
            "2021-05-05 16:26:50,599 - INFO - joeynmt.training - Epoch  25, Step:    62500, Batch Loss:     2.058532, Tokens per Sec:    21094, Lr: 0.000300\n",
            "2021-05-05 16:27:00,868 - INFO - joeynmt.training - Epoch  25, Step:    62600, Batch Loss:     2.013942, Tokens per Sec:    20876, Lr: 0.000300\n",
            "2021-05-05 16:27:11,096 - INFO - joeynmt.training - Epoch  25, Step:    62700, Batch Loss:     1.751585, Tokens per Sec:    20720, Lr: 0.000300\n",
            "2021-05-05 16:27:21,192 - INFO - joeynmt.training - Epoch  25, Step:    62800, Batch Loss:     1.844581, Tokens per Sec:    20324, Lr: 0.000300\n",
            "2021-05-05 16:27:31,475 - INFO - joeynmt.training - Epoch  25, Step:    62900, Batch Loss:     1.938248, Tokens per Sec:    20980, Lr: 0.000300\n",
            "2021-05-05 16:27:41,680 - INFO - joeynmt.training - Epoch  25, Step:    63000, Batch Loss:     1.557330, Tokens per Sec:    20335, Lr: 0.000300\n",
            "2021-05-05 16:27:52,467 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:27:52,467 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:27:52,467 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:27:52,698 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:27:52,698 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:27:53,113 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:27:53,113 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:27:53,113 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:27:53,113 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:27:53,113 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:27:53,114 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:27:53,114 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:27:53,114 - INFO - joeynmt.training - \tHypothesis: Jehovah is hope to see his children again .\n",
            "2021-05-05 16:27:53,114 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:27:53,114 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:27:53,114 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:27:53,114 - INFO - joeynmt.training - \tHypothesis: The Masters recognize that this is why world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:27:53,114 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:27:53,114 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:27:53,115 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:27:53,115 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:27:53,115 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    63000: bleu:  28.26, loss: 41922.5234, ppl:   5.3833, duration: 11.4340s\n",
            "2021-05-05 16:28:03,327 - INFO - joeynmt.training - Epoch  25, Step:    63100, Batch Loss:     1.874888, Tokens per Sec:    20364, Lr: 0.000300\n",
            "2021-05-05 16:28:04,029 - INFO - joeynmt.training - Epoch  25: total training loss 4691.90\n",
            "2021-05-05 16:28:04,030 - INFO - joeynmt.training - EPOCH 26\n",
            "2021-05-05 16:28:13,799 - INFO - joeynmt.training - Epoch  26, Step:    63200, Batch Loss:     1.982898, Tokens per Sec:    19958, Lr: 0.000300\n",
            "2021-05-05 16:28:23,992 - INFO - joeynmt.training - Epoch  26, Step:    63300, Batch Loss:     1.885091, Tokens per Sec:    20822, Lr: 0.000300\n",
            "2021-05-05 16:28:34,147 - INFO - joeynmt.training - Epoch  26, Step:    63400, Batch Loss:     1.933767, Tokens per Sec:    20605, Lr: 0.000300\n",
            "2021-05-05 16:28:44,336 - INFO - joeynmt.training - Epoch  26, Step:    63500, Batch Loss:     1.998833, Tokens per Sec:    20776, Lr: 0.000300\n",
            "2021-05-05 16:28:54,404 - INFO - joeynmt.training - Epoch  26, Step:    63600, Batch Loss:     2.012213, Tokens per Sec:    20203, Lr: 0.000300\n",
            "2021-05-05 16:29:04,633 - INFO - joeynmt.training - Epoch  26, Step:    63700, Batch Loss:     1.741747, Tokens per Sec:    20455, Lr: 0.000300\n",
            "2021-05-05 16:29:14,835 - INFO - joeynmt.training - Epoch  26, Step:    63800, Batch Loss:     1.851199, Tokens per Sec:    20711, Lr: 0.000300\n",
            "2021-05-05 16:29:25,177 - INFO - joeynmt.training - Epoch  26, Step:    63900, Batch Loss:     1.864408, Tokens per Sec:    21022, Lr: 0.000300\n",
            "2021-05-05 16:29:35,378 - INFO - joeynmt.training - Epoch  26, Step:    64000, Batch Loss:     1.879351, Tokens per Sec:    20502, Lr: 0.000300\n",
            "2021-05-05 16:29:46,409 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:29:46,410 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:29:46,410 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:29:46,638 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:29:46,638 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:29:47,019 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:29:47,019 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:29:47,020 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:29:47,020 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:29:47,020 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:29:47,020 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:29:47,020 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:29:47,020 - INFO - joeynmt.training - \tHypothesis: Jehovah is the prospect of seeing his children again .\n",
            "2021-05-05 16:29:47,020 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:29:47,020 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:29:47,020 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:29:47,020 - INFO - joeynmt.training - \tHypothesis: The Mass realize that this is why the world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:29:47,021 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:29:47,021 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:29:47,021 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:29:47,021 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul reveals the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:29:47,021 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    64000: bleu:  28.57, loss: 41714.7656, ppl:   5.3386, duration: 11.6424s\n",
            "2021-05-05 16:29:57,324 - INFO - joeynmt.training - Epoch  26, Step:    64100, Batch Loss:     1.762656, Tokens per Sec:    21023, Lr: 0.000300\n",
            "2021-05-05 16:30:07,450 - INFO - joeynmt.training - Epoch  26, Step:    64200, Batch Loss:     1.902537, Tokens per Sec:    20287, Lr: 0.000300\n",
            "2021-05-05 16:30:17,633 - INFO - joeynmt.training - Epoch  26, Step:    64300, Batch Loss:     1.881596, Tokens per Sec:    20546, Lr: 0.000300\n",
            "2021-05-05 16:30:27,901 - INFO - joeynmt.training - Epoch  26, Step:    64400, Batch Loss:     2.065339, Tokens per Sec:    20961, Lr: 0.000300\n",
            "2021-05-05 16:30:37,957 - INFO - joeynmt.training - Epoch  26, Step:    64500, Batch Loss:     2.037998, Tokens per Sec:    20509, Lr: 0.000300\n",
            "2021-05-05 16:30:48,178 - INFO - joeynmt.training - Epoch  26, Step:    64600, Batch Loss:     1.358320, Tokens per Sec:    20774, Lr: 0.000300\n",
            "2021-05-05 16:30:58,443 - INFO - joeynmt.training - Epoch  26, Step:    64700, Batch Loss:     1.883185, Tokens per Sec:    20754, Lr: 0.000300\n",
            "2021-05-05 16:31:08,660 - INFO - joeynmt.training - Epoch  26, Step:    64800, Batch Loss:     1.845379, Tokens per Sec:    20820, Lr: 0.000300\n",
            "2021-05-05 16:31:18,808 - INFO - joeynmt.training - Epoch  26, Step:    64900, Batch Loss:     1.913812, Tokens per Sec:    20548, Lr: 0.000300\n",
            "2021-05-05 16:31:29,027 - INFO - joeynmt.training - Epoch  26, Step:    65000, Batch Loss:     1.906886, Tokens per Sec:    20596, Lr: 0.000300\n",
            "2021-05-05 16:31:39,745 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:31:39,746 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:31:39,746 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:31:39,984 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:31:39,984 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:31:40,399 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:31:40,400 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:31:40,400 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:31:40,400 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:31:40,400 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:31:40,400 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:31:40,400 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:31:40,400 - INFO - joeynmt.training - \tHypothesis: Jehovah is eager to see his children again .\n",
            "2021-05-05 16:31:40,400 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:31:40,400 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:31:40,401 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:31:40,401 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why the world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:31:40,401 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:31:40,401 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:31:40,401 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:31:40,401 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul reveals the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:31:40,401 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    65000: bleu:  28.36, loss: 41628.2852, ppl:   5.3201, duration: 11.3735s\n",
            "2021-05-05 16:31:50,571 - INFO - joeynmt.training - Epoch  26, Step:    65100, Batch Loss:     1.767599, Tokens per Sec:    20294, Lr: 0.000300\n",
            "2021-05-05 16:32:00,808 - INFO - joeynmt.training - Epoch  26, Step:    65200, Batch Loss:     1.789611, Tokens per Sec:    20821, Lr: 0.000300\n",
            "2021-05-05 16:32:11,028 - INFO - joeynmt.training - Epoch  26, Step:    65300, Batch Loss:     1.971038, Tokens per Sec:    21045, Lr: 0.000300\n",
            "2021-05-05 16:32:21,251 - INFO - joeynmt.training - Epoch  26, Step:    65400, Batch Loss:     1.957147, Tokens per Sec:    20944, Lr: 0.000300\n",
            "2021-05-05 16:32:31,435 - INFO - joeynmt.training - Epoch  26, Step:    65500, Batch Loss:     1.950105, Tokens per Sec:    20450, Lr: 0.000300\n",
            "2021-05-05 16:32:41,602 - INFO - joeynmt.training - Epoch  26, Step:    65600, Batch Loss:     1.844869, Tokens per Sec:    20348, Lr: 0.000300\n",
            "2021-05-05 16:32:44,384 - INFO - joeynmt.training - Epoch  26: total training loss 4670.45\n",
            "2021-05-05 16:32:44,385 - INFO - joeynmt.training - EPOCH 27\n",
            "2021-05-05 16:32:52,267 - INFO - joeynmt.training - Epoch  27, Step:    65700, Batch Loss:     1.483222, Tokens per Sec:    19881, Lr: 0.000300\n",
            "2021-05-05 16:33:02,445 - INFO - joeynmt.training - Epoch  27, Step:    65800, Batch Loss:     1.701819, Tokens per Sec:    20235, Lr: 0.000300\n",
            "2021-05-05 16:33:12,619 - INFO - joeynmt.training - Epoch  27, Step:    65900, Batch Loss:     1.904172, Tokens per Sec:    20227, Lr: 0.000300\n",
            "2021-05-05 16:33:22,837 - INFO - joeynmt.training - Epoch  27, Step:    66000, Batch Loss:     1.776513, Tokens per Sec:    20948, Lr: 0.000300\n",
            "2021-05-05 16:33:33,853 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:33:33,853 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:33:33,853 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:33:34,490 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:33:34,490 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:33:34,490 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:33:34,490 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:33:34,490 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:33:34,490 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:33:34,490 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:33:34,491 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 16:33:34,491 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:33:34,491 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:33:34,491 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:33:34,491 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:33:34,491 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:33:34,491 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:33:34,491 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:33:34,491 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:33:34,491 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    66000: bleu:  28.42, loss: 41646.3789, ppl:   5.3239, duration: 11.6535s\n",
            "2021-05-05 16:33:44,738 - INFO - joeynmt.training - Epoch  27, Step:    66100, Batch Loss:     1.973058, Tokens per Sec:    20719, Lr: 0.000300\n",
            "2021-05-05 16:33:54,934 - INFO - joeynmt.training - Epoch  27, Step:    66200, Batch Loss:     1.755670, Tokens per Sec:    20574, Lr: 0.000300\n",
            "2021-05-05 16:34:05,141 - INFO - joeynmt.training - Epoch  27, Step:    66300, Batch Loss:     1.943871, Tokens per Sec:    20468, Lr: 0.000300\n",
            "2021-05-05 16:34:15,274 - INFO - joeynmt.training - Epoch  27, Step:    66400, Batch Loss:     1.933906, Tokens per Sec:    20708, Lr: 0.000300\n",
            "2021-05-05 16:34:25,516 - INFO - joeynmt.training - Epoch  27, Step:    66500, Batch Loss:     1.827657, Tokens per Sec:    20990, Lr: 0.000300\n",
            "2021-05-05 16:34:35,620 - INFO - joeynmt.training - Epoch  27, Step:    66600, Batch Loss:     1.705453, Tokens per Sec:    20251, Lr: 0.000300\n",
            "2021-05-05 16:34:45,835 - INFO - joeynmt.training - Epoch  27, Step:    66700, Batch Loss:     1.777645, Tokens per Sec:    20409, Lr: 0.000300\n",
            "2021-05-05 16:34:56,025 - INFO - joeynmt.training - Epoch  27, Step:    66800, Batch Loss:     1.848832, Tokens per Sec:    20245, Lr: 0.000300\n",
            "2021-05-05 16:35:06,200 - INFO - joeynmt.training - Epoch  27, Step:    66900, Batch Loss:     1.903172, Tokens per Sec:    20696, Lr: 0.000300\n",
            "2021-05-05 16:35:16,454 - INFO - joeynmt.training - Epoch  27, Step:    67000, Batch Loss:     2.010145, Tokens per Sec:    20818, Lr: 0.000300\n",
            "2021-05-05 16:35:27,832 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:35:27,832 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:35:27,832 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:35:28,066 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:35:28,066 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:35:28,492 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:35:28,492 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:35:28,492 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:35:28,492 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:35:28,492 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:35:28,492 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:35:28,492 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:35:28,492 - INFO - joeynmt.training - \tHypothesis: Jehovah is hoped to see his children again .\n",
            "2021-05-05 16:35:28,493 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:35:28,493 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:35:28,493 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:35:28,493 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why the world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:35:28,493 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:35:28,493 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:35:28,493 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:35:28,493 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul reveals the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:35:28,493 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    67000: bleu:  27.92, loss: 41394.4688, ppl:   5.2703, duration: 12.0389s\n",
            "2021-05-05 16:35:38,673 - INFO - joeynmt.training - Epoch  27, Step:    67100, Batch Loss:     1.784418, Tokens per Sec:    20100, Lr: 0.000300\n",
            "2021-05-05 16:35:48,819 - INFO - joeynmt.training - Epoch  27, Step:    67200, Batch Loss:     1.641026, Tokens per Sec:    20179, Lr: 0.000300\n",
            "2021-05-05 16:35:59,114 - INFO - joeynmt.training - Epoch  27, Step:    67300, Batch Loss:     1.977256, Tokens per Sec:    20865, Lr: 0.000300\n",
            "2021-05-05 16:36:09,386 - INFO - joeynmt.training - Epoch  27, Step:    67400, Batch Loss:     1.943895, Tokens per Sec:    20582, Lr: 0.000300\n",
            "2021-05-05 16:36:19,599 - INFO - joeynmt.training - Epoch  27, Step:    67500, Batch Loss:     1.931667, Tokens per Sec:    20579, Lr: 0.000300\n",
            "2021-05-05 16:36:29,817 - INFO - joeynmt.training - Epoch  27, Step:    67600, Batch Loss:     2.000580, Tokens per Sec:    20630, Lr: 0.000300\n",
            "2021-05-05 16:36:40,062 - INFO - joeynmt.training - Epoch  27, Step:    67700, Batch Loss:     1.823328, Tokens per Sec:    21004, Lr: 0.000300\n",
            "2021-05-05 16:36:50,307 - INFO - joeynmt.training - Epoch  27, Step:    67800, Batch Loss:     1.809083, Tokens per Sec:    20865, Lr: 0.000300\n",
            "2021-05-05 16:37:00,653 - INFO - joeynmt.training - Epoch  27, Step:    67900, Batch Loss:     1.604234, Tokens per Sec:    20934, Lr: 0.000300\n",
            "2021-05-05 16:37:10,858 - INFO - joeynmt.training - Epoch  27, Step:    68000, Batch Loss:     1.789873, Tokens per Sec:    20499, Lr: 0.000300\n",
            "2021-05-05 16:37:21,464 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:37:21,464 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:37:21,464 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:37:21,706 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:37:21,707 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:37:22,118 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:37:22,118 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:37:22,118 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:37:22,118 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:37:22,118 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:37:22,119 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:37:22,119 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:37:22,119 - INFO - joeynmt.training - \tHypothesis: Jehovah is hoped to see his children again .\n",
            "2021-05-05 16:37:22,119 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:37:22,119 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:37:22,119 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:37:22,119 - INFO - joeynmt.training - \tHypothesis: The scholars have seen that this is why the world governments cannot end to corruption and corruption .\n",
            "2021-05-05 16:37:22,119 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:37:22,119 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:37:22,119 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:37:22,120 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:37:22,120 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    68000: bleu:  28.88, loss: 41300.2188, ppl:   5.2504, duration: 11.2611s\n",
            "2021-05-05 16:37:32,370 - INFO - joeynmt.training - Epoch  27, Step:    68100, Batch Loss:     1.774336, Tokens per Sec:    20625, Lr: 0.000300\n",
            "2021-05-05 16:37:37,555 - INFO - joeynmt.training - Epoch  27: total training loss 4646.17\n",
            "2021-05-05 16:37:37,556 - INFO - joeynmt.training - EPOCH 28\n",
            "2021-05-05 16:37:42,870 - INFO - joeynmt.training - Epoch  28, Step:    68200, Batch Loss:     1.979474, Tokens per Sec:    19956, Lr: 0.000300\n",
            "2021-05-05 16:37:53,155 - INFO - joeynmt.training - Epoch  28, Step:    68300, Batch Loss:     2.084852, Tokens per Sec:    20790, Lr: 0.000300\n",
            "2021-05-05 16:38:03,405 - INFO - joeynmt.training - Epoch  28, Step:    68400, Batch Loss:     1.827855, Tokens per Sec:    20828, Lr: 0.000300\n",
            "2021-05-05 16:38:13,615 - INFO - joeynmt.training - Epoch  28, Step:    68500, Batch Loss:     1.848577, Tokens per Sec:    20483, Lr: 0.000300\n",
            "2021-05-05 16:38:23,904 - INFO - joeynmt.training - Epoch  28, Step:    68600, Batch Loss:     1.888596, Tokens per Sec:    20504, Lr: 0.000300\n",
            "2021-05-05 16:38:34,071 - INFO - joeynmt.training - Epoch  28, Step:    68700, Batch Loss:     1.699668, Tokens per Sec:    20509, Lr: 0.000300\n",
            "2021-05-05 16:38:44,152 - INFO - joeynmt.training - Epoch  28, Step:    68800, Batch Loss:     1.860112, Tokens per Sec:    20360, Lr: 0.000300\n",
            "2021-05-05 16:38:54,384 - INFO - joeynmt.training - Epoch  28, Step:    68900, Batch Loss:     1.755111, Tokens per Sec:    20809, Lr: 0.000300\n",
            "2021-05-05 16:39:04,508 - INFO - joeynmt.training - Epoch  28, Step:    69000, Batch Loss:     1.893638, Tokens per Sec:    20646, Lr: 0.000300\n",
            "2021-05-05 16:39:15,115 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:39:15,115 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:39:15,115 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:39:15,733 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:39:15,733 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:39:15,733 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:39:15,733 - INFO - joeynmt.training - \tHypothesis: And they will find peace because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:39:15,733 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:39:15,734 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:39:15,734 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:39:15,734 - INFO - joeynmt.training - \tHypothesis: Jehovah is eager to see his children again .\n",
            "2021-05-05 16:39:15,734 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:39:15,734 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:39:15,734 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:39:15,734 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:39:15,734 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:39:15,734 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:39:15,734 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:39:15,734 - INFO - joeynmt.training - \tHypothesis: In chapter 7 , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:39:15,735 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    69000: bleu:  28.36, loss: 41555.4336, ppl:   5.3045, duration: 11.2266s\n",
            "2021-05-05 16:39:25,994 - INFO - joeynmt.training - Epoch  28, Step:    69100, Batch Loss:     2.154384, Tokens per Sec:    20731, Lr: 0.000300\n",
            "2021-05-05 16:39:36,191 - INFO - joeynmt.training - Epoch  28, Step:    69200, Batch Loss:     1.871474, Tokens per Sec:    20584, Lr: 0.000300\n",
            "2021-05-05 16:39:46,465 - INFO - joeynmt.training - Epoch  28, Step:    69300, Batch Loss:     1.704069, Tokens per Sec:    20578, Lr: 0.000300\n",
            "2021-05-05 16:39:56,582 - INFO - joeynmt.training - Epoch  28, Step:    69400, Batch Loss:     1.628701, Tokens per Sec:    20601, Lr: 0.000300\n",
            "2021-05-05 16:40:06,836 - INFO - joeynmt.training - Epoch  28, Step:    69500, Batch Loss:     2.023340, Tokens per Sec:    20596, Lr: 0.000300\n",
            "2021-05-05 16:40:17,130 - INFO - joeynmt.training - Epoch  28, Step:    69600, Batch Loss:     1.879269, Tokens per Sec:    20459, Lr: 0.000300\n",
            "2021-05-05 16:40:27,320 - INFO - joeynmt.training - Epoch  28, Step:    69700, Batch Loss:     1.984337, Tokens per Sec:    20567, Lr: 0.000300\n",
            "2021-05-05 16:40:37,562 - INFO - joeynmt.training - Epoch  28, Step:    69800, Batch Loss:     1.841875, Tokens per Sec:    20919, Lr: 0.000300\n",
            "2021-05-05 16:40:47,760 - INFO - joeynmt.training - Epoch  28, Step:    69900, Batch Loss:     1.193054, Tokens per Sec:    20209, Lr: 0.000300\n",
            "2021-05-05 16:40:57,986 - INFO - joeynmt.training - Epoch  28, Step:    70000, Batch Loss:     1.872170, Tokens per Sec:    20606, Lr: 0.000300\n",
            "2021-05-05 16:41:08,690 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:41:08,690 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:41:08,690 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:41:09,354 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:41:09,355 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:41:09,355 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:41:09,355 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:41:09,355 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:41:09,355 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:41:09,355 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:41:09,356 - INFO - joeynmt.training - \tHypothesis: Jehovah is hoped to see his children again .\n",
            "2021-05-05 16:41:09,356 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:41:09,356 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:41:09,356 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:41:09,356 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:41:09,356 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:41:09,356 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:41:09,356 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:41:09,356 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:41:09,356 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    70000: bleu:  28.81, loss: 41430.0312, ppl:   5.2779, duration: 11.3695s\n",
            "2021-05-05 16:41:19,630 - INFO - joeynmt.training - Epoch  28, Step:    70100, Batch Loss:     1.791426, Tokens per Sec:    20836, Lr: 0.000300\n",
            "2021-05-05 16:41:29,984 - INFO - joeynmt.training - Epoch  28, Step:    70200, Batch Loss:     1.862105, Tokens per Sec:    20265, Lr: 0.000300\n",
            "2021-05-05 16:41:40,346 - INFO - joeynmt.training - Epoch  28, Step:    70300, Batch Loss:     1.863498, Tokens per Sec:    20509, Lr: 0.000300\n",
            "2021-05-05 16:41:50,656 - INFO - joeynmt.training - Epoch  28, Step:    70400, Batch Loss:     1.592111, Tokens per Sec:    20423, Lr: 0.000300\n",
            "2021-05-05 16:42:00,966 - INFO - joeynmt.training - Epoch  28, Step:    70500, Batch Loss:     2.124076, Tokens per Sec:    20349, Lr: 0.000300\n",
            "2021-05-05 16:42:11,272 - INFO - joeynmt.training - Epoch  28, Step:    70600, Batch Loss:     1.834848, Tokens per Sec:    20181, Lr: 0.000300\n",
            "2021-05-05 16:42:18,800 - INFO - joeynmt.training - Epoch  28: total training loss 4626.35\n",
            "2021-05-05 16:42:18,800 - INFO - joeynmt.training - EPOCH 29\n",
            "2021-05-05 16:42:21,815 - INFO - joeynmt.training - Epoch  29, Step:    70700, Batch Loss:     1.749760, Tokens per Sec:    18952, Lr: 0.000300\n",
            "2021-05-05 16:42:32,092 - INFO - joeynmt.training - Epoch  29, Step:    70800, Batch Loss:     2.014573, Tokens per Sec:    20775, Lr: 0.000300\n",
            "2021-05-05 16:42:42,395 - INFO - joeynmt.training - Epoch  29, Step:    70900, Batch Loss:     1.559365, Tokens per Sec:    20308, Lr: 0.000300\n",
            "2021-05-05 16:42:52,646 - INFO - joeynmt.training - Epoch  29, Step:    71000, Batch Loss:     2.043731, Tokens per Sec:    20362, Lr: 0.000300\n",
            "2021-05-05 16:43:03,759 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:43:03,759 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:43:03,759 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:43:04,403 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:43:04,403 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:43:04,403 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:43:04,403 - INFO - joeynmt.training - \tHypothesis: And they will find security because they apply Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:43:04,403 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:43:04,403 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:43:04,403 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:43:04,404 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 16:43:04,404 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:43:04,404 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:43:04,404 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:43:04,404 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:43:04,404 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:43:04,404 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:43:04,404 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:43:04,405 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of the book of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:43:04,405 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    71000: bleu:  28.92, loss: 41398.3281, ppl:   5.2712, duration: 11.7580s\n",
            "2021-05-05 16:43:14,600 - INFO - joeynmt.training - Epoch  29, Step:    71100, Batch Loss:     1.974053, Tokens per Sec:    20331, Lr: 0.000300\n",
            "2021-05-05 16:43:24,900 - INFO - joeynmt.training - Epoch  29, Step:    71200, Batch Loss:     1.943231, Tokens per Sec:    20909, Lr: 0.000300\n",
            "2021-05-05 16:43:35,095 - INFO - joeynmt.training - Epoch  29, Step:    71300, Batch Loss:     2.043123, Tokens per Sec:    20346, Lr: 0.000300\n",
            "2021-05-05 16:43:45,294 - INFO - joeynmt.training - Epoch  29, Step:    71400, Batch Loss:     2.003706, Tokens per Sec:    20648, Lr: 0.000300\n",
            "2021-05-05 16:43:55,439 - INFO - joeynmt.training - Epoch  29, Step:    71500, Batch Loss:     1.971063, Tokens per Sec:    20222, Lr: 0.000300\n",
            "2021-05-05 16:44:05,664 - INFO - joeynmt.training - Epoch  29, Step:    71600, Batch Loss:     1.720377, Tokens per Sec:    20353, Lr: 0.000300\n",
            "2021-05-05 16:44:15,850 - INFO - joeynmt.training - Epoch  29, Step:    71700, Batch Loss:     1.720845, Tokens per Sec:    20581, Lr: 0.000300\n",
            "2021-05-05 16:44:26,061 - INFO - joeynmt.training - Epoch  29, Step:    71800, Batch Loss:     2.157460, Tokens per Sec:    20928, Lr: 0.000300\n",
            "2021-05-05 16:44:36,248 - INFO - joeynmt.training - Epoch  29, Step:    71900, Batch Loss:     1.974474, Tokens per Sec:    20372, Lr: 0.000300\n",
            "2021-05-05 16:44:46,324 - INFO - joeynmt.training - Epoch  29, Step:    72000, Batch Loss:     1.302631, Tokens per Sec:    20533, Lr: 0.000300\n",
            "2021-05-05 16:44:57,271 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:44:57,271 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:44:57,271 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:44:57,946 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:44:57,947 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:44:57,947 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:44:57,947 - INFO - joeynmt.training - \tHypothesis: And they will find security because they heed Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:44:57,947 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:44:57,947 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:44:57,947 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:44:57,947 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 16:44:57,947 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:44:57,947 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:44:57,947 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:44:57,948 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:44:57,948 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:44:57,948 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:44:57,948 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:44:57,948 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:44:57,948 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    72000: bleu:  28.84, loss: 41336.2930, ppl:   5.2580, duration: 11.6241s\n",
            "2021-05-05 16:45:08,135 - INFO - joeynmt.training - Epoch  29, Step:    72100, Batch Loss:     2.060237, Tokens per Sec:    20139, Lr: 0.000300\n",
            "2021-05-05 16:45:18,394 - INFO - joeynmt.training - Epoch  29, Step:    72200, Batch Loss:     2.118624, Tokens per Sec:    20682, Lr: 0.000300\n",
            "2021-05-05 16:45:28,706 - INFO - joeynmt.training - Epoch  29, Step:    72300, Batch Loss:     1.774109, Tokens per Sec:    20789, Lr: 0.000300\n",
            "2021-05-05 16:45:38,909 - INFO - joeynmt.training - Epoch  29, Step:    72400, Batch Loss:     2.054914, Tokens per Sec:    20377, Lr: 0.000300\n",
            "2021-05-05 16:45:49,148 - INFO - joeynmt.training - Epoch  29, Step:    72500, Batch Loss:     1.662699, Tokens per Sec:    20549, Lr: 0.000300\n",
            "2021-05-05 16:45:59,405 - INFO - joeynmt.training - Epoch  29, Step:    72600, Batch Loss:     2.043568, Tokens per Sec:    20591, Lr: 0.000300\n",
            "2021-05-05 16:46:09,670 - INFO - joeynmt.training - Epoch  29, Step:    72700, Batch Loss:     1.884494, Tokens per Sec:    20780, Lr: 0.000300\n",
            "2021-05-05 16:46:19,859 - INFO - joeynmt.training - Epoch  29, Step:    72800, Batch Loss:     1.815910, Tokens per Sec:    20593, Lr: 0.000300\n",
            "2021-05-05 16:46:29,984 - INFO - joeynmt.training - Epoch  29, Step:    72900, Batch Loss:     1.726565, Tokens per Sec:    20441, Lr: 0.000300\n",
            "2021-05-05 16:46:40,047 - INFO - joeynmt.training - Epoch  29, Step:    73000, Batch Loss:     1.886080, Tokens per Sec:    20478, Lr: 0.000300\n",
            "2021-05-05 16:46:51,258 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:46:51,258 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:46:51,258 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:46:51,492 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:46:51,492 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:46:51,949 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:46:51,949 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:46:51,949 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:46:51,949 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:46:51,949 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:46:51,950 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:46:51,950 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:46:51,950 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 16:46:51,950 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:46:51,950 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:46:51,950 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:46:51,950 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why the world governments cannot end corruption and corruption .\n",
            "2021-05-05 16:46:51,950 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:46:51,950 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:46:51,950 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:46:51,951 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:46:51,951 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    73000: bleu:  28.53, loss: 41161.9297, ppl:   5.2214, duration: 11.9027s\n",
            "2021-05-05 16:47:02,261 - INFO - joeynmt.training - Epoch  29, Step:    73100, Batch Loss:     1.813620, Tokens per Sec:    20533, Lr: 0.000300\n",
            "2021-05-05 16:47:12,559 - INFO - joeynmt.training - Epoch  29, Step:    73200, Batch Loss:     1.981269, Tokens per Sec:    20976, Lr: 0.000300\n",
            "2021-05-05 16:47:12,770 - INFO - joeynmt.training - Epoch  29: total training loss 4613.63\n",
            "2021-05-05 16:47:12,770 - INFO - joeynmt.training - EPOCH 30\n",
            "2021-05-05 16:47:23,113 - INFO - joeynmt.training - Epoch  30, Step:    73300, Batch Loss:     2.099507, Tokens per Sec:    19567, Lr: 0.000300\n",
            "2021-05-05 16:47:33,392 - INFO - joeynmt.training - Epoch  30, Step:    73400, Batch Loss:     2.016699, Tokens per Sec:    20641, Lr: 0.000300\n",
            "2021-05-05 16:47:43,577 - INFO - joeynmt.training - Epoch  30, Step:    73500, Batch Loss:     1.913988, Tokens per Sec:    20996, Lr: 0.000300\n",
            "2021-05-05 16:47:53,736 - INFO - joeynmt.training - Epoch  30, Step:    73600, Batch Loss:     1.861450, Tokens per Sec:    20610, Lr: 0.000300\n",
            "2021-05-05 16:48:04,000 - INFO - joeynmt.training - Epoch  30, Step:    73700, Batch Loss:     1.805262, Tokens per Sec:    20877, Lr: 0.000300\n",
            "2021-05-05 16:48:14,229 - INFO - joeynmt.training - Epoch  30, Step:    73800, Batch Loss:     1.881631, Tokens per Sec:    20837, Lr: 0.000300\n",
            "2021-05-05 16:48:24,530 - INFO - joeynmt.training - Epoch  30, Step:    73900, Batch Loss:     1.642363, Tokens per Sec:    20671, Lr: 0.000300\n",
            "2021-05-05 16:48:34,768 - INFO - joeynmt.training - Epoch  30, Step:    74000, Batch Loss:     1.848840, Tokens per Sec:    20833, Lr: 0.000300\n",
            "2021-05-05 16:48:45,549 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:48:45,550 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:48:45,550 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:48:45,781 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:48:45,781 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:48:46,154 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:48:46,154 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:48:46,154 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:48:46,154 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:48:46,155 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:48:46,155 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:48:46,155 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:48:46,155 - INFO - joeynmt.training - \tHypothesis: Jehovah hope to see his children again .\n",
            "2021-05-05 16:48:46,155 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:48:46,155 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:48:46,155 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:48:46,155 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why the world governments cannot bring an end to corruption and corruption .\n",
            "2021-05-05 16:48:46,155 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:48:46,155 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:48:46,155 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:48:46,155 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul revealed the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:48:46,156 - INFO - joeynmt.training - Validation result (greedy) at epoch  30, step    74000: bleu:  28.71, loss: 41123.1055, ppl:   5.2132, duration: 11.3870s\n",
            "2021-05-05 16:48:56,494 - INFO - joeynmt.training - Epoch  30, Step:    74100, Batch Loss:     1.989806, Tokens per Sec:    20556, Lr: 0.000300\n",
            "2021-05-05 16:49:06,836 - INFO - joeynmt.training - Epoch  30, Step:    74200, Batch Loss:     1.795804, Tokens per Sec:    20679, Lr: 0.000300\n",
            "2021-05-05 16:49:17,113 - INFO - joeynmt.training - Epoch  30, Step:    74300, Batch Loss:     1.840080, Tokens per Sec:    20626, Lr: 0.000300\n",
            "2021-05-05 16:49:27,409 - INFO - joeynmt.training - Epoch  30, Step:    74400, Batch Loss:     1.903285, Tokens per Sec:    20784, Lr: 0.000300\n",
            "2021-05-05 16:49:37,777 - INFO - joeynmt.training - Epoch  30, Step:    74500, Batch Loss:     2.163499, Tokens per Sec:    20608, Lr: 0.000300\n",
            "2021-05-05 16:49:47,986 - INFO - joeynmt.training - Epoch  30, Step:    74600, Batch Loss:     2.057750, Tokens per Sec:    20301, Lr: 0.000300\n",
            "2021-05-05 16:49:58,314 - INFO - joeynmt.training - Epoch  30, Step:    74700, Batch Loss:     1.912521, Tokens per Sec:    20909, Lr: 0.000300\n",
            "2021-05-05 16:50:08,555 - INFO - joeynmt.training - Epoch  30, Step:    74800, Batch Loss:     1.813411, Tokens per Sec:    19997, Lr: 0.000300\n",
            "2021-05-05 16:50:18,633 - INFO - joeynmt.training - Epoch  30, Step:    74900, Batch Loss:     1.945461, Tokens per Sec:    20589, Lr: 0.000300\n",
            "2021-05-05 16:50:28,905 - INFO - joeynmt.training - Epoch  30, Step:    75000, Batch Loss:     1.821300, Tokens per Sec:    20639, Lr: 0.000300\n",
            "2021-05-05 16:50:40,047 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:50:40,047 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:50:40,048 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:50:40,281 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-05 16:50:40,281 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-05 16:50:40,702 - INFO - joeynmt.training - Example #0\n",
            "2021-05-05 16:50:40,703 - INFO - joeynmt.training - \tSource:     ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-05 16:50:40,703 - INFO - joeynmt.training - \tReference:  They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:50:40,703 - INFO - joeynmt.training - \tHypothesis: And they will find security because they follow Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-05 16:50:40,703 - INFO - joeynmt.training - Example #1\n",
            "2021-05-05 16:50:40,703 - INFO - joeynmt.training - \tSource:     ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-05 16:50:40,703 - INFO - joeynmt.training - \tReference:  * By all means I shall have pity upon him . ”\n",
            "2021-05-05 16:50:40,703 - INFO - joeynmt.training - \tHypothesis: Jehovah has the prospect of seeing his children again .\n",
            "2021-05-05 16:50:40,703 - INFO - joeynmt.training - Example #2\n",
            "2021-05-05 16:50:40,703 - INFO - joeynmt.training - \tSource:     Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "2021-05-05 16:50:40,704 - INFO - joeynmt.training - \tReference:  Experts admit that this is why human governments cannot eliminate corruption .\n",
            "2021-05-05 16:50:40,704 - INFO - joeynmt.training - \tHypothesis: The scholars realize that this is why the world governments cannot end to corruption and corruption .\n",
            "2021-05-05 16:50:40,704 - INFO - joeynmt.training - Example #3\n",
            "2021-05-05 16:50:40,704 - INFO - joeynmt.training - \tSource:     A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "2021-05-05 16:50:40,704 - INFO - joeynmt.training - \tReference:  In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "2021-05-05 16:50:40,704 - INFO - joeynmt.training - \tHypothesis: In chapter 7 of Romans , Paul reveals the power of sin in our imperfect flesh .\n",
            "2021-05-05 16:50:40,704 - INFO - joeynmt.training - Validation result (greedy) at epoch  30, step    75000: bleu:  28.97, loss: 41080.0156, ppl:   5.2042, duration: 11.7983s\n",
            "2021-05-05 16:50:50,936 - INFO - joeynmt.training - Epoch  30, Step:    75100, Batch Loss:     1.874350, Tokens per Sec:    20487, Lr: 0.000300\n",
            "2021-05-05 16:51:01,159 - INFO - joeynmt.training - Epoch  30, Step:    75200, Batch Loss:     1.640849, Tokens per Sec:    19886, Lr: 0.000300\n",
            "2021-05-05 16:51:11,385 - INFO - joeynmt.training - Epoch  30, Step:    75300, Batch Loss:     1.690557, Tokens per Sec:    20460, Lr: 0.000300\n",
            "2021-05-05 16:51:21,567 - INFO - joeynmt.training - Epoch  30, Step:    75400, Batch Loss:     1.807415, Tokens per Sec:    20456, Lr: 0.000300\n",
            "2021-05-05 16:51:31,708 - INFO - joeynmt.training - Epoch  30, Step:    75500, Batch Loss:     1.613224, Tokens per Sec:    20620, Lr: 0.000300\n",
            "2021-05-05 16:51:41,923 - INFO - joeynmt.training - Epoch  30, Step:    75600, Batch Loss:     2.018558, Tokens per Sec:    20588, Lr: 0.000300\n",
            "2021-05-05 16:51:52,159 - INFO - joeynmt.training - Epoch  30, Step:    75700, Batch Loss:     1.958797, Tokens per Sec:    20272, Lr: 0.000300\n",
            "2021-05-05 16:51:54,441 - INFO - joeynmt.training - Epoch  30: total training loss 4575.76\n",
            "2021-05-05 16:51:54,441 - INFO - joeynmt.training - Training ended after  30 epochs.\n",
            "2021-05-05 16:51:54,441 - INFO - joeynmt.training - Best validation result (greedy) at step    75000:   5.20 ppl.\n",
            "2021-05-05 16:51:54,460 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 1, batch_size per device: 18000 (with beam_size)\n",
            "2021-05-05 16:51:54,634 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
            "2021-05-05 16:51:54,839 - INFO - joeynmt.model - Enc-dec model built.\n",
            "2021-05-05 16:51:54,909 - INFO - joeynmt.prediction - Decoding on dev set (data/haen/dev.bpe.en)...\n",
            "2021-05-05 16:52:09,158 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:52:09,158 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:52:09,159 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:52:09,396 - INFO - joeynmt.prediction -  dev bleu[13a]:  29.44 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2021-05-05 16:52:09,397 - INFO - joeynmt.prediction - Translations saved to: models/haen_reverse_transformer/00075000.hyps.dev\n",
            "2021-05-05 16:52:09,397 - INFO - joeynmt.prediction - Decoding on test set (data/haen/test.bpe.en)...\n",
            "2021-05-05 16:52:49,653 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 16:52:49,653 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 16:52:49,653 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 16:52:50,408 - INFO - joeynmt.prediction - test bleu[13a]:  34.52 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2021-05-05 16:52:50,410 - INFO - joeynmt.prediction - Translations saved to: models/haen_reverse_transformer/00075000.hyps.test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBoDS09JM807"
      },
      "source": [
        "##############################################################################################################################################################\n",
        "# Copy the created models from the notebook storage to google drive for persistant storage \n",
        "# If you face error like this: cp: target '/content/drive/My Drive/masakhane/ha-en-baseline_v2.0/models/enha_reverse_transformer/' is not a directory, then\n",
        "# comment the active line after, uncomment the line below, run the cell again.\n",
        "##############################################################################################################################################################\n",
        "# !cp -r joeynmt/models/${tgt}${src}_reverse_transformer/* \"$gdrive_path/models/${src}${tgt}_reverse_transformer/\"\n",
        "!cp -r joeynmt/models/${tgt}${src}_reverse_transformer/* \"$gdrive_path/models/${tgt}${src}_reverse_transformer/\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n94wlrCjVc17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b32543-765e-4727-ec77-eeb660029b17"
      },
      "source": [
        "# Output our validation accuracy\n",
        "! cat \"$gdrive_path/models/${tgt}${src}_reverse_transformer/validations.txt\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps: 1000\tLoss: 107511.65625\tPPL: 74.95367\tbleu: 0.62085\tLR: 0.00030000\t*\n",
            "Steps: 2000\tLoss: 93123.58594\tPPL: 42.06231\tbleu: 2.94389\tLR: 0.00030000\t*\n",
            "Steps: 3000\tLoss: 82444.13281\tPPL: 27.39457\tbleu: 4.31298\tLR: 0.00030000\t*\n",
            "Steps: 4000\tLoss: 76083.49219\tPPL: 21.22009\tbleu: 6.60819\tLR: 0.00030000\t*\n",
            "Steps: 5000\tLoss: 71687.17188\tPPL: 17.78624\tbleu: 9.58350\tLR: 0.00030000\t*\n",
            "Steps: 6000\tLoss: 68112.65625\tPPL: 15.40819\tbleu: 11.53071\tLR: 0.00030000\t*\n",
            "Steps: 7000\tLoss: 65488.13281\tPPL: 13.86708\tbleu: 13.95326\tLR: 0.00030000\t*\n",
            "Steps: 8000\tLoss: 63095.07031\tPPL: 12.59664\tbleu: 15.45249\tLR: 0.00030000\t*\n",
            "Steps: 9000\tLoss: 60736.20312\tPPL: 11.45831\tbleu: 17.06465\tLR: 0.00030000\t*\n",
            "Steps: 10000\tLoss: 59028.21875\tPPL: 10.69884\tbleu: 18.13761\tLR: 0.00030000\t*\n",
            "Steps: 11000\tLoss: 57990.07031\tPPL: 10.26203\tbleu: 18.96110\tLR: 0.00030000\t*\n",
            "Steps: 12000\tLoss: 56541.01953\tPPL: 9.68199\tbleu: 19.34897\tLR: 0.00030000\t*\n",
            "Steps: 13000\tLoss: 55614.21875\tPPL: 9.32831\tbleu: 20.68070\tLR: 0.00030000\t*\n",
            "Steps: 14000\tLoss: 54565.46484\tPPL: 8.94365\tbleu: 20.27981\tLR: 0.00030000\t*\n",
            "Steps: 15000\tLoss: 53820.84766\tPPL: 8.68021\tbleu: 21.19482\tLR: 0.00030000\t*\n",
            "Steps: 16000\tLoss: 52881.68359\tPPL: 8.35898\tbleu: 21.69544\tLR: 0.00030000\t*\n",
            "Steps: 17000\tLoss: 52207.18750\tPPL: 8.13563\tbleu: 21.92272\tLR: 0.00030000\t*\n",
            "Steps: 18000\tLoss: 51612.82422\tPPL: 7.94377\tbleu: 22.48111\tLR: 0.00030000\t*\n",
            "Steps: 19000\tLoss: 51020.17188\tPPL: 7.75697\tbleu: 22.84053\tLR: 0.00030000\t*\n",
            "Steps: 20000\tLoss: 50282.92578\tPPL: 7.53071\tbleu: 23.18055\tLR: 0.00030000\t*\n",
            "Steps: 21000\tLoss: 49894.41406\tPPL: 7.41414\tbleu: 23.44911\tLR: 0.00030000\t*\n",
            "Steps: 22000\tLoss: 49703.70312\tPPL: 7.35759\tbleu: 23.21315\tLR: 0.00030000\t*\n",
            "Steps: 23000\tLoss: 49025.67969\tPPL: 7.15998\tbleu: 24.34094\tLR: 0.00030000\t*\n",
            "Steps: 24000\tLoss: 48637.12500\tPPL: 7.04914\tbleu: 24.24142\tLR: 0.00030000\t*\n",
            "Steps: 25000\tLoss: 48401.14062\tPPL: 6.98267\tbleu: 24.27192\tLR: 0.00030000\t*\n",
            "Steps: 26000\tLoss: 47966.60156\tPPL: 6.86189\tbleu: 24.32754\tLR: 0.00030000\t*\n",
            "Steps: 27000\tLoss: 47488.11719\tPPL: 6.73131\tbleu: 24.63713\tLR: 0.00030000\t*\n",
            "Steps: 28000\tLoss: 47183.83594\tPPL: 6.64957\tbleu: 24.76662\tLR: 0.00030000\t*\n",
            "Steps: 29000\tLoss: 46732.74609\tPPL: 6.53022\tbleu: 25.21833\tLR: 0.00030000\t*\n",
            "Steps: 30000\tLoss: 46699.30078\tPPL: 6.52145\tbleu: 25.29700\tLR: 0.00030000\t*\n",
            "Steps: 31000\tLoss: 46287.35547\tPPL: 6.41447\tbleu: 25.40965\tLR: 0.00030000\t*\n",
            "Steps: 32000\tLoss: 46124.12109\tPPL: 6.37257\tbleu: 25.78614\tLR: 0.00030000\t*\n",
            "Steps: 33000\tLoss: 45938.10156\tPPL: 6.32515\tbleu: 25.53340\tLR: 0.00030000\t*\n",
            "Steps: 34000\tLoss: 45809.99609\tPPL: 6.29270\tbleu: 25.62300\tLR: 0.00030000\t*\n",
            "Steps: 35000\tLoss: 45435.40625\tPPL: 6.19876\tbleu: 25.74272\tLR: 0.00030000\t*\n",
            "Steps: 36000\tLoss: 45297.34766\tPPL: 6.16449\tbleu: 25.98414\tLR: 0.00030000\t*\n",
            "Steps: 37000\tLoss: 45123.23828\tPPL: 6.12154\tbleu: 25.98190\tLR: 0.00030000\t*\n",
            "Steps: 38000\tLoss: 44857.55859\tPPL: 6.05659\tbleu: 26.35267\tLR: 0.00030000\t*\n",
            "Steps: 39000\tLoss: 44583.80469\tPPL: 5.99038\tbleu: 26.39606\tLR: 0.00030000\t*\n",
            "Steps: 40000\tLoss: 44459.16406\tPPL: 5.96047\tbleu: 26.61612\tLR: 0.00030000\t*\n",
            "Steps: 41000\tLoss: 44285.74609\tPPL: 5.91911\tbleu: 26.40538\tLR: 0.00030000\t*\n",
            "Steps: 42000\tLoss: 44149.57422\tPPL: 5.88684\tbleu: 26.69321\tLR: 0.00030000\t*\n",
            "Steps: 43000\tLoss: 44102.21875\tPPL: 5.87566\tbleu: 26.81400\tLR: 0.00030000\t*\n",
            "Steps: 44000\tLoss: 44005.01953\tPPL: 5.85277\tbleu: 26.96132\tLR: 0.00030000\t*\n",
            "Steps: 45000\tLoss: 43944.02344\tPPL: 5.83845\tbleu: 26.82001\tLR: 0.00030000\t*\n",
            "Steps: 46000\tLoss: 43548.18359\tPPL: 5.74639\tbleu: 27.29909\tLR: 0.00030000\t*\n",
            "Steps: 47000\tLoss: 43542.80469\tPPL: 5.74515\tbleu: 27.15432\tLR: 0.00030000\t*\n",
            "Steps: 48000\tLoss: 43565.42578\tPPL: 5.75037\tbleu: 27.42668\tLR: 0.00030000\t\n",
            "Steps: 49000\tLoss: 43180.84375\tPPL: 5.66225\tbleu: 27.15403\tLR: 0.00030000\t*\n",
            "Steps: 50000\tLoss: 43158.94922\tPPL: 5.65728\tbleu: 27.35491\tLR: 0.00030000\t*\n",
            "Steps: 51000\tLoss: 43019.70312\tPPL: 5.62574\tbleu: 27.23748\tLR: 0.00030000\t*\n",
            "Steps: 52000\tLoss: 43065.71484\tPPL: 5.63614\tbleu: 27.25392\tLR: 0.00030000\t\n",
            "Steps: 53000\tLoss: 42805.44141\tPPL: 5.57755\tbleu: 27.60451\tLR: 0.00030000\t*\n",
            "Steps: 54000\tLoss: 42680.53125\tPPL: 5.54964\tbleu: 28.25214\tLR: 0.00030000\t*\n",
            "Steps: 55000\tLoss: 42595.02734\tPPL: 5.53062\tbleu: 27.99763\tLR: 0.00030000\t*\n",
            "Steps: 56000\tLoss: 42516.89453\tPPL: 5.51330\tbleu: 27.65856\tLR: 0.00030000\t*\n",
            "Steps: 57000\tLoss: 42291.87109\tPPL: 5.46371\tbleu: 27.86352\tLR: 0.00030000\t*\n",
            "Steps: 58000\tLoss: 42379.59766\tPPL: 5.48299\tbleu: 28.22612\tLR: 0.00030000\t\n",
            "Steps: 59000\tLoss: 42166.54688\tPPL: 5.43628\tbleu: 28.29739\tLR: 0.00030000\t*\n",
            "Steps: 60000\tLoss: 42118.55469\tPPL: 5.42582\tbleu: 28.27922\tLR: 0.00030000\t*\n",
            "Steps: 61000\tLoss: 41985.39844\tPPL: 5.39689\tbleu: 28.05547\tLR: 0.00030000\t*\n",
            "Steps: 62000\tLoss: 41922.53906\tPPL: 5.38328\tbleu: 28.17591\tLR: 0.00030000\t*\n",
            "Steps: 63000\tLoss: 41922.52344\tPPL: 5.38328\tbleu: 28.26127\tLR: 0.00030000\t*\n",
            "Steps: 64000\tLoss: 41714.76562\tPPL: 5.33856\tbleu: 28.57343\tLR: 0.00030000\t*\n",
            "Steps: 65000\tLoss: 41628.28516\tPPL: 5.32005\tbleu: 28.36372\tLR: 0.00030000\t*\n",
            "Steps: 66000\tLoss: 41646.37891\tPPL: 5.32392\tbleu: 28.42299\tLR: 0.00030000\t\n",
            "Steps: 67000\tLoss: 41394.46875\tPPL: 5.27034\tbleu: 27.91558\tLR: 0.00030000\t*\n",
            "Steps: 68000\tLoss: 41300.21875\tPPL: 5.25043\tbleu: 28.87907\tLR: 0.00030000\t*\n",
            "Steps: 69000\tLoss: 41555.43359\tPPL: 5.30451\tbleu: 28.35649\tLR: 0.00030000\t\n",
            "Steps: 70000\tLoss: 41430.03125\tPPL: 5.27787\tbleu: 28.80741\tLR: 0.00030000\t\n",
            "Steps: 71000\tLoss: 41398.32812\tPPL: 5.27116\tbleu: 28.91780\tLR: 0.00030000\t\n",
            "Steps: 72000\tLoss: 41336.29297\tPPL: 5.25804\tbleu: 28.84069\tLR: 0.00030000\t\n",
            "Steps: 73000\tLoss: 41161.92969\tPPL: 5.22136\tbleu: 28.52650\tLR: 0.00030000\t*\n",
            "Steps: 74000\tLoss: 41123.10547\tPPL: 5.21323\tbleu: 28.70965\tLR: 0.00030000\t*\n",
            "Steps: 75000\tLoss: 41080.01562\tPPL: 5.20421\tbleu: 28.96565\tLR: 0.00030000\t*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66WhRE9lIhoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d001b180-1d93-4927-961b-81259c8fac1a"
      },
      "source": [
        "# Test our model\n",
        "! cd joeynmt; python3 -m joeynmt test \"$gdrive_path/models/${tgt}${src}_reverse_transformer/config.yaml\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-05 17:11:46,447 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n",
            "2021-05-05 17:11:46,448 - INFO - joeynmt.data - Building vocabulary...\n",
            "2021-05-05 17:11:46,717 - INFO - joeynmt.data - Loading dev data...\n",
            "2021-05-05 17:11:46,729 - INFO - joeynmt.data - Loading test data...\n",
            "2021-05-05 17:11:46,756 - INFO - joeynmt.data - Data loaded.\n",
            "2021-05-05 17:11:46,789 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 1, batch_size per device: 18000 (with beam_size)\n",
            "2021-05-05 17:11:49,371 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
            "2021-05-05 17:11:49,572 - INFO - joeynmt.model - Enc-dec model built.\n",
            "2021-05-05 17:11:49,641 - INFO - joeynmt.prediction - Decoding on dev set (data/haen/dev.bpe.en)...\n",
            "2021-05-05 17:12:03,823 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 17:12:03,823 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 17:12:03,824 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 17:12:04,043 - INFO - joeynmt.prediction -  dev bleu[13a]:  29.44 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2021-05-05 17:12:04,044 - INFO - joeynmt.prediction - Decoding on test set (data/haen/test.bpe.en)...\n",
            "2021-05-05 17:12:44,193 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-05 17:12:44,193 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-05 17:12:44,193 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-05 17:12:44,941 - INFO - joeynmt.prediction - test bleu[13a]:  34.52 [Beam search decoding with beam size = 5 and alpha = 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coqcvDzviaHN"
      },
      "source": [
        "# Credits\n",
        "\n",
        "Thank you Cate, for helping to debug.\n",
        "\n",
        "Thank you joeynmt team, for joeynmt\n",
        "\n",
        "Thank you Masakhane github team, for the starter notebook.\n",
        "\n",
        "Author: Tunde Ajayi"
      ]
    }
  ]
}