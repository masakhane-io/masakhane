{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "en-ha_v1.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tunde99/masakhane-mt/blob/master/en_ha_v1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igc5itf-xMGj"
      },
      "source": [
        "# Masakhane - Machine Translation for African Languages (Using JoeyNMT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4fXCKCf36IK"
      },
      "source": [
        "## Note before beginning:\n",
        "### - The idea is that you should be able to make minimal changes to this in order to get SOME result for your own translation corpus. \n",
        "\n",
        "### - The tl;dr: Go to the **\"TODO\"** comments which will tell you what to update to get up and running\n",
        "\n",
        "### - If you actually want to have a clue what you're doing, read the text and peek at the links\n",
        "\n",
        "### - With 100 epochs, it should take around 7 hours to run in Google Colab\n",
        "\n",
        "### - Once you've gotten a result for your language, please attach and email your notebook that generated it to masakhanetranslation@gmail.com\n",
        "\n",
        "### - If you care enough and get a chance, doing a brief background on your language would be amazing. See examples in  [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l929HimrxS0a"
      },
      "source": [
        "## Retrieve your data & make a parallel corpus\n",
        "\n",
        "If you want to use the JW300 data referenced on the Masakhane website or in our GitHub repo, you can use `opus-tools` to convert the data into a convenient format. `opus_read` from that package provides a convenient tool for reading the native aligned XML files and to convert them to TMX format. The tool can also be used to fetch relevant files from OPUS on the fly and to filter the data as necessary. [Read the documentation](https://pypi.org/project/opustools-pkg/) for more details.\n",
        "\n",
        "Once you have your corpus files in TMX format (an xml structure which will include the sentences in your target language and your source language in a single file), we recommend reading them into a pandas dataframe. Thankfully, Jade wrote a silly `tmx2dataframe` package which converts your tmx file to a pandas dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "oGRmDELn7Az0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6776f45b-af75-41c9-c681-9727a6febbbb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Cn3tgQLzUxwn"
      },
      "source": [
        "# TODO: Set your source and target languages. Keep in mind, these traditionally use language codes as found here:\n",
        "# These will also become the suffix's of all vocab and corpus files used throughout\n",
        "import os\n",
        "source_language = \"en\"\n",
        "target_language = \"ha\" \n",
        "lc = False  # If True, lowercase the data.\n",
        "seed = 42  # Random seed for shuffling.\n",
        "tag = \"baseline_v1.2\" # Give a unique name to your folder - this is to ensure you don't rewrite any models you've already submitted\n",
        "\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
        "os.environ[\"tgt\"] = target_language\n",
        "os.environ[\"tag\"] = tag\n",
        "\n",
        "\n",
        "# This will save it to a folder in our gdrive instead! \n",
        "!mkdir -p \"/content/drive/My Drive/masakhane/$src-$tgt-$tag\"\n",
        "g_drive_path = \"/content/drive/My Drive/masakhane/%s-%s-%s\" % (source_language, target_language, tag)\n",
        "os.environ[\"gdrive_path\"] = g_drive_path\n",
        "models_path = '%s/models/%s%s_transformer'% (g_drive_path, source_language, target_language)\n",
        "# model temporary directory for training\n",
        "model_temp_dir = \"/content/drive/My Drive/masakhane/model-temp\"\n",
        "# model permanent storage on the drive\n",
        "!mkdir -p \"$gdrive_path/models/${src}${tgt}_transformer/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kBSgJHEw7Nvx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57697081-8d93-4402-b9d2-03181871a742"
      },
      "source": [
        "!echo $gdrive_path"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masakhane/en-ha-baseline_v1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gA75Fs9ys8Y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39cdba08-616c-4616-fff2-0d22a0df2079"
      },
      "source": [
        "# Install opus-tools\n",
        "! pip install opustools-pkg"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opustools-pkg\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/9f/e829a0cceccc603450cd18e1ff80807b6237a88d9a8df2c0bb320796e900/opustools_pkg-0.0.52-py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 26.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 26.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 61kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 71kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 6.8MB/s \n",
            "\u001b[?25hInstalling collected packages: opustools-pkg\n",
            "Successfully installed opustools-pkg-0.0.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xq-tDZVks7ZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d260d518-16ea-4c18-c2d4-c5f9c5d29808"
      },
      "source": [
        "# Downloading our corpus\n",
        "! opus_read -d JW300 -s $src -t $tgt -wm moses -w jw300.$src jw300.$tgt -q\n",
        "\n",
        "# extract the corpus file\n",
        "! gunzip JW300_latest_xml_$src-$tgt.xml.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Alignment file /proj/nlpl/data/OPUS/JW300/latest/xml/en-ha.xml.gz not found. The following files are available for downloading:\n",
            "\n",
            "   3 MB https://object.pouta.csc.fi/OPUS-JW300/v1b/xml/en-ha.xml.gz\n",
            " 263 MB https://object.pouta.csc.fi/OPUS-JW300/v1b/xml/en.zip\n",
            "  24 MB https://object.pouta.csc.fi/OPUS-JW300/v1b/xml/ha.zip\n",
            "\n",
            " 289 MB Total size\n",
            "./JW300_latest_xml_en-ha.xml.gz ... 100% of 3 MB\n",
            "./JW300_latest_xml_en.zip ... 100% of 263 MB\n",
            "./JW300_latest_xml_ha.zip ... 100% of 24 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "n48GDRnP8y2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "189baacc-82a5-4d57-8aae-692ebd199ea0"
      },
      "source": [
        "# Download the global test set.\n",
        "! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-any.en\n",
        "  \n",
        "# And the specific test set for this language pair.\n",
        "os.environ[\"trg\"] = target_language \n",
        "os.environ[\"src\"] = source_language \n",
        "\n",
        "# Uncomment the following lines of code if your language pair is part of the global test set\n",
        "# else, create the test set and upload them to this notebook.\n",
        "\n",
        "# ! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-$trg.en \n",
        "# ! mv test.en-$trg.en test.en\n",
        "# ! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-$trg.$trg \n",
        "# ! mv test.en-$trg.$trg test.$trg"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-04 13:43:40--  https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-any.en\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 277791 (271K) [text/plain]\n",
            "Saving to: ‘test.en-any.en’\n",
            "\n",
            "\rtest.en-any.en        0%[                    ]       0  --.-KB/s               \rtest.en-any.en      100%[===================>] 271.28K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-05-04 13:43:40 (21.3 MB/s) - ‘test.en-any.en’ saved [277791/277791]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CmDahaJ2j_X",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "a98e6a83-5d68-4134-828a-6776a7e6e38e"
      },
      "source": [
        "# Loading created test sets\n",
        "from google.colab import files\n",
        "upload_files = files.upload()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1cce912-2cd7-4a55-aed4-f85ddb61ab14\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a1cce912-2cd7-4a55-aed4-f85ddb61ab14\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.en to test.en\n",
            "Saving test.ha to test.ha\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NqDG-CI28y2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3798988-7a94-45cf-e339-1295013312bc"
      },
      "source": [
        "# Read the test data to filter from train and dev splits.\n",
        "# Store english portion in set for quick filtering checks.\n",
        "en_test_sents = set()\n",
        "filter_test_sents = \"test.en-any.en\"\n",
        "j = 0\n",
        "with open(filter_test_sents) as f:\n",
        "  for line in f:\n",
        "    en_test_sents.add(line.strip())\n",
        "    j += 1\n",
        "print('Loaded {} global test sentences to filter from the training/dev data.'.format(j))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 3571 global test sentences to filter from the training/dev data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "3CNdwLBCfSIl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "14850610-be71-4ac9-e431-97ddfb030aea"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TMX file to dataframe\n",
        "source_file = 'jw300.' + source_language\n",
        "target_file = 'jw300.' + target_language\n",
        "\n",
        "source = []\n",
        "target = []\n",
        "skip_lines = []  # Collect the line numbers of the source portion to skip the same lines for the target portion.\n",
        "with open(source_file) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        # Skip sentences that are contained in the test set.\n",
        "        if line.strip() not in en_test_sents:\n",
        "            source.append(line.strip())\n",
        "        else:\n",
        "            skip_lines.append(i)             \n",
        "with open(target_file) as f:\n",
        "    for j, line in enumerate(f):\n",
        "        # Only add to corpus if corresponding source was not skipped.\n",
        "        if j not in skip_lines:\n",
        "            target.append(line.strip())\n",
        "    \n",
        "print('Loaded data and skipped {}/{} lines since contained in test set.'.format(len(skip_lines), i))\n",
        "    \n",
        "df = pd.DataFrame(zip(source, target), columns=['source_sentence', 'target_sentence'])\n",
        "# if you get TypeError: data argument can't be an iterator is because of your zip version run this below\n",
        "#df = pd.DataFrame(list(zip(source, target)), columns=['source_sentence', 'target_sentence'])\n",
        "df.head(3)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded data and skipped 5417/237064 lines since contained in test set.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Questions From Readers</td>\n",
              "      <td>Tambayoyi Daga Masu Karatu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How seriously should Christians view an engage...</td>\n",
              "      <td>Yaya ya kamata Kiristoci su ɗauki riƙo ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>An engagement to marry is a cause for happines...</td>\n",
              "      <td>Riƙo dalili ne na farinciki , amma kuma muhimm...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     source_sentence                                    target_sentence\n",
              "0                             Questions From Readers                         Tambayoyi Daga Masu Karatu\n",
              "1  How seriously should Christians view an engage...           Yaya ya kamata Kiristoci su ɗauki riƙo ?\n",
              "2  An engagement to marry is a cause for happines...  Riƙo dalili ne na farinciki , amma kuma muhimm..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkuK3B4p2AkN"
      },
      "source": [
        "## Pre-processing and export\n",
        "\n",
        "It is generally a good idea to remove duplicate translations and conflicting translations from the corpus. In practice, these public corpora include some number of these that need to be cleaned.\n",
        "\n",
        "In addition we will split our data into dev/test/train and export to the filesystem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "M_2ouEOH1_1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5178373-4e53-46f4-9268-b5769d50174b"
      },
      "source": [
        "# drop duplicate translations\n",
        "df_pp = df.drop_duplicates()\n",
        "\n",
        "# drop conflicting translations\n",
        "# (this is optional and something that you might want to comment out \n",
        "# depending on the size of your corpus)\n",
        "df_pp.drop_duplicates(subset='source_sentence', inplace=True)\n",
        "df_pp.drop_duplicates(subset='target_sentence', inplace=True)\n",
        "\n",
        "# Shuffle the data to remove bias in dev set selection.\n",
        "df_pp = df_pp.sample(frac=1, random_state=seed).reset_index(drop=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Z_1BwAApEtMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1253d533-47e1-4a3a-ecbc-de0be52f1941"
      },
      "source": [
        "# Install fuzzy wuzzy to remove \"almost duplicate\" sentences in the\n",
        "# test and training sets.\n",
        "! pip install fuzzywuzzy\n",
        "! pip install python-Levenshtein\n",
        "import time\n",
        "from fuzzywuzzy import process\n",
        "import numpy as np\n",
        "from os import cpu_count\n",
        "from functools import partial\n",
        "from multiprocessing import Pool\n",
        "\n",
        "\n",
        "# reset the index of the training set after previous filtering\n",
        "df_pp.reset_index(drop=False, inplace=True)\n",
        "\n",
        "# Remove samples from the training data set if they \"almost overlap\" with the\n",
        "# samples in the test set.\n",
        "\n",
        "# Filtering function. Adjust pad to narrow down the candidate matches to\n",
        "# within a certain length of characters of the given sample.\n",
        "def fuzzfilter(sample, candidates, pad):\n",
        "  candidates = [x for x in candidates if len(x) <= len(sample)+pad and len(x) >= len(sample)-pad] \n",
        "  if len(candidates) > 0:\n",
        "    return process.extractOne(sample, candidates)[1]\n",
        "  else:\n",
        "    return np.nan"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n",
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (56.0.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149826 sha256=3761057294e52cf6db2df7868cfa021f1ebed26a304c5d15aaec4ca61ec9bb6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/26/73/4b48503bac73f01cf18e52cd250947049a7f339e940c5df8fc\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "UD9zoju71PZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06712071-0e6c-44d9-c959-7f890cd17943"
      },
      "source": [
        "# NOTE - This might run slow depending on the size of your training set. We are\n",
        "# printing some information to help you track how long it would take. \n",
        "scores = []\n",
        "start_time = time.time()\n",
        "for idx, row in df_pp.iterrows():\n",
        "  scores.append(fuzzfilter(row['source_sentence'], list(en_test_sents), 5))\n",
        "  if idx % 1000 == 0:\n",
        "    hours, rem = divmod(time.time() - start_time, 3600)\n",
        "    minutes, seconds = divmod(rem, 60)\n",
        "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds), \"%0.2f percent complete\" % (100.0*float(idx)/float(len(df_pp))))\n",
        "\n",
        "# Filter out \"almost overlapping samples\"\n",
        "df_pp['scores'] = scores\n",
        "df_pp = df_pp[df_pp['scores'] < 95]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00:00:00.07 0.00 percent complete\n",
            "00:00:19.37 0.48 percent complete\n",
            "00:00:38.69 0.96 percent complete\n",
            "00:00:58.35 1.44 percent complete\n",
            "00:01:18.05 1.91 percent complete\n",
            "00:01:37.79 2.39 percent complete\n",
            "00:01:56.71 2.87 percent complete\n",
            "00:02:16.47 3.35 percent complete\n",
            "00:02:35.65 3.83 percent complete\n",
            "00:02:54.80 4.31 percent complete\n",
            "00:03:13.63 4.78 percent complete\n",
            "00:03:33.53 5.26 percent complete\n",
            "00:03:53.02 5.74 percent complete\n",
            "00:04:12.48 6.22 percent complete\n",
            "00:04:32.17 6.70 percent complete\n",
            "00:04:51.82 7.18 percent complete\n",
            "00:05:12.17 7.65 percent complete\n",
            "00:05:31.79 8.13 percent complete\n",
            "00:05:50.47 8.61 percent complete\n",
            "00:06:09.83 9.09 percent complete\n",
            "00:06:29.92 9.57 percent complete\n",
            "00:06:49.34 10.05 percent complete\n",
            "00:07:09.11 10.52 percent complete\n",
            "00:07:28.25 11.00 percent complete\n",
            "00:07:47.40 11.48 percent complete\n",
            "00:08:06.82 11.96 percent complete\n",
            "00:08:26.66 12.44 percent complete\n",
            "00:08:46.15 12.92 percent complete\n",
            "00:09:05.53 13.39 percent complete\n",
            "00:09:25.32 13.87 percent complete\n",
            "00:09:44.53 14.35 percent complete\n",
            "00:10:03.78 14.83 percent complete\n",
            "00:10:23.14 15.31 percent complete\n",
            "00:10:42.25 15.79 percent complete\n",
            "00:11:02.39 16.26 percent complete\n",
            "00:11:21.32 16.74 percent complete\n",
            "00:11:40.58 17.22 percent complete\n",
            "00:12:00.21 17.70 percent complete\n",
            "00:12:20.10 18.18 percent complete\n",
            "00:12:39.93 18.66 percent complete\n",
            "00:12:59.59 19.13 percent complete\n",
            "00:13:19.46 19.61 percent complete\n",
            "00:13:39.73 20.09 percent complete\n",
            "00:13:59.48 20.57 percent complete\n",
            "00:14:18.68 21.05 percent complete\n",
            "00:14:38.42 21.53 percent complete\n",
            "00:14:58.49 22.00 percent complete\n",
            "00:15:17.66 22.48 percent complete\n",
            "00:15:37.39 22.96 percent complete\n",
            "00:15:56.75 23.44 percent complete\n",
            "00:16:16.66 23.92 percent complete\n",
            "00:16:36.67 24.40 percent complete\n",
            "00:16:56.67 24.87 percent complete\n",
            "00:17:16.44 25.35 percent complete\n",
            "00:17:36.45 25.83 percent complete\n",
            "00:17:55.79 26.31 percent complete\n",
            "00:18:15.10 26.79 percent complete\n",
            "00:18:34.61 27.27 percent complete\n",
            "00:18:54.62 27.74 percent complete\n",
            "00:19:14.46 28.22 percent complete\n",
            "00:19:34.42 28.70 percent complete\n",
            "00:19:54.02 29.18 percent complete\n",
            "00:20:13.10 29.66 percent complete\n",
            "00:20:33.33 30.14 percent complete\n",
            "00:20:52.83 30.61 percent complete\n",
            "00:21:12.46 31.09 percent complete\n",
            "00:21:31.94 31.57 percent complete\n",
            "00:21:51.55 32.05 percent complete\n",
            "00:22:11.10 32.53 percent complete\n",
            "00:22:30.69 33.01 percent complete\n",
            "00:22:50.50 33.48 percent complete\n",
            "00:23:10.62 33.96 percent complete\n",
            "00:23:29.63 34.44 percent complete\n",
            "00:23:49.41 34.92 percent complete\n",
            "00:24:09.37 35.40 percent complete\n",
            "00:24:28.68 35.88 percent complete\n",
            "00:24:48.64 36.35 percent complete\n",
            "00:25:08.49 36.83 percent complete\n",
            "00:25:27.43 37.31 percent complete\n",
            "00:25:47.13 37.79 percent complete\n",
            "00:26:07.14 38.27 percent complete\n",
            "00:26:26.77 38.75 percent complete\n",
            "00:26:46.61 39.22 percent complete\n",
            "00:27:05.95 39.70 percent complete\n",
            "00:27:25.30 40.18 percent complete\n",
            "00:27:44.69 40.66 percent complete\n",
            "00:28:04.60 41.14 percent complete\n",
            "00:28:24.84 41.62 percent complete\n",
            "00:28:44.78 42.09 percent complete\n",
            "00:29:04.77 42.57 percent complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '․ ․ ․ ․ ․']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:29:24.51 43.05 percent complete\n",
            "00:29:44.56 43.53 percent complete\n",
            "00:30:03.98 44.01 percent complete\n",
            "00:30:23.24 44.49 percent complete\n",
            "00:30:42.34 44.96 percent complete\n",
            "00:31:01.83 45.44 percent complete\n",
            "00:31:21.77 45.92 percent complete\n",
            "00:31:41.49 46.40 percent complete\n",
            "00:32:00.79 46.88 percent complete\n",
            "00:32:20.16 47.36 percent complete\n",
            "00:32:40.42 47.83 percent complete\n",
            "00:33:00.08 48.31 percent complete\n",
            "00:33:19.53 48.79 percent complete\n",
            "00:33:39.70 49.27 percent complete\n",
            "00:33:59.02 49.75 percent complete\n",
            "00:34:19.33 50.23 percent complete\n",
            "00:34:38.66 50.70 percent complete\n",
            "00:34:57.62 51.18 percent complete\n",
            "00:35:17.75 51.66 percent complete\n",
            "00:35:37.11 52.14 percent complete\n",
            "00:35:57.09 52.62 percent complete\n",
            "00:36:16.86 53.10 percent complete\n",
            "00:36:35.92 53.57 percent complete\n",
            "00:36:55.63 54.05 percent complete\n",
            "00:37:14.92 54.53 percent complete\n",
            "00:37:35.06 55.01 percent complete\n",
            "00:37:54.26 55.49 percent complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '․ ․']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:38:13.76 55.97 percent complete\n",
            "00:38:33.12 56.45 percent complete\n",
            "00:38:52.83 56.92 percent complete\n",
            "00:39:12.89 57.40 percent complete\n",
            "00:39:32.03 57.88 percent complete\n",
            "00:39:51.54 58.36 percent complete\n",
            "00:40:11.00 58.84 percent complete\n",
            "00:40:30.25 59.32 percent complete\n",
            "00:40:49.58 59.79 percent complete\n",
            "00:41:08.49 60.27 percent complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '*']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:41:28.18 60.75 percent complete\n",
            "00:41:47.90 61.23 percent complete\n",
            "00:42:07.11 61.71 percent complete\n",
            "00:42:27.01 62.19 percent complete\n",
            "00:42:47.13 62.66 percent complete\n",
            "00:43:06.88 63.14 percent complete\n",
            "00:43:27.18 63.62 percent complete\n",
            "00:43:47.27 64.10 percent complete\n",
            "00:44:06.69 64.58 percent complete\n",
            "00:44:25.99 65.06 percent complete\n",
            "00:44:45.07 65.53 percent complete\n",
            "00:45:04.56 66.01 percent complete\n",
            "00:45:23.74 66.49 percent complete\n",
            "00:45:43.55 66.97 percent complete\n",
            "00:46:02.95 67.45 percent complete\n",
            "00:46:22.50 67.93 percent complete\n",
            "00:46:41.89 68.40 percent complete\n",
            "00:47:01.30 68.88 percent complete\n",
            "00:47:20.92 69.36 percent complete\n",
            "00:47:41.12 69.84 percent complete\n",
            "00:48:00.99 70.32 percent complete\n",
            "00:48:20.32 70.80 percent complete\n",
            "00:48:40.54 71.27 percent complete\n",
            "00:49:00.71 71.75 percent complete\n",
            "00:49:20.79 72.23 percent complete\n",
            "00:49:39.82 72.71 percent complete\n",
            "00:49:58.96 73.19 percent complete\n",
            "00:50:17.89 73.67 percent complete\n",
            "00:50:37.62 74.14 percent complete\n",
            "00:50:57.02 74.62 percent complete\n",
            "00:51:16.21 75.10 percent complete\n",
            "00:51:35.61 75.58 percent complete\n",
            "00:51:55.15 76.06 percent complete\n",
            "00:52:14.88 76.54 percent complete\n",
            "00:52:34.93 77.01 percent complete\n",
            "00:52:54.29 77.49 percent complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:53:13.56 77.97 percent complete\n",
            "00:53:33.08 78.45 percent complete\n",
            "00:53:52.78 78.93 percent complete\n",
            "00:54:11.63 79.41 percent complete\n",
            "00:54:31.07 79.88 percent complete\n",
            "00:54:50.90 80.36 percent complete\n",
            "00:55:10.12 80.84 percent complete\n",
            "00:55:29.51 81.32 percent complete\n",
            "00:55:49.64 81.80 percent complete\n",
            "00:56:09.07 82.28 percent complete\n",
            "00:56:28.71 82.75 percent complete\n",
            "00:56:48.71 83.23 percent complete\n",
            "00:57:07.79 83.71 percent complete\n",
            "00:57:27.17 84.19 percent complete\n",
            "00:57:47.11 84.67 percent complete\n",
            "00:58:06.90 85.15 percent complete\n",
            "00:58:26.27 85.62 percent complete\n",
            "00:58:46.12 86.10 percent complete\n",
            "00:59:06.03 86.58 percent complete\n",
            "00:59:25.82 87.06 percent complete\n",
            "00:59:45.44 87.54 percent complete\n",
            "01:00:04.46 88.02 percent complete\n",
            "01:00:23.61 88.49 percent complete\n",
            "01:00:43.05 88.97 percent complete\n",
            "01:01:02.73 89.45 percent complete\n",
            "01:01:22.51 89.93 percent complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '⇩']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "01:01:42.08 90.41 percent complete\n",
            "01:02:01.62 90.89 percent complete\n",
            "01:02:21.33 91.36 percent complete\n",
            "01:02:40.13 91.84 percent complete\n",
            "01:02:59.75 92.32 percent complete\n",
            "01:03:19.42 92.80 percent complete\n",
            "01:03:39.43 93.28 percent complete\n",
            "01:03:59.16 93.76 percent complete\n",
            "01:04:19.12 94.23 percent complete\n",
            "01:04:38.69 94.71 percent complete\n",
            "01:04:57.91 95.19 percent complete\n",
            "01:05:17.16 95.67 percent complete\n",
            "01:05:36.83 96.15 percent complete\n",
            "01:05:56.27 96.63 percent complete\n",
            "01:06:16.20 97.10 percent complete\n",
            "01:06:35.97 97.58 percent complete\n",
            "01:06:55.74 98.06 percent complete\n",
            "01:07:15.25 98.54 percent complete\n",
            "01:07:34.66 99.02 percent complete\n",
            "01:07:54.74 99.50 percent complete\n",
            "01:08:14.97 99.97 percent complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hxxBOCA-xXhy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b21acf1-c6ad-4eea-f46f-b8d5d0253815"
      },
      "source": [
        "# This section does the split between train/dev for the parallel corpora then saves them as separate files\n",
        "# We use 1000 dev test and the given test set.\n",
        "import csv\n",
        "\n",
        "# Do the split between dev/train and create parallel corpora\n",
        "num_dev_patterns = 1000\n",
        "\n",
        "# Optional: lower case the corpora - this will make it easier to generalize, but without proper casing.\n",
        "if lc:  # Julia: making lowercasing optional\n",
        "    df_pp[\"source_sentence\"] = df_pp[\"source_sentence\"].str.lower()\n",
        "    df_pp[\"target_sentence\"] = df_pp[\"target_sentence\"].str.lower()\n",
        "\n",
        "# Julia: test sets are already generated\n",
        "dev = df_pp.tail(num_dev_patterns) # Herman: Error in original\n",
        "stripped = df_pp.drop(df_pp.tail(num_dev_patterns).index)\n",
        "\n",
        "with open(\"train.\"+source_language, \"w\") as src_file, open(\"train.\"+target_language, \"w\") as trg_file:\n",
        "  for index, row in stripped.iterrows():\n",
        "    src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
        "    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
        "    \n",
        "with open(\"dev.\"+source_language, \"w\") as src_file, open(\"dev.\"+target_language, \"w\") as trg_file:\n",
        "  for index, row in dev.iterrows():\n",
        "    src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
        "    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
        "\n",
        "#stripped[[\"source_sentence\"]].to_csv(\"train.\"+source_language, header=False, index=False)  # Herman: Added `header=False` everywhere\n",
        "#stripped[[\"target_sentence\"]].to_csv(\"train.\"+target_language, header=False, index=False)  # Julia: Problematic handling of quotation marks.\n",
        "\n",
        "#dev[[\"source_sentence\"]].to_csv(\"dev.\"+source_language, header=False, index=False)\n",
        "#dev[[\"target_sentence\"]].to_csv(\"dev.\"+target_language, header=False, index=False)\n",
        "\n",
        "# Doublecheck the format below. There should be no extra quotation marks or weird characters.\n",
        "! head train.*\n",
        "! head dev.*"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> train.en <==\n",
            "“ Preaching in a territory where you meet individuals who are so eager to learn the truth that they want to study the Bible with you every day is such a joy , ” says Stephanie .\n",
            "Where a public reading was forbidden , some sent copies to every member of the church . They wanted no further dealings with false religion !\n",
            "How can couples apply Ephesians 4 : 26 , 27 in their marriage ?\n",
            "Why may we look to the future with confidence ?\n",
            "However , she did what she could , and this can teach us a lesson .\n",
            "Consider what happened just before his arrest , trial , and execution .\n",
            "Many overcame their superstitious fears , and the number attending grew to over 80 .\n",
            "This spectacular display attracts tourists from all over the country .\n",
            "Therefore , beloved ones , since you are awaiting these things , do your utmost to be found finally by him spotless and unblemished and in peace . ”\n",
            "God’s Word , the Bible , foretold that in our time people would be “ self - assuming , haughty . ”\n",
            "\n",
            "==> train.ha <==\n",
            "Stephanie ta ce : “ Yin wa’azi a yankin da za ka haɗu da mutanen da suke son koyan gaskiya da kuma nazarin Littafi Mai Tsarki a kullum abin farin ciki ne .\n",
            "A inda ba a amince da hakan ba , ‘ yan’uwan sukan tura wasiƙa ga kowane memban cocin cewa ba sa son su yi tarayya da addinin ƙarya ko kaɗan !\n",
            "Ta yaya ne ma’aurata za su iya yin amfani da Afisawa 4 : 26 , 27 a aurensu ?\n",
            "Me ya sa ya kamata mu duba gaba da tabbaci ?\n",
            "Amma ta yi iya ƙoƙarinta , kuma hakan ya koya mana darasi .\n",
            "Ka yi la’akari da abin da ya faru kafin a kama shi , a yi masa hukunci , kuma a kashe shi .\n",
            "Mutane da yawa sun ɗauki wannan matakin , kuma adadin waɗanda suke halartar taro ya fi mutane 80 .\n",
            "Wannan yana jawo hankalin masu ziyara daga ko’ina a cikin ƙasar .\n",
            "Domin wannan , ƙaunatattu , tun da kuke sauraron waɗannan al’amura , sai ku ba da anniya a tarar da ku cikin salama , marasa - aibi marasa - laifi a gabansa . ” ( 2 Bit .\n",
            "Kalmar Allah , Littafi Mai Tsarki ta annabta cewa a zamaninmu mutane za su zama “ masu - ruba , masu - girman kai . ”\n",
            "==> dev.en <==\n",
            "Her home is a pleasant and comfortable place for the entire family .\n",
            "Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "* By all means I shall have pity upon him . ”\n",
            "Experts admit that this is why human governments cannot eliminate corruption .\n",
            "In the 7th chapter of Romans , Paul acknowledged the power of sin on the imperfect flesh .\n",
            "Dedication signifies a setting apart , or a separation , for a sacred purpose .\n",
            "The woman mentioned at the outset took the initiative to return to Jehovah and visited a local congregation of Jehovah’s Witnesses .\n",
            "They do not abuse their wives physically or verbally , do not insist on degrading sexual practices , and do not dishonor their wives by flirting with other women or by viewing pornography .\n",
            "JEHOVAH GOD’S Word exhorts us to love “ loving - kindness . ”\n",
            "\n",
            "==> dev.ha <==\n",
            "14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "Masana sun gano cewa wannan ne dalilin da ya sa gwamnatocin duniya ba za su iya kawo ƙarshen cin hanci da rashawa ba .\n",
            "A cikin sura ta 7 ta littafin Romawa , Bulus ya bayyana ikon zunubi a jikinmu ajizi .\n",
            "( Yahuda 20 , 21 ) Keɓewa yana nufin a ware , don tsarkaken nufi .\n",
            "Matar da aka ambata a farkon talifin nan ta ɗauki mataki don ta sake soma bauta wa Jehobah kuma ta ziyarci ikilisiyar Shaidun Jehobah da ke inda take da zama .\n",
            "( 1 Bitrus 3 : 7 ) Ba sa wulaƙanta matansu a zahiri ko kuma da baki , ba sa nacewa ga jima’i mai ƙasƙantarwa ba , kuma ba sa raina matansu ta wajen neman wasu mata ko kuma ta wajen kallon hotunan tsirarun mata .\n",
            "KALMAR Jehovah Allah ta aririce mu mu yi ƙauna “ [ ƙauna ta alheri ] . ”\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epeCydmCyS8X"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Installation of JoeyNMT\n",
        "\n",
        "JoeyNMT is a simple, minimalist NMT package which is useful for learning and teaching. Check out the documentation for JoeyNMT [here](https://joeynmt.readthedocs.io)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "iBRMm4kMxZ8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ae1e1a-8821-41a1-840f-aeb16ec9cafe"
      },
      "source": [
        "# Install JoeyNMT\n",
        "! git clone https://github.com/joeynmt/joeynmt.git\n",
        "! cd joeynmt; pip3 install .\n",
        "# Install Pytorch with GPU support v1.7.1.\n",
        "! pip install torch==1.8+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'joeynmt' already exists and is not an empty directory.\n",
            "Processing /content/joeynmt\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (7.1.2)\n",
            "Requirement already satisfied: numpy==1.20.1 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (1.20.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (56.0.0)\n",
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (1.8.0)\n",
            "Requirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (2.4.1)\n",
            "Requirement already satisfied: torchtext==0.9.0 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (0.9.0)\n",
            "Requirement already satisfied: sacrebleu>=1.3.6 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (1.5.1)\n",
            "Requirement already satisfied: subword-nmt in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (0.3.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (5.4.1)\n",
            "Requirement already satisfied: pylint in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (2.8.2)\n",
            "Requirement already satisfied: six==1.12 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (1.12.0)\n",
            "Requirement already satisfied: wrapt==1.11.1 in /usr/local/lib/python3.7/dist-packages (from joeynmt==1.3) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->joeynmt==1.3) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (1.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (1.28.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (1.32.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (0.4.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt==1.3) (0.36.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0->joeynmt==1.3) (4.41.1)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.3.6->joeynmt==1.3) (2.0.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt==1.3) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt==1.3) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt==1.3) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt==1.3) (2.8.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn->joeynmt==1.3) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->joeynmt==1.3) (1.4.1)\n",
            "Requirement already satisfied: mccabe<0.7,>=0.6 in /usr/local/lib/python3.7/dist-packages (from pylint->joeynmt==1.3) (0.6.1)\n",
            "Requirement already satisfied: toml>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pylint->joeynmt==1.3) (0.10.2)\n",
            "Requirement already satisfied: isort<6,>=4.2.5 in /usr/local/lib/python3.7/dist-packages (from pylint->joeynmt==1.3) (5.8.0)\n",
            "Requirement already satisfied: astroid<2.7,>=2.5.6 in /usr/local/lib/python3.7/dist-packages (from pylint->joeynmt==1.3) (2.5.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.3) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.3) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.3) (4.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.3) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->joeynmt==1.3) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.15->joeynmt==1.3) (3.10.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->joeynmt==1.3) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn->joeynmt==1.3) (2018.9)\n",
            "Requirement already satisfied: typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from astroid<2.7,>=2.5.6->pylint->joeynmt==1.3) (1.4.3)\n",
            "Requirement already satisfied: lazy-object-proxy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from astroid<2.7,>=2.5.6->pylint->joeynmt==1.3) (1.6.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=1.15->joeynmt==1.3) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.15->joeynmt==1.3) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->joeynmt==1.3) (3.1.0)\n",
            "Building wheels for collected packages: joeynmt\n",
            "  Building wheel for joeynmt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for joeynmt: filename=joeynmt-1.3-cp37-none-any.whl size=84842 sha256=85ce3b5f498f4c2e75b4b74dcdb0fb140e5bce6e152ae8ffa59a4de8999945c2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e31uj9h_/wheels/db/01/db/751cc9f3e7f6faec127c43644ba250a3ea7ad200594aeda70a\n",
            "Successfully built joeynmt\n",
            "Installing collected packages: joeynmt\n",
            "  Found existing installation: joeynmt 1.3\n",
            "    Uninstalling joeynmt-1.3:\n",
            "      Successfully uninstalled joeynmt-1.3\n",
            "Successfully installed joeynmt-1.3\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.8.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (763.5MB)\n",
            "\u001b[K     |████████████████████████████████| 763.5MB 23kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8+cu101) (1.20.1)\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.8.0+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.8.0\n",
            "    Uninstalling torch-1.8.0:\n",
            "      Successfully uninstalled torch-1.8.0\n",
            "Successfully installed torch-1.8.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaE77Tcppex9"
      },
      "source": [
        "# Preprocessing the Data into Subword BPE Tokens\n",
        "\n",
        "- One of the most powerful improvements for agglutinative languages (a feature of most Bantu languages) is using BPE tokenization [ (Sennrich, 2015) ](https://arxiv.org/abs/1508.07909).\n",
        "\n",
        "- It was also shown that by optimizing the umber of BPE codes we significantly improve results for low-resourced languages [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021) [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)\n",
        "\n",
        "- Below we have the scripts for doing BPE tokenization of our data. We use 4000 tokens as recommended by [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021). You do not need to change anything. Simply running the below will be suitable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "H-TyjtmXB1mL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18921627-4004-40f6-c229-cc3b8757b740"
      },
      "source": [
        "# One of the huge boosts in NMT performance was to use a different method of tokenizing. \n",
        "# Usually, NMT would tokenize by words. However, using a method called BPE gave amazing boosts to performance\n",
        "\n",
        "# Do subword NMT\n",
        "from os import path\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
        "os.environ[\"tgt\"] = target_language\n",
        "\n",
        "# Learn BPEs on the training data.\n",
        "os.environ[\"data_path\"] = path.join(\"joeynmt\", \"data\", source_language + target_language) # Herman! \n",
        "! subword-nmt learn-joint-bpe-and-vocab --input train.$src train.$tgt -s 4000 -o bpe.codes.4000 --write-vocabulary vocab.$src vocab.$tgt\n",
        "\n",
        "# Apply BPE splits to the development and test data.\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < train.$src > train.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < train.$tgt > train.bpe.$tgt\n",
        "\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < dev.$src > dev.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < dev.$tgt > dev.bpe.$tgt\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < test.$src > test.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < test.$tgt > test.bpe.$tgt\n",
        "\n",
        "# Create directory, move everyone we care about to the correct location\n",
        "! mkdir -p $data_path\n",
        "! cp train.* $data_path\n",
        "! cp test.* $data_path\n",
        "! cp dev.* $data_path\n",
        "! cp bpe.codes.4000 $data_path\n",
        "! ls $data_path\n",
        "\n",
        "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
        "! cp train.* \"$gdrive_path\"\n",
        "! cp test.* \"$gdrive_path\"\n",
        "! cp dev.* \"$gdrive_path\"\n",
        "! cp bpe.codes.4000 \"$gdrive_path\"\n",
        "! ls \"$gdrive_path\"\n",
        "\n",
        "# Create that vocab using build_vocab\n",
        "! sudo chmod 777 joeynmt/scripts/build_vocab.py\n",
        "! joeynmt/scripts/build_vocab.py joeynmt/data/$src$tgt/train.bpe.$src joeynmt/data/$src$tgt/train.bpe.$tgt --output_path joeynmt/data/$src$tgt/vocab.txt\n",
        "\n",
        "# Some output\n",
        "! echo \"BPE Hausa Sentences\"\n",
        "! tail -n 5 test.bpe.$tgt\n",
        "! echo \"Combined BPE Vocab\"\n",
        "! tail -n 10 joeynmt/data/$src$tgt/vocab.txt  # Herman"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe.codes.4000\tdev.en\t     test.bpe.ha     test.ha\t   train.en\n",
            "dev.bpe.en\tdev.ha\t     test.en\t     train.bpe.en  train.ha\n",
            "dev.bpe.ha\ttest.bpe.en  test.en-any.en  train.bpe.ha\n",
            "bpe.codes.4000\tdev.en\ttest.bpe.en  test.en-any.en  train.bpe.ha\n",
            "dev.bpe.en\tdev.ha\ttest.bpe.ha  test.ha\t     train.en\n",
            "dev.bpe.ha\tmodels\ttest.en      train.bpe.en    train.ha\n",
            "BPE Hausa Sentences\n",
            "Kada mu zama kamar Ab@@ ner da Ab@@ sal@@ om da suka ci am@@ ana .\n",
            "[ 1 ] ( sa@@ kin la@@ yi na 7 ) An canja wasu sun@@ a@@ ye .\n",
            "Idan muna da aminci da kuma tawali’u , za mu mai da hankali ga abin da Jehobah yake so mu yi , ba abin da muke so ba\n",
            "Idan mu masu aminci ne da kuma kirki , za mu riƙa taimaka wa mutane , kuma za mu bi da su yadda Jehobah yake so\n",
            "Idan muna da aminci da kuma ƙarfin zuciya , za mu yi biyayya ga Jehobah ko da yin hakan yana da wuya ko kuma muna far@@ gabaCombined BPE Vocab\n",
            "ö\n",
            "ş\n",
            "⁄\n",
            "refore\n",
            "+\n",
            "Ž@@\n",
            "Ó@@\n",
            "£\n",
            "tabl@@\n",
            "↓\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixmzi60WsUZ8"
      },
      "source": [
        "# Creating the JoeyNMT Config\n",
        "\n",
        "JoeyNMT requires a yaml config. We provide a template below. We've also set a number of defaults with it, that you may play with!\n",
        "\n",
        "- We used Transformer architecture \n",
        "- We set our dropout to reasonably high: 0.3 (recommended in  [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021))\n",
        "\n",
        "Things worth playing with:\n",
        "- The batch size (also recommended to change for low-resourced languages)\n",
        "- The number of epochs (we've set it at 30 just so it runs in about an hour, for testing purposes)\n",
        "- The decoder options (beam_size, alpha)\n",
        "- Evaluation metrics (BLEU versus Crhf4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j44fI7U7PntE"
      },
      "source": [
        "def get_last_checkpoint(directory):\n",
        "  last_checkpoint = ''\n",
        "  try:\n",
        "    for filename in os.listdir(directory):\n",
        "      if not 'best' in filename and filename.endswith(\".ckpt\"):\n",
        "          if not last_checkpoint or int(filename.split('.')[0]) > int(last_checkpoint.split('.')[0]):\n",
        "            last_checkpoint = filename\n",
        "  except FileNotFoundError as e:\n",
        "    print('Error Occur ', e)\n",
        "  return last_checkpoint"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVoB16AcPrOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61f38ce4-85b2-42bd-8686-e9b490466cab"
      },
      "source": [
        "# Copy the created models from the temporary storage to main storage on google drive for persistant storage \n",
        "# the content of the folder will be overwritten when you start training\n",
        "!cp -r \"/content/drive/My Drive/masakhane/model-temp/\"* \"$gdrive_path/models/${src}${tgt}_transformer/\"\n",
        "last_checkpoint = get_last_checkpoint(models_path)\n",
        "print('Last checkpoint :',last_checkpoint)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/drive/My Drive/masakhane/model-temp/*': No such file or directory\n",
            "Last checkpoint : \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PIs1lY2hxMsl"
      },
      "source": [
        "# This creates the config file for our JoeyNMT system. It might seem overwhelming so we've provided a couple of useful parameters you'll need to update\n",
        "# (You can of course play with all the parameters if you'd like!)\n",
        "\n",
        "name = '%s%s' % (source_language, target_language)\n",
        "gdrive_path = os.environ[\"gdrive_path\"]\n",
        "\n",
        "# Create the config\n",
        "config = \"\"\"\n",
        "name: \"{name}_transformer\"\n",
        "\n",
        "data:\n",
        "    src: \"{source_language}\"\n",
        "    trg: \"{target_language}\"\n",
        "    train: \"data/{name}/train.bpe\"\n",
        "    dev:   \"data/{name}/dev.bpe\"\n",
        "    test:  \"data/{name}/test.bpe\"\n",
        "    level: \"bpe\"\n",
        "    lowercase: False\n",
        "    max_sent_length: 100\n",
        "    src_vocab: \"data/{name}/vocab.txt\"\n",
        "    trg_vocab: \"data/{name}/vocab.txt\"\n",
        "\n",
        "testing:\n",
        "    beam_size: 5\n",
        "    alpha: 1.0\n",
        "\n",
        "training:\n",
        "    #load_model: \"{gdrive_path}/models/{name}_transformer/1.ckpt\" # if uncommented, load a pre-trained model from this checkpoint\n",
        "    random_seed: 42\n",
        "    optimizer: \"adam\"\n",
        "    normalization: \"tokens\"\n",
        "    adam_betas: [0.9, 0.999] \n",
        "    scheduling: \"plateau\"           # TODO: try switching from plateau to Noam scheduling\n",
        "    patience: 5                     # For plateau: decrease learning rate by decrease_factor if validation score has not improved for this many validation rounds.\n",
        "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n",
        "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n",
        "    decrease_factor: 0.7\n",
        "    loss: \"crossentropy\"\n",
        "    learning_rate: 0.0003\n",
        "    learning_rate_min: 0.00000001\n",
        "    weight_decay: 0.0\n",
        "    label_smoothing: 0.1\n",
        "    batch_size: 4096\n",
        "    batch_type: \"token\"\n",
        "    eval_batch_size: 3600\n",
        "    eval_batch_type: \"token\"\n",
        "    batch_multiplier: 1\n",
        "    early_stopping_metric: \"ppl\"\n",
        "    epochs: 30                     # TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\n",
        "    validation_freq: 1000          # TODO: Set to at least once per epoch.\n",
        "    logging_freq: 100\n",
        "    eval_metric: \"bleu\"\n",
        "    model_dir: \"models/{name}_transformer\"\n",
        "    overwrite: False               # TODO: Set to True if you want to overwrite possibly existing models. \n",
        "    shuffle: True\n",
        "    use_cuda: True\n",
        "    max_output_length: 100\n",
        "    print_valid_sents: [0, 1, 2, 3]\n",
        "    keep_last_ckpts: 3\n",
        "\n",
        "model:\n",
        "    initializer: \"xavier\"\n",
        "    bias_initializer: \"zeros\"\n",
        "    init_gain: 1.0\n",
        "    embed_initializer: \"xavier\"\n",
        "    embed_init_gain: 1.0\n",
        "    tied_embeddings: True\n",
        "    tied_softmax: True\n",
        "    encoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 4             # TODO: Increase to 8 for larger data.\n",
        "        embeddings:\n",
        "            embedding_dim: 256   # TODO: Increase to 512 for larger data.\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 256         # TODO: Increase to 512 for larger data.\n",
        "        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n",
        "        dropout: 0.3\n",
        "    decoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 4              # TODO: Increase to 8 for larger data.\n",
        "        embeddings:\n",
        "            embedding_dim: 256    # TODO: Increase to 512 for larger data.\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 256         # TODO: Increase to 512 for larger data.\n",
        "        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n",
        "        dropout: 0.3\n",
        "\"\"\".format(name=name, gdrive_path=os.environ[\"gdrive_path\"], source_language=source_language, target_language=target_language)\n",
        "with open(\"joeynmt/configs/transformer_{name}.yaml\".format(name=name),'w') as f:\n",
        "    f.write(config)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIifxE3Qzuvs"
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "This single line of joeynmt runs the training using the config we made above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6ZBPFwT94WpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d56605-fa81-4906-e1eb-beaf2ef35a44"
      },
      "source": [
        "# Train the model\n",
        "# You can press Ctrl-C to stop. And then run the next cell to save your checkpoints! \n",
        "!cd joeynmt; python3 -m joeynmt train configs/transformer_$src$tgt.yaml"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-04 15:12:34,252 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n",
            "2021-05-04 15:12:34,308 - INFO - joeynmt.data - Loading training data...\n",
            "2021-05-04 15:12:37,640 - INFO - joeynmt.data - Building vocabulary...\n",
            "2021-05-04 15:12:37,906 - INFO - joeynmt.data - Loading dev data...\n",
            "2021-05-04 15:12:37,930 - INFO - joeynmt.data - Loading test data...\n",
            "2021-05-04 15:12:38,562 - INFO - joeynmt.data - Data loaded.\n",
            "2021-05-04 15:12:38,562 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
            "2021-05-04 15:12:38,758 - INFO - joeynmt.model - Enc-dec model built.\n",
            "2021-05-04 15:12:38.915646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-05-04 15:12:40,518 - INFO - joeynmt.training - Total params: 12151808\n",
            "2021-05-04 15:12:42,890 - INFO - joeynmt.helpers - cfg.name                           : enha_transformer\n",
            "2021-05-04 15:12:42,890 - INFO - joeynmt.helpers - cfg.data.src                       : en\n",
            "2021-05-04 15:12:42,890 - INFO - joeynmt.helpers - cfg.data.trg                       : ha\n",
            "2021-05-04 15:12:42,890 - INFO - joeynmt.helpers - cfg.data.train                     : data/enha/train.bpe\n",
            "2021-05-04 15:12:42,890 - INFO - joeynmt.helpers - cfg.data.dev                       : data/enha/dev.bpe\n",
            "2021-05-04 15:12:42,890 - INFO - joeynmt.helpers - cfg.data.test                      : data/enha/test.bpe\n",
            "2021-05-04 15:12:42,890 - INFO - joeynmt.helpers - cfg.data.level                     : bpe\n",
            "2021-05-04 15:12:42,890 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False\n",
            "2021-05-04 15:12:42,890 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 100\n",
            "2021-05-04 15:12:42,890 - INFO - joeynmt.helpers - cfg.data.src_vocab                 : data/enha/vocab.txt\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.data.trg_vocab                 : data/enha/vocab.txt\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.patience              : 5\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.learning_rate_factor  : 0.5\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.learning_rate_warmup  : 1000\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0003\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0\n",
            "2021-05-04 15:12:42,891 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.batch_size            : 4096\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.batch_type            : token\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 3600\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.eval_batch_type       : token\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.epochs                : 30\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 1000\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/enha_transformer\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.overwrite             : False\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.shuffle               : True\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3]\n",
            "2021-05-04 15:12:42,892 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 3\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : True\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 4\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.2\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 256\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 1024\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.3\n",
            "2021-05-04 15:12:42,893 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 4\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.2\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 256\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 1024\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.3\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - Data set sizes: \n",
            "\ttrain 207025,\n",
            "\tvalid 1000,\n",
            "\ttest 3309\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - First training example:\n",
            "\t[SRC] “ P@@ re@@ aching in a ter@@ rit@@ ory where you meet individuals who are so e@@ ag@@ er to learn the truth that they want to study the Bible with you every day is such a joy , ” says S@@ te@@ p@@ han@@ i@@ e .\n",
            "\t[TRG] S@@ te@@ p@@ han@@ i@@ e ta ce : “ Yin wa’azi a yan@@ kin da za ka haɗ@@ u da mutanen da suke son ko@@ yan gaskiya da kuma nazarin Littafi Mai Tsarki a kullum abin farin ciki ne .\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) da (7) a (8) the (9) ya\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) da (7) a (8) the (9) ya\n",
            "2021-05-04 15:12:42,894 - INFO - joeynmt.helpers - Number of Src words (types): 4264\n",
            "2021-05-04 15:12:42,895 - INFO - joeynmt.helpers - Number of Trg words (types): 4264\n",
            "2021-05-04 15:12:42,895 - INFO - joeynmt.training - Model(\n",
            "\tencoder=TransformerEncoder(num_layers=6, num_heads=4),\n",
            "\tdecoder=TransformerDecoder(num_layers=6, num_heads=4),\n",
            "\tsrc_embed=Embeddings(embedding_dim=256, vocab_size=4264),\n",
            "\ttrg_embed=Embeddings(embedding_dim=256, vocab_size=4264))\n",
            "2021-05-04 15:12:42,898 - INFO - joeynmt.training - Train stats:\n",
            "\tdevice: cuda\n",
            "\tn_gpu: 1\n",
            "\t16-bits training: False\n",
            "\tgradient accumulation: 1\n",
            "\tbatch size per device: 4096\n",
            "\ttotal batch size (w. parallel & accumulation): 4096\n",
            "2021-05-04 15:12:42,898 - INFO - joeynmt.training - EPOCH 1\n",
            "2021-05-04 15:12:53,111 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     5.350611, Tokens per Sec:    21330, Lr: 0.000300\n",
            "2021-05-04 15:13:03,123 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     5.146645, Tokens per Sec:    21645, Lr: 0.000300\n",
            "2021-05-04 15:13:12,964 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     4.935674, Tokens per Sec:    21506, Lr: 0.000300\n",
            "2021-05-04 15:13:22,803 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     4.692558, Tokens per Sec:    20954, Lr: 0.000300\n",
            "2021-05-04 15:13:32,747 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     4.671406, Tokens per Sec:    21748, Lr: 0.000300\n",
            "2021-05-04 15:13:42,699 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     4.445690, Tokens per Sec:    21840, Lr: 0.000300\n",
            "2021-05-04 15:13:52,730 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     4.151548, Tokens per Sec:    21796, Lr: 0.000300\n",
            "2021-05-04 15:14:02,622 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.889798, Tokens per Sec:    21473, Lr: 0.000300\n",
            "2021-05-04 15:14:12,694 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     4.213735, Tokens per Sec:    21883, Lr: 0.000300\n",
            "2021-05-04 15:14:22,580 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     4.034126, Tokens per Sec:    21479, Lr: 0.000300\n",
            "2021-05-04 15:14:48,262 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:14:48,262 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:14:48,262 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:14:48,531 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:14:48,531 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:14:48,943 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:14:48,943 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:14:48,943 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:14:48,943 - INFO - joeynmt.training - \tHypothesis: A lokacin da haka , za su iya yi wa Jehobah ya yi wa Jehobah .\n",
            "2021-05-04 15:14:48,943 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:14:48,943 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:14:48,943 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:14:48,944 - INFO - joeynmt.training - \tHypothesis: ( 1 : 1 ) A lokacin da haka , ya ce : “ Ku yi wa Jehobah , “ Ku yi wa Jehobah , amma ya yi wa Jehobah , amma ya yi wa Jehobah . ”\n",
            "2021-05-04 15:14:48,944 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:14:48,944 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:14:48,944 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:14:48,944 - INFO - joeynmt.training - \tHypothesis: ( 1 : 1 ) A lokacin da haka , muna da muka yi wa Jehobah , kuma muna da kuma muka yi wa Jehobah .\n",
            "2021-05-04 15:14:48,944 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:14:48,944 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:14:48,944 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:14:48,944 - INFO - joeynmt.training - \tHypothesis: ( 1 : 1 ) A lokacin da haka , ya yi wa Jehobah ya yi wa Jehobah .\n",
            "2021-05-04 15:14:48,944 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     1000: bleu:   1.29, loss: 95550.1328, ppl:  44.5918, duration: 26.3636s\n",
            "2021-05-04 15:14:58,849 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.473196, Tokens per Sec:    21497, Lr: 0.000300\n",
            "2021-05-04 15:15:08,819 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.850900, Tokens per Sec:    21784, Lr: 0.000300\n",
            "2021-05-04 15:15:18,668 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     3.764089, Tokens per Sec:    21293, Lr: 0.000300\n",
            "2021-05-04 15:15:28,639 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     3.547829, Tokens per Sec:    21557, Lr: 0.000300\n",
            "2021-05-04 15:15:38,502 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.229292, Tokens per Sec:    21539, Lr: 0.000300\n",
            "2021-05-04 15:15:48,488 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     3.763644, Tokens per Sec:    21595, Lr: 0.000300\n",
            "2021-05-04 15:15:58,410 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     3.665765, Tokens per Sec:    21630, Lr: 0.000300\n",
            "2021-05-04 15:16:08,410 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     3.560595, Tokens per Sec:    21775, Lr: 0.000300\n",
            "2021-05-04 15:16:18,463 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     3.388868, Tokens per Sec:    21715, Lr: 0.000300\n",
            "2021-05-04 15:16:28,298 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     3.368750, Tokens per Sec:    21517, Lr: 0.000300\n",
            "2021-05-04 15:16:54,165 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:16:54,165 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:16:54,165 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:16:54,439 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:16:54,439 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:16:54,813 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:16:54,814 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:16:54,814 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:16:54,814 - INFO - joeynmt.training - \tHypothesis: ( 1 Korinthiyawa 4 : 1 ) Ka yi la’akari da wannan yanayin da kuma yin hakan .\n",
            "2021-05-04 15:16:54,814 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:16:54,814 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:16:54,814 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:16:54,814 - INFO - joeynmt.training - \tHypothesis: ( 1 Korinthiyawa 4 : 1 ) Ko da yake da yake da daɗewa ba za su iya yin amfani da shi da kuma “ ba , ” kuma za su iya yin hakan zai iya yin amfani da shi .\n",
            "2021-05-04 15:16:54,814 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:16:54,814 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:16:54,815 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:16:54,815 - INFO - joeynmt.training - \tHypothesis: Sun yi amfani da su da yin nazarin Littafi Mai Tsarki da kuma su yi amfani da Littafi Mai Tsarki . — Karanta 1 Korinthiyawa 4 : 1 ; 1 : 1 ; 1 ; 1 Kor .\n",
            "2021-05-04 15:16:54,815 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:16:54,815 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:16:54,815 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:16:54,815 - INFO - joeynmt.training - \tHypothesis: * ( 1 Korinthiyawa 4 : 1 ) Amma , sai ya yi hakan ya yi hakan . ”\n",
            "2021-05-04 15:16:54,815 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     2000: bleu:   3.43, loss: 81565.0625, ppl:  25.5778, duration: 26.5169s\n",
            "2021-05-04 15:17:04,798 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     3.154326, Tokens per Sec:    21734, Lr: 0.000300\n",
            "2021-05-04 15:17:14,728 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     3.496944, Tokens per Sec:    21665, Lr: 0.000300\n",
            "2021-05-04 15:17:24,668 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     3.551393, Tokens per Sec:    21553, Lr: 0.000300\n",
            "2021-05-04 15:17:34,548 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     3.396475, Tokens per Sec:    21145, Lr: 0.000300\n",
            "2021-05-04 15:17:44,253 - INFO - joeynmt.training - Epoch   1: total training loss 9869.01\n",
            "2021-05-04 15:17:44,253 - INFO - joeynmt.training - EPOCH 2\n",
            "2021-05-04 15:17:44,707 - INFO - joeynmt.training - Epoch   2, Step:     2500, Batch Loss:     3.114618, Tokens per Sec:     8763, Lr: 0.000300\n",
            "2021-05-04 15:17:54,686 - INFO - joeynmt.training - Epoch   2, Step:     2600, Batch Loss:     3.009286, Tokens per Sec:    21583, Lr: 0.000300\n",
            "2021-05-04 15:18:04,724 - INFO - joeynmt.training - Epoch   2, Step:     2700, Batch Loss:     3.139431, Tokens per Sec:    21459, Lr: 0.000300\n",
            "2021-05-04 15:18:14,641 - INFO - joeynmt.training - Epoch   2, Step:     2800, Batch Loss:     2.790691, Tokens per Sec:    21235, Lr: 0.000300\n",
            "2021-05-04 15:18:24,543 - INFO - joeynmt.training - Epoch   2, Step:     2900, Batch Loss:     3.057859, Tokens per Sec:    21476, Lr: 0.000300\n",
            "2021-05-04 15:18:34,482 - INFO - joeynmt.training - Epoch   2, Step:     3000, Batch Loss:     2.986220, Tokens per Sec:    21673, Lr: 0.000300\n",
            "2021-05-04 15:18:49,732 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:18:49,732 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:18:49,733 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:18:49,989 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:18:49,989 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:18:50,373 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:18:50,373 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:18:50,373 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:18:50,373 - INFO - joeynmt.training - \tHypothesis: A lokacin da ake bukata a kai da kuma yin hakan zai iya taimaka wa mutane su kasance da aminci .\n",
            "2021-05-04 15:18:50,373 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:18:50,374 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:18:50,374 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:18:50,374 - INFO - joeynmt.training - \tHypothesis: Kamar yadda yake ba zai iya yin hakan ba , zai iya yin amfani da “ mai - adalci ” ko kuma “ ba za a iya yin hakan ba .\n",
            "2021-05-04 15:18:50,374 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:18:50,374 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:18:50,374 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:18:50,374 - INFO - joeynmt.training - \tHypothesis: Suna bukatar su yi amfani da ƙa’idodin Littafi Mai Tsarki . — Matta 24 : 11 .\n",
            "2021-05-04 15:18:50,374 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:18:50,374 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:18:50,375 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:18:50,375 - INFO - joeynmt.training - \tHypothesis: * Ta yaya na yi hakan . ”\n",
            "2021-05-04 15:18:50,375 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     3000: bleu:   6.79, loss: 73370.5391, ppl:  18.4681, duration: 15.8922s\n",
            "2021-05-04 15:19:00,290 - INFO - joeynmt.training - Epoch   2, Step:     3100, Batch Loss:     3.352598, Tokens per Sec:    21519, Lr: 0.000300\n",
            "2021-05-04 15:19:10,285 - INFO - joeynmt.training - Epoch   2, Step:     3200, Batch Loss:     2.528327, Tokens per Sec:    21624, Lr: 0.000300\n",
            "2021-05-04 15:19:20,260 - INFO - joeynmt.training - Epoch   2, Step:     3300, Batch Loss:     3.053290, Tokens per Sec:    21568, Lr: 0.000300\n",
            "2021-05-04 15:19:30,141 - INFO - joeynmt.training - Epoch   2, Step:     3400, Batch Loss:     3.138974, Tokens per Sec:    21721, Lr: 0.000300\n",
            "2021-05-04 15:19:40,102 - INFO - joeynmt.training - Epoch   2, Step:     3500, Batch Loss:     2.969343, Tokens per Sec:    21618, Lr: 0.000300\n",
            "2021-05-04 15:19:50,054 - INFO - joeynmt.training - Epoch   2, Step:     3600, Batch Loss:     2.744800, Tokens per Sec:    21864, Lr: 0.000300\n",
            "2021-05-04 15:19:59,915 - INFO - joeynmt.training - Epoch   2, Step:     3700, Batch Loss:     2.823925, Tokens per Sec:    21530, Lr: 0.000300\n",
            "2021-05-04 15:20:09,818 - INFO - joeynmt.training - Epoch   2, Step:     3800, Batch Loss:     3.151373, Tokens per Sec:    21716, Lr: 0.000300\n",
            "2021-05-04 15:20:19,688 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:     2.869235, Tokens per Sec:    21295, Lr: 0.000300\n",
            "2021-05-04 15:20:29,558 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     2.987447, Tokens per Sec:    21821, Lr: 0.000300\n",
            "2021-05-04 15:20:40,012 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:20:40,013 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:20:40,013 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:20:40,265 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:20:40,265 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:20:40,678 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:20:40,679 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:20:40,679 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:20:40,679 - INFO - joeynmt.training - \tHypothesis: Wani ɗan’uwa mai suna farin ciki da kuma farin ciki da kuma iyali .\n",
            "2021-05-04 15:20:40,679 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:20:40,679 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:20:40,679 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:20:40,679 - INFO - joeynmt.training - \tHypothesis: Kamar yadda yake da shi zai iya zama mai kyau ko kuma ya yi amfani da shi , “ mai - hikima ” ko kuma “ dukan duniya ” zai iya sa mutane su kasance da aminci .\n",
            "2021-05-04 15:20:40,679 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:20:40,679 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:20:40,679 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:20:40,680 - INFO - joeynmt.training - \tHypothesis: Suna farin ciki sosai a cikin Littafi Mai Tsarki da kuma koyarwa . — Ishaya 37 : 19 .\n",
            "2021-05-04 15:20:40,680 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:20:40,680 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:20:40,680 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:20:40,680 - INFO - joeynmt.training - \tHypothesis: * Ta yaya zan yi masa biyayya ga Allah . ”\n",
            "2021-05-04 15:20:40,680 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     4000: bleu:   8.89, loss: 68123.6641, ppl:  14.9919, duration: 11.1213s\n",
            "2021-05-04 15:20:50,653 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     3.190817, Tokens per Sec:    21619, Lr: 0.000300\n",
            "2021-05-04 15:21:00,496 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     2.870574, Tokens per Sec:    21393, Lr: 0.000300\n",
            "2021-05-04 15:21:10,437 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     3.036352, Tokens per Sec:    21788, Lr: 0.000300\n",
            "2021-05-04 15:21:20,363 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     2.992985, Tokens per Sec:    21661, Lr: 0.000300\n",
            "2021-05-04 15:21:30,311 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     2.552546, Tokens per Sec:    21628, Lr: 0.000300\n",
            "2021-05-04 15:21:40,191 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     2.729985, Tokens per Sec:    21355, Lr: 0.000300\n",
            "2021-05-04 15:21:50,266 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     2.605189, Tokens per Sec:    21993, Lr: 0.000300\n",
            "2021-05-04 15:22:00,146 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     3.019416, Tokens per Sec:    21665, Lr: 0.000300\n",
            "2021-05-04 15:22:10,022 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     3.118214, Tokens per Sec:    21840, Lr: 0.000300\n",
            "2021-05-04 15:22:19,507 - INFO - joeynmt.training - Epoch   2: total training loss 7360.66\n",
            "2021-05-04 15:22:19,508 - INFO - joeynmt.training - EPOCH 3\n",
            "2021-05-04 15:22:20,359 - INFO - joeynmt.training - Epoch   3, Step:     5000, Batch Loss:     2.839321, Tokens per Sec:    15549, Lr: 0.000300\n",
            "2021-05-04 15:22:37,012 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:22:37,012 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:22:37,012 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:22:37,277 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:22:37,277 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:22:37,695 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:22:37,695 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:22:37,695 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:22:37,695 - INFO - joeynmt.training - \tHypothesis: Wata gida mai farin ciki da kuma farin ciki da kuma iyali .\n",
            "2021-05-04 15:22:37,695 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:22:37,695 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:22:37,695 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:22:37,695 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya yin amfani da shi a kan hanyar da za a iya sa mu yi wa Allah rai , wato , “ dukan duniya ” zai iya sa mutane su kasance da aminci .\n",
            "2021-05-04 15:22:37,695 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:22:37,696 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:22:37,696 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:22:37,696 - INFO - joeynmt.training - \tHypothesis: Sun fahimci cewa suna da salama ta gaskiya ta gaskiya . — Ishaya 18 : 18 .\n",
            "2021-05-04 15:22:37,696 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:22:37,696 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:22:37,696 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:22:37,696 - INFO - joeynmt.training - \tHypothesis: * Ta wurin yin hakan zai sa ni . ”\n",
            "2021-05-04 15:22:37,696 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     5000: bleu:  11.91, loss: 63590.6250, ppl:  12.5203, duration: 17.3370s\n",
            "2021-05-04 15:22:47,577 - INFO - joeynmt.training - Epoch   3, Step:     5100, Batch Loss:     2.668513, Tokens per Sec:    21593, Lr: 0.000300\n",
            "2021-05-04 15:22:57,581 - INFO - joeynmt.training - Epoch   3, Step:     5200, Batch Loss:     2.608630, Tokens per Sec:    21605, Lr: 0.000300\n",
            "2021-05-04 15:23:07,515 - INFO - joeynmt.training - Epoch   3, Step:     5300, Batch Loss:     2.477944, Tokens per Sec:    21421, Lr: 0.000300\n",
            "2021-05-04 15:23:17,404 - INFO - joeynmt.training - Epoch   3, Step:     5400, Batch Loss:     2.749511, Tokens per Sec:    21462, Lr: 0.000300\n",
            "2021-05-04 15:23:27,293 - INFO - joeynmt.training - Epoch   3, Step:     5500, Batch Loss:     3.133108, Tokens per Sec:    21228, Lr: 0.000300\n",
            "2021-05-04 15:23:37,201 - INFO - joeynmt.training - Epoch   3, Step:     5600, Batch Loss:     2.350335, Tokens per Sec:    21220, Lr: 0.000300\n",
            "2021-05-04 15:23:47,016 - INFO - joeynmt.training - Epoch   3, Step:     5700, Batch Loss:     2.745310, Tokens per Sec:    21506, Lr: 0.000300\n",
            "2021-05-04 15:23:56,973 - INFO - joeynmt.training - Epoch   3, Step:     5800, Batch Loss:     2.980063, Tokens per Sec:    22160, Lr: 0.000300\n",
            "2021-05-04 15:24:06,815 - INFO - joeynmt.training - Epoch   3, Step:     5900, Batch Loss:     3.030011, Tokens per Sec:    21108, Lr: 0.000300\n",
            "2021-05-04 15:24:16,794 - INFO - joeynmt.training - Epoch   3, Step:     6000, Batch Loss:     2.490679, Tokens per Sec:    21909, Lr: 0.000300\n",
            "2021-05-04 15:24:32,330 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:24:32,331 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:24:32,331 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:24:32,607 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:24:32,607 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:24:33,003 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:24:33,004 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:24:33,004 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:24:33,004 - INFO - joeynmt.training - \tHypothesis: Wata gida mai suna farin ciki kuma yana da wuya a yi farin ciki .\n",
            "2021-05-04 15:24:33,004 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:24:33,004 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:24:33,004 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:24:33,004 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya yin amfani da shi a hanyar da Allah ya yi , ko kuma yin haƙuri , za a iya “ yi haƙuri ” da mutane masu kyau da za su iya samun rai .\n",
            "2021-05-04 15:24:33,004 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:24:33,005 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:24:33,005 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:24:33,005 - INFO - joeynmt.training - \tHypothesis: Sun fahimci cewa suna son su yi rayuwa a rayuwarsu . — Ishaya 18 : 18 .\n",
            "2021-05-04 15:24:33,005 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:24:33,005 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:24:33,005 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:24:33,005 - INFO - joeynmt.training - \tHypothesis: * Ta yaya zan yi amfani da shi . ”\n",
            "2021-05-04 15:24:33,005 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     6000: bleu:  14.53, loss: 60572.6094, ppl:  11.1051, duration: 16.2109s\n",
            "2021-05-04 15:24:42,890 - INFO - joeynmt.training - Epoch   3, Step:     6100, Batch Loss:     2.364619, Tokens per Sec:    21370, Lr: 0.000300\n",
            "2021-05-04 15:24:52,805 - INFO - joeynmt.training - Epoch   3, Step:     6200, Batch Loss:     2.235600, Tokens per Sec:    21662, Lr: 0.000300\n",
            "2021-05-04 15:25:02,766 - INFO - joeynmt.training - Epoch   3, Step:     6300, Batch Loss:     2.647047, Tokens per Sec:    21970, Lr: 0.000300\n",
            "2021-05-04 15:25:12,796 - INFO - joeynmt.training - Epoch   3, Step:     6400, Batch Loss:     2.485922, Tokens per Sec:    21566, Lr: 0.000300\n",
            "2021-05-04 15:25:22,728 - INFO - joeynmt.training - Epoch   3, Step:     6500, Batch Loss:     2.791592, Tokens per Sec:    21842, Lr: 0.000300\n",
            "2021-05-04 15:25:32,597 - INFO - joeynmt.training - Epoch   3, Step:     6600, Batch Loss:     2.347885, Tokens per Sec:    21394, Lr: 0.000300\n",
            "2021-05-04 15:25:42,571 - INFO - joeynmt.training - Epoch   3, Step:     6700, Batch Loss:     2.736700, Tokens per Sec:    21958, Lr: 0.000300\n",
            "2021-05-04 15:25:52,438 - INFO - joeynmt.training - Epoch   3, Step:     6800, Batch Loss:     2.387038, Tokens per Sec:    21728, Lr: 0.000300\n",
            "2021-05-04 15:26:02,211 - INFO - joeynmt.training - Epoch   3, Step:     6900, Batch Loss:     2.319848, Tokens per Sec:    21279, Lr: 0.000300\n",
            "2021-05-04 15:26:12,118 - INFO - joeynmt.training - Epoch   3, Step:     7000, Batch Loss:     2.075906, Tokens per Sec:    21579, Lr: 0.000300\n",
            "2021-05-04 15:26:30,514 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:26:30,515 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:26:30,515 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:26:30,765 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:26:30,765 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:26:31,166 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:26:31,167 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:26:31,167 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:26:31,167 - INFO - joeynmt.training - \tHypothesis: Wata gida tana farin ciki kuma tana farin ciki sosai don mu sami kwanciyar hankali .\n",
            "2021-05-04 15:26:31,167 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:26:31,167 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:26:31,167 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:26:31,167 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya samun ƙarfin zuciya ko kuma ya yi zunubi , Allah zai “ yi haƙuri ” da mugunta , wato , mutane da yawa za su iya more rayuwa a duniya .\n",
            "2021-05-04 15:26:31,167 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:26:31,168 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:26:31,168 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:26:31,168 - INFO - joeynmt.training - \tHypothesis: Sun fahimci cewa suna da salama ta wajen bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:26:31,168 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:26:31,168 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:26:31,168 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:26:31,168 - INFO - joeynmt.training - \tHypothesis: * Ta wurin yin nufin cewa zan yi masa laifi . ”\n",
            "2021-05-04 15:26:31,168 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     7000: bleu:  15.90, loss: 58054.2109, ppl:  10.0474, duration: 19.0495s\n",
            "2021-05-04 15:26:41,177 - INFO - joeynmt.training - Epoch   3, Step:     7100, Batch Loss:     2.329052, Tokens per Sec:    21709, Lr: 0.000300\n",
            "2021-05-04 15:26:51,080 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:     2.354638, Tokens per Sec:    21263, Lr: 0.000300\n",
            "2021-05-04 15:27:00,934 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:     2.451887, Tokens per Sec:    21440, Lr: 0.000300\n",
            "2021-05-04 15:27:10,899 - INFO - joeynmt.training - Epoch   3, Step:     7400, Batch Loss:     2.744364, Tokens per Sec:    21740, Lr: 0.000300\n",
            "2021-05-04 15:27:20,660 - INFO - joeynmt.training - Epoch   3: total training loss 6518.70\n",
            "2021-05-04 15:27:20,660 - INFO - joeynmt.training - EPOCH 4\n",
            "2021-05-04 15:27:21,156 - INFO - joeynmt.training - Epoch   4, Step:     7500, Batch Loss:     1.968551, Tokens per Sec:     8779, Lr: 0.000300\n",
            "2021-05-04 15:27:31,159 - INFO - joeynmt.training - Epoch   4, Step:     7600, Batch Loss:     1.670732, Tokens per Sec:    21506, Lr: 0.000300\n",
            "2021-05-04 15:27:41,114 - INFO - joeynmt.training - Epoch   4, Step:     7700, Batch Loss:     2.590484, Tokens per Sec:    21566, Lr: 0.000300\n",
            "2021-05-04 15:27:51,107 - INFO - joeynmt.training - Epoch   4, Step:     7800, Batch Loss:     2.309126, Tokens per Sec:    21581, Lr: 0.000300\n",
            "2021-05-04 15:28:01,002 - INFO - joeynmt.training - Epoch   4, Step:     7900, Batch Loss:     2.811205, Tokens per Sec:    21607, Lr: 0.000300\n",
            "2021-05-04 15:28:10,905 - INFO - joeynmt.training - Epoch   4, Step:     8000, Batch Loss:     2.397529, Tokens per Sec:    21709, Lr: 0.000300\n",
            "2021-05-04 15:28:27,461 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:28:27,462 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:28:27,462 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:28:27,711 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:28:27,712 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:28:28,099 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:28:28,099 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:28:28,099 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:28:28,099 - INFO - joeynmt.training - \tHypothesis: Mafi gidanta tana farin ciki kuma yana da sauƙi a yi wa iyalinmu .\n",
            "2021-05-04 15:28:28,099 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:28:28,099 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:28:28,099 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:28:28,100 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya samun haƙuri ko kuma yin rayuwa mai kyau , Allah zai “ kawar da miyagu ” da yawa da ke duniya .\n",
            "2021-05-04 15:28:28,100 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:28:28,100 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:28:28,100 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:28:28,100 - INFO - joeynmt.training - \tHypothesis: Sun sami salama ta hanyar da suke yi a rayuwarsu ta wajen bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:28:28,100 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:28:28,100 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:28:28,100 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:28:28,100 - INFO - joeynmt.training - \tHypothesis: * Ta wurin yin nufin Allah zai yi masa . ”\n",
            "2021-05-04 15:28:28,100 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step     8000: bleu:  17.44, loss: 56168.5859, ppl:   9.3219, duration: 17.1954s\n",
            "2021-05-04 15:28:38,067 - INFO - joeynmt.training - Epoch   4, Step:     8100, Batch Loss:     2.435355, Tokens per Sec:    21477, Lr: 0.000300\n",
            "2021-05-04 15:28:47,926 - INFO - joeynmt.training - Epoch   4, Step:     8200, Batch Loss:     2.540082, Tokens per Sec:    21354, Lr: 0.000300\n",
            "2021-05-04 15:28:57,768 - INFO - joeynmt.training - Epoch   4, Step:     8300, Batch Loss:     2.508212, Tokens per Sec:    21295, Lr: 0.000300\n",
            "2021-05-04 15:29:07,575 - INFO - joeynmt.training - Epoch   4, Step:     8400, Batch Loss:     2.589948, Tokens per Sec:    21423, Lr: 0.000300\n",
            "2021-05-04 15:29:17,415 - INFO - joeynmt.training - Epoch   4, Step:     8500, Batch Loss:     2.224814, Tokens per Sec:    21108, Lr: 0.000300\n",
            "2021-05-04 15:29:27,425 - INFO - joeynmt.training - Epoch   4, Step:     8600, Batch Loss:     2.253810, Tokens per Sec:    21591, Lr: 0.000300\n",
            "2021-05-04 15:29:37,309 - INFO - joeynmt.training - Epoch   4, Step:     8700, Batch Loss:     2.314297, Tokens per Sec:    21161, Lr: 0.000300\n",
            "2021-05-04 15:29:47,287 - INFO - joeynmt.training - Epoch   4, Step:     8800, Batch Loss:     2.168400, Tokens per Sec:    21965, Lr: 0.000300\n",
            "2021-05-04 15:29:57,202 - INFO - joeynmt.training - Epoch   4, Step:     8900, Batch Loss:     2.312088, Tokens per Sec:    21277, Lr: 0.000300\n",
            "2021-05-04 15:30:07,305 - INFO - joeynmt.training - Epoch   4, Step:     9000, Batch Loss:     2.215744, Tokens per Sec:    22192, Lr: 0.000300\n",
            "2021-05-04 15:30:21,500 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:30:21,500 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:30:21,500 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:30:21,750 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:30:21,750 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:30:22,124 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:30:22,124 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:30:22,124 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:30:22,125 - INFO - joeynmt.training - \tHypothesis: Magidanta tana farin ciki kuma tana da ban ƙarfafa iyalai .\n",
            "2021-05-04 15:30:22,125 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:30:22,125 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:30:22,125 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:30:22,125 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya samun tagomashin rai ko kuma yin haƙuri da Allah zai “ tsaya ” da miyagun mutane da yawa da za su more rayuwa mai kyau a duniya .\n",
            "2021-05-04 15:30:22,125 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:30:22,125 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:30:22,125 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:30:22,125 - INFO - joeynmt.training - \tHypothesis: Sun fuskanci salama ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:30:22,125 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:30:22,126 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:30:22,126 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:30:22,126 - INFO - joeynmt.training - \tHypothesis: * Ta wurin yin nufin Allah zai yi masa albarka . ”\n",
            "2021-05-04 15:30:22,126 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step     9000: bleu:  18.72, loss: 54043.5156, ppl:   8.5669, duration: 14.8201s\n",
            "2021-05-04 15:30:32,031 - INFO - joeynmt.training - Epoch   4, Step:     9100, Batch Loss:     2.639573, Tokens per Sec:    21565, Lr: 0.000300\n",
            "2021-05-04 15:30:42,041 - INFO - joeynmt.training - Epoch   4, Step:     9200, Batch Loss:     2.535367, Tokens per Sec:    21440, Lr: 0.000300\n",
            "2021-05-04 15:30:52,012 - INFO - joeynmt.training - Epoch   4, Step:     9300, Batch Loss:     2.390511, Tokens per Sec:    21908, Lr: 0.000300\n",
            "2021-05-04 15:31:01,846 - INFO - joeynmt.training - Epoch   4, Step:     9400, Batch Loss:     2.474350, Tokens per Sec:    21326, Lr: 0.000300\n",
            "2021-05-04 15:31:11,846 - INFO - joeynmt.training - Epoch   4, Step:     9500, Batch Loss:     2.671679, Tokens per Sec:    21825, Lr: 0.000300\n",
            "2021-05-04 15:31:21,850 - INFO - joeynmt.training - Epoch   4, Step:     9600, Batch Loss:     2.271096, Tokens per Sec:    22073, Lr: 0.000300\n",
            "2021-05-04 15:31:31,594 - INFO - joeynmt.training - Epoch   4, Step:     9700, Batch Loss:     2.481997, Tokens per Sec:    21217, Lr: 0.000300\n",
            "2021-05-04 15:31:41,622 - INFO - joeynmt.training - Epoch   4, Step:     9800, Batch Loss:     2.085812, Tokens per Sec:    21891, Lr: 0.000300\n",
            "2021-05-04 15:31:51,514 - INFO - joeynmt.training - Epoch   4, Step:     9900, Batch Loss:     2.671287, Tokens per Sec:    21519, Lr: 0.000300\n",
            "2021-05-04 15:32:01,332 - INFO - joeynmt.training - Epoch   4: total training loss 6000.30\n",
            "2021-05-04 15:32:01,332 - INFO - joeynmt.training - EPOCH 5\n",
            "2021-05-04 15:32:01,716 - INFO - joeynmt.training - Epoch   5, Step:    10000, Batch Loss:     2.528957, Tokens per Sec:     7699, Lr: 0.000300\n",
            "2021-05-04 15:32:13,928 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:32:13,928 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:32:13,928 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:32:14,185 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:32:14,185 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:32:14,581 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:32:14,582 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:32:14,582 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:32:14,582 - INFO - joeynmt.training - \tHypothesis: Mafi kyau yana farin ciki kuma yana da kyau a yi wa iyalinmu hidima .\n",
            "2021-05-04 15:32:14,582 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:32:14,582 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:32:14,582 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:32:14,582 - INFO - joeynmt.training - \tHypothesis: Kamar yadda aka yi a kan tsegumi zai motsa mutum ya yi haƙuri , Allah zai “ kawar da miyagu ” da kuma “ miyagu ” da za su more rayuwa a duniya .\n",
            "2021-05-04 15:32:14,582 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:32:14,582 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:32:14,582 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:32:14,582 - INFO - joeynmt.training - \tHypothesis: Suna da begen yin rayuwa a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:32:14,583 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:32:14,583 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:32:14,583 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:32:14,583 - INFO - joeynmt.training - \tHypothesis: * Ta wurin za a yi masa biyayya . ”\n",
            "2021-05-04 15:32:14,583 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    10000: bleu:  19.22, loss: 52418.2109, ppl:   8.0310, duration: 12.8667s\n",
            "2021-05-04 15:32:24,459 - INFO - joeynmt.training - Epoch   5, Step:    10100, Batch Loss:     2.369074, Tokens per Sec:    21089, Lr: 0.000300\n",
            "2021-05-04 15:32:34,346 - INFO - joeynmt.training - Epoch   5, Step:    10200, Batch Loss:     2.060676, Tokens per Sec:    21368, Lr: 0.000300\n",
            "2021-05-04 15:32:44,350 - INFO - joeynmt.training - Epoch   5, Step:    10300, Batch Loss:     2.135396, Tokens per Sec:    21891, Lr: 0.000300\n",
            "2021-05-04 15:32:54,308 - INFO - joeynmt.training - Epoch   5, Step:    10400, Batch Loss:     2.046204, Tokens per Sec:    21733, Lr: 0.000300\n",
            "2021-05-04 15:33:04,349 - INFO - joeynmt.training - Epoch   5, Step:    10500, Batch Loss:     2.069070, Tokens per Sec:    21845, Lr: 0.000300\n",
            "2021-05-04 15:33:14,218 - INFO - joeynmt.training - Epoch   5, Step:    10600, Batch Loss:     2.645519, Tokens per Sec:    21341, Lr: 0.000300\n",
            "2021-05-04 15:33:24,196 - INFO - joeynmt.training - Epoch   5, Step:    10700, Batch Loss:     2.208388, Tokens per Sec:    21600, Lr: 0.000300\n",
            "2021-05-04 15:33:34,099 - INFO - joeynmt.training - Epoch   5, Step:    10800, Batch Loss:     2.346725, Tokens per Sec:    21443, Lr: 0.000300\n",
            "2021-05-04 15:33:44,136 - INFO - joeynmt.training - Epoch   5, Step:    10900, Batch Loss:     2.344884, Tokens per Sec:    22020, Lr: 0.000300\n",
            "2021-05-04 15:33:54,105 - INFO - joeynmt.training - Epoch   5, Step:    11000, Batch Loss:     2.020163, Tokens per Sec:    21789, Lr: 0.000300\n",
            "2021-05-04 15:34:07,591 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:34:07,591 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:34:07,591 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:34:07,838 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:34:07,838 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:34:08,205 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:34:08,206 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:34:08,206 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:34:08,206 - INFO - joeynmt.training - \tHypothesis: Magidanta yana farin ciki kuma yana da kyau a cikin iyali .\n",
            "2021-05-04 15:34:08,206 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:34:08,206 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:34:08,206 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:34:08,206 - INFO - joeynmt.training - \tHypothesis: Kamar yadda aka yi a cikin yanayi zai iya motsa mutum ya kasance da haƙuri , Allah zai “ kawar da miyagun mutane ” da yawa a duniya .\n",
            "2021-05-04 15:34:08,206 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:34:08,206 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:34:08,207 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:34:08,207 - INFO - joeynmt.training - \tHypothesis: Sun shaida salama ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:34:08,207 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:34:08,207 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:34:08,207 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:34:08,207 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a gare shi . ”\n",
            "2021-05-04 15:34:08,207 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    11000: bleu:  20.11, loss: 51041.7734, ppl:   7.6035, duration: 14.1016s\n",
            "2021-05-04 15:34:18,168 - INFO - joeynmt.training - Epoch   5, Step:    11100, Batch Loss:     2.507944, Tokens per Sec:    21513, Lr: 0.000300\n",
            "2021-05-04 15:34:28,077 - INFO - joeynmt.training - Epoch   5, Step:    11200, Batch Loss:     1.982955, Tokens per Sec:    21246, Lr: 0.000300\n",
            "2021-05-04 15:34:38,073 - INFO - joeynmt.training - Epoch   5, Step:    11300, Batch Loss:     2.502889, Tokens per Sec:    21791, Lr: 0.000300\n",
            "2021-05-04 15:34:48,021 - INFO - joeynmt.training - Epoch   5, Step:    11400, Batch Loss:     2.480612, Tokens per Sec:    21668, Lr: 0.000300\n",
            "2021-05-04 15:34:57,918 - INFO - joeynmt.training - Epoch   5, Step:    11500, Batch Loss:     1.973300, Tokens per Sec:    21243, Lr: 0.000300\n",
            "2021-05-04 15:35:07,768 - INFO - joeynmt.training - Epoch   5, Step:    11600, Batch Loss:     2.032309, Tokens per Sec:    21226, Lr: 0.000300\n",
            "2021-05-04 15:35:17,756 - INFO - joeynmt.training - Epoch   5, Step:    11700, Batch Loss:     2.699896, Tokens per Sec:    21721, Lr: 0.000300\n",
            "2021-05-04 15:35:27,615 - INFO - joeynmt.training - Epoch   5, Step:    11800, Batch Loss:     2.272602, Tokens per Sec:    21597, Lr: 0.000300\n",
            "2021-05-04 15:35:37,630 - INFO - joeynmt.training - Epoch   5, Step:    11900, Batch Loss:     2.636756, Tokens per Sec:    21594, Lr: 0.000300\n",
            "2021-05-04 15:35:47,608 - INFO - joeynmt.training - Epoch   5, Step:    12000, Batch Loss:     2.421333, Tokens per Sec:    21913, Lr: 0.000300\n",
            "2021-05-04 15:35:57,746 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:35:57,746 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:35:57,746 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:35:57,995 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:35:57,995 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:35:58,398 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:35:58,398 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:35:58,398 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:35:58,398 - INFO - joeynmt.training - \tHypothesis: Magidanta yana farin ciki kuma yana da kyau a dukan iyalin .\n",
            "2021-05-04 15:35:58,398 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:35:58,398 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:35:58,398 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:35:58,399 - INFO - joeynmt.training - \tHypothesis: Kamar yadda aka yi a kan tseren da zai iya sa mu kasance da haƙuri , Allah zai “ halaka miyagu ” domin “ miyagun mutane masu - kyau .\n",
            "2021-05-04 15:35:58,399 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:35:58,399 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:35:58,399 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:35:58,399 - INFO - joeynmt.training - \tHypothesis: Sun fuskanci salama a rayuwarsu ta wajen bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:35:58,399 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:35:58,399 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:35:58,399 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:35:58,399 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi masa . ”\n",
            "2021-05-04 15:35:58,399 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    12000: bleu:  20.57, loss: 50055.0938, ppl:   7.3111, duration: 10.7913s\n",
            "2021-05-04 15:36:08,391 - INFO - joeynmt.training - Epoch   5, Step:    12100, Batch Loss:     2.638085, Tokens per Sec:    21741, Lr: 0.000300\n",
            "2021-05-04 15:36:18,296 - INFO - joeynmt.training - Epoch   5, Step:    12200, Batch Loss:     2.146213, Tokens per Sec:    21378, Lr: 0.000300\n",
            "2021-05-04 15:36:28,253 - INFO - joeynmt.training - Epoch   5, Step:    12300, Batch Loss:     2.370723, Tokens per Sec:    21588, Lr: 0.000300\n",
            "2021-05-04 15:36:38,159 - INFO - joeynmt.training - Epoch   5, Step:    12400, Batch Loss:     2.416833, Tokens per Sec:    21378, Lr: 0.000300\n",
            "2021-05-04 15:36:47,644 - INFO - joeynmt.training - Epoch   5: total training loss 5637.38\n",
            "2021-05-04 15:36:47,644 - INFO - joeynmt.training - EPOCH 6\n",
            "2021-05-04 15:36:48,490 - INFO - joeynmt.training - Epoch   6, Step:    12500, Batch Loss:     2.539575, Tokens per Sec:    14994, Lr: 0.000300\n",
            "2021-05-04 15:36:58,388 - INFO - joeynmt.training - Epoch   6, Step:    12600, Batch Loss:     2.457708, Tokens per Sec:    21378, Lr: 0.000300\n",
            "2021-05-04 15:37:08,446 - INFO - joeynmt.training - Epoch   6, Step:    12700, Batch Loss:     1.364865, Tokens per Sec:    21884, Lr: 0.000300\n",
            "2021-05-04 15:37:18,412 - INFO - joeynmt.training - Epoch   6, Step:    12800, Batch Loss:     2.291174, Tokens per Sec:    21657, Lr: 0.000300\n",
            "2021-05-04 15:37:28,342 - INFO - joeynmt.training - Epoch   6, Step:    12900, Batch Loss:     2.576082, Tokens per Sec:    21729, Lr: 0.000300\n",
            "2021-05-04 15:37:38,282 - INFO - joeynmt.training - Epoch   6, Step:    13000, Batch Loss:     1.894943, Tokens per Sec:    21243, Lr: 0.000300\n",
            "2021-05-04 15:37:50,942 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:37:50,942 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:37:50,942 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:37:51,194 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:37:51,194 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:37:51,571 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:37:51,571 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:37:51,571 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:37:51,571 - INFO - joeynmt.training - \tHypothesis: Magidanta yana farin ciki kuma yana da kyau a yi wa iyalai .\n",
            "2021-05-04 15:37:51,571 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:37:51,571 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:37:51,571 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:37:51,572 - INFO - joeynmt.training - \tHypothesis: Kamar yadda aka yi a kan gado zai iya sa mutum ya yi haƙuri ko kuma ya yi haƙuri ga Allah , “ za ya halaka miyagun mutane masu - kyau . ”\n",
            "2021-05-04 15:37:51,572 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:37:51,572 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:37:51,572 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:37:51,572 - INFO - joeynmt.training - \tHypothesis: Sun fuskanci salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:37:51,572 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:37:51,572 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:37:51,572 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:37:51,572 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a gare shi . ”\n",
            "2021-05-04 15:37:51,572 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    13000: bleu:  21.58, loss: 49093.6641, ppl:   7.0370, duration: 13.2902s\n",
            "2021-05-04 15:38:01,553 - INFO - joeynmt.training - Epoch   6, Step:    13100, Batch Loss:     1.890670, Tokens per Sec:    21720, Lr: 0.000300\n",
            "2021-05-04 15:38:11,398 - INFO - joeynmt.training - Epoch   6, Step:    13200, Batch Loss:     2.456108, Tokens per Sec:    21435, Lr: 0.000300\n",
            "2021-05-04 15:38:21,350 - INFO - joeynmt.training - Epoch   6, Step:    13300, Batch Loss:     2.115306, Tokens per Sec:    21512, Lr: 0.000300\n",
            "2021-05-04 15:38:31,328 - INFO - joeynmt.training - Epoch   6, Step:    13400, Batch Loss:     2.150574, Tokens per Sec:    21446, Lr: 0.000300\n",
            "2021-05-04 15:38:41,254 - INFO - joeynmt.training - Epoch   6, Step:    13500, Batch Loss:     1.592712, Tokens per Sec:    21442, Lr: 0.000300\n",
            "2021-05-04 15:38:51,235 - INFO - joeynmt.training - Epoch   6, Step:    13600, Batch Loss:     2.433059, Tokens per Sec:    21701, Lr: 0.000300\n",
            "2021-05-04 15:39:01,123 - INFO - joeynmt.training - Epoch   6, Step:    13700, Batch Loss:     2.474842, Tokens per Sec:    21927, Lr: 0.000300\n",
            "2021-05-04 15:39:10,984 - INFO - joeynmt.training - Epoch   6, Step:    13800, Batch Loss:     2.046794, Tokens per Sec:    21419, Lr: 0.000300\n",
            "2021-05-04 15:39:20,933 - INFO - joeynmt.training - Epoch   6, Step:    13900, Batch Loss:     1.898933, Tokens per Sec:    21655, Lr: 0.000300\n",
            "2021-05-04 15:39:30,915 - INFO - joeynmt.training - Epoch   6, Step:    14000, Batch Loss:     2.132435, Tokens per Sec:    21496, Lr: 0.000300\n",
            "2021-05-04 15:39:42,734 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:39:42,735 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:39:42,735 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:39:42,979 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:39:42,979 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:39:43,359 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:39:43,360 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:39:43,360 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:39:43,360 - INFO - joeynmt.training - \tHypothesis: Magidanta yana da kyau kuma yana da kyau a dukan iyalai .\n",
            "2021-05-04 15:39:43,360 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:39:43,360 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:39:43,360 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:39:43,360 - INFO - joeynmt.training - \tHypothesis: Kamar yadda aka yi a kan gado zai iya motsa mutum ya yi haƙuri , Allah zai “ kawar da miyagu ” domin ya more rayuwa a duniya .\n",
            "2021-05-04 15:39:43,360 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:39:43,360 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:39:43,361 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:39:43,361 - INFO - joeynmt.training - \tHypothesis: Suna da salama a rayuwarsu ta wajen bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:39:43,361 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:39:43,361 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:39:43,361 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:39:43,361 - INFO - joeynmt.training - \tHypothesis: * A dukan duniya , zan yi masa biyayya . ”\n",
            "2021-05-04 15:39:43,361 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    14000: bleu:  21.96, loss: 48136.8750, ppl:   6.7744, duration: 12.4452s\n",
            "2021-05-04 15:39:53,283 - INFO - joeynmt.training - Epoch   6, Step:    14100, Batch Loss:     2.495116, Tokens per Sec:    22004, Lr: 0.000300\n",
            "2021-05-04 15:40:03,258 - INFO - joeynmt.training - Epoch   6, Step:    14200, Batch Loss:     2.380581, Tokens per Sec:    21619, Lr: 0.000300\n",
            "2021-05-04 15:40:13,265 - INFO - joeynmt.training - Epoch   6, Step:    14300, Batch Loss:     2.338693, Tokens per Sec:    22041, Lr: 0.000300\n",
            "2021-05-04 15:40:23,170 - INFO - joeynmt.training - Epoch   6, Step:    14400, Batch Loss:     2.594536, Tokens per Sec:    21500, Lr: 0.000300\n",
            "2021-05-04 15:40:33,147 - INFO - joeynmt.training - Epoch   6, Step:    14500, Batch Loss:     2.107109, Tokens per Sec:    21460, Lr: 0.000300\n",
            "2021-05-04 15:40:43,091 - INFO - joeynmt.training - Epoch   6, Step:    14600, Batch Loss:     2.006577, Tokens per Sec:    21323, Lr: 0.000300\n",
            "2021-05-04 15:40:53,041 - INFO - joeynmt.training - Epoch   6, Step:    14700, Batch Loss:     2.033399, Tokens per Sec:    21836, Lr: 0.000300\n",
            "2021-05-04 15:41:02,979 - INFO - joeynmt.training - Epoch   6, Step:    14800, Batch Loss:     2.102340, Tokens per Sec:    21276, Lr: 0.000300\n",
            "2021-05-04 15:41:12,858 - INFO - joeynmt.training - Epoch   6, Step:    14900, Batch Loss:     1.888215, Tokens per Sec:    21579, Lr: 0.000300\n",
            "2021-05-04 15:41:21,568 - INFO - joeynmt.training - Epoch   6: total training loss 5387.12\n",
            "2021-05-04 15:41:21,568 - INFO - joeynmt.training - EPOCH 7\n",
            "2021-05-04 15:41:23,063 - INFO - joeynmt.training - Epoch   7, Step:    15000, Batch Loss:     1.785726, Tokens per Sec:    18960, Lr: 0.000300\n",
            "2021-05-04 15:41:33,826 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:41:33,826 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:41:33,826 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:41:34,080 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:41:34,080 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:41:34,468 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:41:34,468 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:41:34,468 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:41:34,468 - INFO - joeynmt.training - \tHypothesis: Magidanta yana da kyau kuma yana da kyau a dukan iyali .\n",
            "2021-05-04 15:41:34,468 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:41:34,468 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:41:34,468 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:41:34,468 - INFO - joeynmt.training - \tHypothesis: Kamar yadda aka yi a duniya zai iya sa mutum ya tsira ko kuma ya ceci rai , Allah zai “ halaka miyagu ” domin mutane masu kyau da za su more rayuwa a duniya .\n",
            "2021-05-04 15:41:34,468 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:41:34,469 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:41:34,469 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:41:34,469 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:41:34,469 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:41:34,469 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:41:34,469 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:41:34,469 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi masa . ”\n",
            "2021-05-04 15:41:34,469 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    15000: bleu:  22.21, loss: 47430.9570, ppl:   6.5870, duration: 11.4055s\n",
            "2021-05-04 15:41:44,442 - INFO - joeynmt.training - Epoch   7, Step:    15100, Batch Loss:     1.940388, Tokens per Sec:    21865, Lr: 0.000300\n",
            "2021-05-04 15:41:54,345 - INFO - joeynmt.training - Epoch   7, Step:    15200, Batch Loss:     2.054428, Tokens per Sec:    21816, Lr: 0.000300\n",
            "2021-05-04 15:42:04,185 - INFO - joeynmt.training - Epoch   7, Step:    15300, Batch Loss:     2.040367, Tokens per Sec:    21893, Lr: 0.000300\n",
            "2021-05-04 15:42:14,056 - INFO - joeynmt.training - Epoch   7, Step:    15400, Batch Loss:     2.350744, Tokens per Sec:    22093, Lr: 0.000300\n",
            "2021-05-04 15:42:23,904 - INFO - joeynmt.training - Epoch   7, Step:    15500, Batch Loss:     2.353095, Tokens per Sec:    21573, Lr: 0.000300\n",
            "2021-05-04 15:42:33,824 - INFO - joeynmt.training - Epoch   7, Step:    15600, Batch Loss:     1.473323, Tokens per Sec:    21845, Lr: 0.000300\n",
            "2021-05-04 15:42:43,873 - INFO - joeynmt.training - Epoch   7, Step:    15700, Batch Loss:     2.135247, Tokens per Sec:    21860, Lr: 0.000300\n",
            "2021-05-04 15:42:53,731 - INFO - joeynmt.training - Epoch   7, Step:    15800, Batch Loss:     2.015415, Tokens per Sec:    21798, Lr: 0.000300\n",
            "2021-05-04 15:43:03,591 - INFO - joeynmt.training - Epoch   7, Step:    15900, Batch Loss:     2.087177, Tokens per Sec:    21066, Lr: 0.000300\n",
            "2021-05-04 15:43:13,510 - INFO - joeynmt.training - Epoch   7, Step:    16000, Batch Loss:     2.189523, Tokens per Sec:    21998, Lr: 0.000300\n",
            "2021-05-04 15:43:24,872 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:43:24,872 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:43:24,872 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:43:25,122 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:43:25,122 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:43:25,463 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:43:25,463 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:43:25,463 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:43:25,463 - INFO - joeynmt.training - \tHypothesis: Idan ba a yi wa iyalinmu farin ciki ba , hakan zai sa mu yi farin ciki sosai .\n",
            "2021-05-04 15:43:25,463 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:43:25,464 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:43:25,464 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:43:25,464 - INFO - joeynmt.training - \tHypothesis: Kamar yadda aka yi a duniya zai iya motsa mutum ya tsira daga rayuwa , Allah zai “ halaka miyagun mutane ” domin mutane masu kirki za su more rayuwa a duniya .\n",
            "2021-05-04 15:43:25,464 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:43:25,464 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:43:25,464 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:43:25,464 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:43:25,464 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:43:25,464 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:43:25,464 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:43:25,464 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan duniya za a yi masa sujada . ”\n",
            "2021-05-04 15:43:25,465 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    16000: bleu:  22.54, loss: 46602.2227, ppl:   6.3736, duration: 11.9538s\n",
            "2021-05-04 15:43:35,330 - INFO - joeynmt.training - Epoch   7, Step:    16100, Batch Loss:     1.987410, Tokens per Sec:    21766, Lr: 0.000300\n",
            "2021-05-04 15:43:45,125 - INFO - joeynmt.training - Epoch   7, Step:    16200, Batch Loss:     2.018509, Tokens per Sec:    21472, Lr: 0.000300\n",
            "2021-05-04 15:43:55,003 - INFO - joeynmt.training - Epoch   7, Step:    16300, Batch Loss:     2.096290, Tokens per Sec:    21762, Lr: 0.000300\n",
            "2021-05-04 15:44:04,819 - INFO - joeynmt.training - Epoch   7, Step:    16400, Batch Loss:     2.086224, Tokens per Sec:    21502, Lr: 0.000300\n",
            "2021-05-04 15:44:14,756 - INFO - joeynmt.training - Epoch   7, Step:    16500, Batch Loss:     1.828749, Tokens per Sec:    21991, Lr: 0.000300\n",
            "2021-05-04 15:44:24,647 - INFO - joeynmt.training - Epoch   7, Step:    16600, Batch Loss:     1.949552, Tokens per Sec:    21684, Lr: 0.000300\n",
            "2021-05-04 15:44:34,539 - INFO - joeynmt.training - Epoch   7, Step:    16700, Batch Loss:     1.975749, Tokens per Sec:    21630, Lr: 0.000300\n",
            "2021-05-04 15:44:44,457 - INFO - joeynmt.training - Epoch   7, Step:    16800, Batch Loss:     2.234316, Tokens per Sec:    21383, Lr: 0.000300\n",
            "2021-05-04 15:44:54,333 - INFO - joeynmt.training - Epoch   7, Step:    16900, Batch Loss:     2.099680, Tokens per Sec:    21379, Lr: 0.000300\n",
            "2021-05-04 15:45:04,263 - INFO - joeynmt.training - Epoch   7, Step:    17000, Batch Loss:     2.172381, Tokens per Sec:    21446, Lr: 0.000300\n",
            "2021-05-04 15:45:16,282 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:45:16,282 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:45:16,282 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:45:16,537 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:45:16,537 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:45:16,928 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:45:16,929 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:45:16,929 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:45:16,929 - INFO - joeynmt.training - \tHypothesis: A gida yana da kyau kuma yana da kyau a yi wa iyalinmu tanadi .\n",
            "2021-05-04 15:45:16,929 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:45:16,929 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:45:16,929 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:45:16,929 - INFO - joeynmt.training - \tHypothesis: Kamar yadda aka yi nasara a duniya zai iya sa mutum ya tsira daga rayuwa , Allah zai “ halaka ” domin miyagu masu kyau da za su more rayuwa a duniya .\n",
            "2021-05-04 15:45:16,929 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:45:16,930 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:45:16,930 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:45:16,930 - INFO - joeynmt.training - \tHypothesis: Sun fuskanci salama ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:45:16,930 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:45:16,930 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:45:16,930 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:45:16,930 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan duniya za ta yi masa albarka . ”\n",
            "2021-05-04 15:45:16,930 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    17000: bleu:  22.74, loss: 46469.9297, ppl:   6.3402, duration: 12.6668s\n",
            "2021-05-04 15:45:26,769 - INFO - joeynmt.training - Epoch   7, Step:    17100, Batch Loss:     2.529991, Tokens per Sec:    21522, Lr: 0.000300\n",
            "2021-05-04 15:45:36,741 - INFO - joeynmt.training - Epoch   7, Step:    17200, Batch Loss:     2.090135, Tokens per Sec:    21767, Lr: 0.000300\n",
            "2021-05-04 15:45:46,684 - INFO - joeynmt.training - Epoch   7, Step:    17300, Batch Loss:     2.137247, Tokens per Sec:    21192, Lr: 0.000300\n",
            "2021-05-04 15:45:56,581 - INFO - joeynmt.training - Epoch   7, Step:    17400, Batch Loss:     1.690568, Tokens per Sec:    21874, Lr: 0.000300\n",
            "2021-05-04 15:46:05,115 - INFO - joeynmt.training - Epoch   7: total training loss 5194.81\n",
            "2021-05-04 15:46:05,115 - INFO - joeynmt.training - EPOCH 8\n",
            "2021-05-04 15:46:06,682 - INFO - joeynmt.training - Epoch   8, Step:    17500, Batch Loss:     1.676177, Tokens per Sec:    17500, Lr: 0.000300\n",
            "2021-05-04 15:46:16,508 - INFO - joeynmt.training - Epoch   8, Step:    17600, Batch Loss:     1.904032, Tokens per Sec:    21288, Lr: 0.000300\n",
            "2021-05-04 15:46:26,407 - INFO - joeynmt.training - Epoch   8, Step:    17700, Batch Loss:     1.788634, Tokens per Sec:    21219, Lr: 0.000300\n",
            "2021-05-04 15:46:36,356 - INFO - joeynmt.training - Epoch   8, Step:    17800, Batch Loss:     2.029494, Tokens per Sec:    21494, Lr: 0.000300\n",
            "2021-05-04 15:46:46,267 - INFO - joeynmt.training - Epoch   8, Step:    17900, Batch Loss:     1.997058, Tokens per Sec:    21116, Lr: 0.000300\n",
            "2021-05-04 15:46:56,296 - INFO - joeynmt.training - Epoch   8, Step:    18000, Batch Loss:     2.043913, Tokens per Sec:    21753, Lr: 0.000300\n",
            "2021-05-04 15:47:06,814 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:47:06,815 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:47:06,815 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:47:07,077 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:47:07,077 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:47:07,425 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:47:07,425 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:47:07,425 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:47:07,425 - INFO - joeynmt.training - \tHypothesis: Magidanta yana da daɗi kuma yana da kyau a dukan iyalin .\n",
            "2021-05-04 15:47:07,425 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:47:07,426 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:47:07,426 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:47:07,426 - INFO - joeynmt.training - \tHypothesis: Kamar yadda aka yi nasara a duniya zai iya sa mutum ya tsira daga rayuwa , Allah zai “ tashi ” saboda miyagu da za su iya more rayuwa a duniya .\n",
            "2021-05-04 15:47:07,426 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:47:07,426 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:47:07,426 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:47:07,426 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:47:07,426 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:47:07,426 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:47:07,426 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:47:07,426 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 15:47:07,426 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    18000: bleu:  23.51, loss: 45306.6953, ppl:   6.0537, duration: 11.1306s\n",
            "2021-05-04 15:47:17,422 - INFO - joeynmt.training - Epoch   8, Step:    18100, Batch Loss:     1.784214, Tokens per Sec:    21492, Lr: 0.000300\n",
            "2021-05-04 15:47:27,425 - INFO - joeynmt.training - Epoch   8, Step:    18200, Batch Loss:     1.909622, Tokens per Sec:    21719, Lr: 0.000300\n",
            "2021-05-04 15:47:37,456 - INFO - joeynmt.training - Epoch   8, Step:    18300, Batch Loss:     2.137947, Tokens per Sec:    21631, Lr: 0.000300\n",
            "2021-05-04 15:47:47,517 - INFO - joeynmt.training - Epoch   8, Step:    18400, Batch Loss:     1.582088, Tokens per Sec:    22025, Lr: 0.000300\n",
            "2021-05-04 15:47:57,547 - INFO - joeynmt.training - Epoch   8, Step:    18500, Batch Loss:     1.866864, Tokens per Sec:    21743, Lr: 0.000300\n",
            "2021-05-04 15:48:07,447 - INFO - joeynmt.training - Epoch   8, Step:    18600, Batch Loss:     1.837876, Tokens per Sec:    21392, Lr: 0.000300\n",
            "2021-05-04 15:48:17,409 - INFO - joeynmt.training - Epoch   8, Step:    18700, Batch Loss:     1.695490, Tokens per Sec:    21729, Lr: 0.000300\n",
            "2021-05-04 15:48:27,301 - INFO - joeynmt.training - Epoch   8, Step:    18800, Batch Loss:     1.905964, Tokens per Sec:    21566, Lr: 0.000300\n",
            "2021-05-04 15:48:37,368 - INFO - joeynmt.training - Epoch   8, Step:    18900, Batch Loss:     1.674111, Tokens per Sec:    21903, Lr: 0.000300\n",
            "2021-05-04 15:48:47,409 - INFO - joeynmt.training - Epoch   8, Step:    19000, Batch Loss:     2.126298, Tokens per Sec:    21541, Lr: 0.000300\n",
            "2021-05-04 15:48:59,504 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:48:59,504 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:48:59,505 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:48:59,749 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:48:59,750 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:49:00,123 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:49:00,123 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:49:00,123 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:49:00,123 - INFO - joeynmt.training - \tHypothesis: ( 1 Timothawus 3 : 1 ) Magidanta yana da kyau kuma yana da kyau a sami kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:49:00,123 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:49:00,123 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:49:00,124 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:49:00,124 - INFO - joeynmt.training - \tHypothesis: Kamar yadda aka yi nasara a kan tseren da zai iya sa mutum ya tsira daga rayuwa , Allah zai “ rufe ” saboda miyagun mutane masu kyau su more rayuwa a duniya .\n",
            "2021-05-04 15:49:00,124 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:49:00,124 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:49:00,124 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:49:00,124 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:49:00,124 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:49:00,124 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:49:00,124 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:49:00,124 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a bisa shi . ”\n",
            "2021-05-04 15:49:00,124 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    19000: bleu:  23.94, loss: 44839.2500, ppl:   5.9423, duration: 12.7149s\n",
            "2021-05-04 15:49:10,030 - INFO - joeynmt.training - Epoch   8, Step:    19100, Batch Loss:     1.978700, Tokens per Sec:    21382, Lr: 0.000300\n",
            "2021-05-04 15:49:19,985 - INFO - joeynmt.training - Epoch   8, Step:    19200, Batch Loss:     2.007665, Tokens per Sec:    21651, Lr: 0.000300\n",
            "2021-05-04 15:49:29,990 - INFO - joeynmt.training - Epoch   8, Step:    19300, Batch Loss:     1.747461, Tokens per Sec:    22001, Lr: 0.000300\n",
            "2021-05-04 15:49:39,800 - INFO - joeynmt.training - Epoch   8, Step:    19400, Batch Loss:     2.816568, Tokens per Sec:    21268, Lr: 0.000300\n",
            "2021-05-04 15:49:49,766 - INFO - joeynmt.training - Epoch   8, Step:    19500, Batch Loss:     2.188967, Tokens per Sec:    21754, Lr: 0.000300\n",
            "2021-05-04 15:49:59,666 - INFO - joeynmt.training - Epoch   8, Step:    19600, Batch Loss:     2.002140, Tokens per Sec:    21504, Lr: 0.000300\n",
            "2021-05-04 15:50:09,610 - INFO - joeynmt.training - Epoch   8, Step:    19700, Batch Loss:     2.358958, Tokens per Sec:    21629, Lr: 0.000300\n",
            "2021-05-04 15:50:19,539 - INFO - joeynmt.training - Epoch   8, Step:    19800, Batch Loss:     2.288377, Tokens per Sec:    21414, Lr: 0.000300\n",
            "2021-05-04 15:50:29,329 - INFO - joeynmt.training - Epoch   8, Step:    19900, Batch Loss:     2.240881, Tokens per Sec:    21080, Lr: 0.000300\n",
            "2021-05-04 15:50:37,895 - INFO - joeynmt.training - Epoch   8: total training loss 5031.01\n",
            "2021-05-04 15:50:37,896 - INFO - joeynmt.training - EPOCH 9\n",
            "2021-05-04 15:50:39,542 - INFO - joeynmt.training - Epoch   9, Step:    20000, Batch Loss:     1.914986, Tokens per Sec:    16909, Lr: 0.000300\n",
            "2021-05-04 15:50:52,839 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:50:52,839 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:50:52,839 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:50:53,089 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:50:53,089 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:50:53,441 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:50:53,441 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:50:53,441 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:50:53,441 - INFO - joeynmt.training - \tHypothesis: Magidanta yana da daɗi kuma yana da kyau a wurin dukan iyali .\n",
            "2021-05-04 15:50:53,441 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:50:53,441 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:50:53,441 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:50:53,441 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da wannan dabbobi ko kuma ya ceci rai , Allah zai “ kawar da ” saboda mugayen mutane masu kyau da za su more rayuwa a duniya .\n",
            "2021-05-04 15:50:53,441 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:50:53,442 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:50:53,442 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:50:53,442 - INFO - joeynmt.training - \tHypothesis: Sun sami kwanciyar rai a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:50:53,442 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:50:53,442 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:50:53,442 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:50:53,442 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 15:50:53,442 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    20000: bleu:  24.50, loss: 44355.1211, ppl:   5.8290, duration: 13.9002s\n",
            "2021-05-04 15:51:03,430 - INFO - joeynmt.training - Epoch   9, Step:    20100, Batch Loss:     1.718169, Tokens per Sec:    21690, Lr: 0.000300\n",
            "2021-05-04 15:51:13,364 - INFO - joeynmt.training - Epoch   9, Step:    20200, Batch Loss:     2.052196, Tokens per Sec:    21678, Lr: 0.000300\n",
            "2021-05-04 15:51:23,352 - INFO - joeynmt.training - Epoch   9, Step:    20300, Batch Loss:     2.013378, Tokens per Sec:    21774, Lr: 0.000300\n",
            "2021-05-04 15:51:33,305 - INFO - joeynmt.training - Epoch   9, Step:    20400, Batch Loss:     2.175079, Tokens per Sec:    21676, Lr: 0.000300\n",
            "2021-05-04 15:51:43,263 - INFO - joeynmt.training - Epoch   9, Step:    20500, Batch Loss:     1.988985, Tokens per Sec:    21189, Lr: 0.000300\n",
            "2021-05-04 15:51:53,243 - INFO - joeynmt.training - Epoch   9, Step:    20600, Batch Loss:     1.924099, Tokens per Sec:    21915, Lr: 0.000300\n",
            "2021-05-04 15:52:03,185 - INFO - joeynmt.training - Epoch   9, Step:    20700, Batch Loss:     2.158504, Tokens per Sec:    21285, Lr: 0.000300\n",
            "2021-05-04 15:52:13,132 - INFO - joeynmt.training - Epoch   9, Step:    20800, Batch Loss:     2.110269, Tokens per Sec:    21671, Lr: 0.000300\n",
            "2021-05-04 15:52:22,893 - INFO - joeynmt.training - Epoch   9, Step:    20900, Batch Loss:     2.096233, Tokens per Sec:    21179, Lr: 0.000300\n",
            "2021-05-04 15:52:32,868 - INFO - joeynmt.training - Epoch   9, Step:    21000, Batch Loss:     2.055526, Tokens per Sec:    21438, Lr: 0.000300\n",
            "2021-05-04 15:52:44,132 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:52:44,132 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:52:44,132 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:52:44,381 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:52:44,381 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:52:44,715 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:52:44,715 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:52:44,715 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:52:44,715 - INFO - joeynmt.training - \tHypothesis: Magidanta yana da kyau kuma yana da kyau a iyalin .\n",
            "2021-05-04 15:52:44,715 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:52:44,715 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:52:44,715 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:52:44,716 - INFO - joeynmt.training - \tHypothesis: Kamar yadda aka yi nasara a kan gadōn da zai iya sa mutum ya ceci rai , Allah zai “ rufe ” mugayen mutane masu kyau da za su more rayuwa a duniya .\n",
            "2021-05-04 15:52:44,716 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:52:44,716 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:52:44,716 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:52:44,716 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:52:44,716 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:52:44,716 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:52:44,716 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:52:44,716 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi masa . ”\n",
            "2021-05-04 15:52:44,716 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    21000: bleu:  24.34, loss: 43949.3633, ppl:   5.7358, duration: 11.8478s\n",
            "2021-05-04 15:52:54,553 - INFO - joeynmt.training - Epoch   9, Step:    21100, Batch Loss:     1.890308, Tokens per Sec:    21392, Lr: 0.000300\n",
            "2021-05-04 15:53:04,538 - INFO - joeynmt.training - Epoch   9, Step:    21200, Batch Loss:     2.051321, Tokens per Sec:    22042, Lr: 0.000300\n",
            "2021-05-04 15:53:14,456 - INFO - joeynmt.training - Epoch   9, Step:    21300, Batch Loss:     2.169920, Tokens per Sec:    21472, Lr: 0.000300\n",
            "2021-05-04 15:53:24,389 - INFO - joeynmt.training - Epoch   9, Step:    21400, Batch Loss:     1.777657, Tokens per Sec:    21747, Lr: 0.000300\n",
            "2021-05-04 15:53:34,344 - INFO - joeynmt.training - Epoch   9, Step:    21500, Batch Loss:     1.788966, Tokens per Sec:    21922, Lr: 0.000300\n",
            "2021-05-04 15:53:44,280 - INFO - joeynmt.training - Epoch   9, Step:    21600, Batch Loss:     1.921848, Tokens per Sec:    21371, Lr: 0.000300\n",
            "2021-05-04 15:53:54,299 - INFO - joeynmt.training - Epoch   9, Step:    21700, Batch Loss:     1.811719, Tokens per Sec:    22011, Lr: 0.000300\n",
            "2021-05-04 15:54:04,182 - INFO - joeynmt.training - Epoch   9, Step:    21800, Batch Loss:     1.930955, Tokens per Sec:    21437, Lr: 0.000300\n",
            "2021-05-04 15:54:14,124 - INFO - joeynmt.training - Epoch   9, Step:    21900, Batch Loss:     1.960503, Tokens per Sec:    21839, Lr: 0.000300\n",
            "2021-05-04 15:54:24,060 - INFO - joeynmt.training - Epoch   9, Step:    22000, Batch Loss:     1.900278, Tokens per Sec:    21538, Lr: 0.000300\n",
            "2021-05-04 15:54:35,691 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:54:35,691 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:54:35,691 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:54:35,934 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:54:35,934 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:54:36,317 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:54:36,317 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:54:36,317 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:54:36,317 - INFO - joeynmt.training - \tHypothesis: Magidanta yana da daɗi kuma yana da kyau a dukan iyali .\n",
            "2021-05-04 15:54:36,317 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:54:36,318 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:54:36,318 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:54:36,318 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da rayuwa ko kuma a ceci rai , Allah zai “ rushe ” saboda miyagun mutane masu kirki da gaske za su more rayuwa a duniya .\n",
            "2021-05-04 15:54:36,318 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:54:36,318 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:54:36,318 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:54:36,318 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:54:36,318 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:54:36,318 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:54:36,318 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:54:36,318 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan duniya za ya yi masa albarka . ”\n",
            "2021-05-04 15:54:36,319 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    22000: bleu:  24.98, loss: 43371.0234, ppl:   5.6055, duration: 12.2580s\n",
            "2021-05-04 15:54:46,309 - INFO - joeynmt.training - Epoch   9, Step:    22100, Batch Loss:     2.121494, Tokens per Sec:    21170, Lr: 0.000300\n",
            "2021-05-04 15:54:56,422 - INFO - joeynmt.training - Epoch   9, Step:    22200, Batch Loss:     2.227874, Tokens per Sec:    21887, Lr: 0.000300\n",
            "2021-05-04 15:55:06,294 - INFO - joeynmt.training - Epoch   9, Step:    22300, Batch Loss:     1.893790, Tokens per Sec:    21394, Lr: 0.000300\n",
            "2021-05-04 15:55:16,203 - INFO - joeynmt.training - Epoch   9, Step:    22400, Batch Loss:     2.056356, Tokens per Sec:    21448, Lr: 0.000300\n",
            "2021-05-04 15:55:24,392 - INFO - joeynmt.training - Epoch   9: total training loss 4890.82\n",
            "2021-05-04 15:55:24,392 - INFO - joeynmt.training - EPOCH 10\n",
            "2021-05-04 15:55:26,415 - INFO - joeynmt.training - Epoch  10, Step:    22500, Batch Loss:     1.990791, Tokens per Sec:    19979, Lr: 0.000300\n",
            "2021-05-04 15:55:36,263 - INFO - joeynmt.training - Epoch  10, Step:    22600, Batch Loss:     1.592771, Tokens per Sec:    21232, Lr: 0.000300\n",
            "2021-05-04 15:55:46,223 - INFO - joeynmt.training - Epoch  10, Step:    22700, Batch Loss:     2.078689, Tokens per Sec:    21578, Lr: 0.000300\n",
            "2021-05-04 15:55:56,100 - INFO - joeynmt.training - Epoch  10, Step:    22800, Batch Loss:     1.946098, Tokens per Sec:    21389, Lr: 0.000300\n",
            "2021-05-04 15:56:06,030 - INFO - joeynmt.training - Epoch  10, Step:    22900, Batch Loss:     1.870298, Tokens per Sec:    21913, Lr: 0.000300\n",
            "2021-05-04 15:56:15,957 - INFO - joeynmt.training - Epoch  10, Step:    23000, Batch Loss:     2.149150, Tokens per Sec:    21748, Lr: 0.000300\n",
            "2021-05-04 15:56:27,819 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:56:27,819 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:56:27,819 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:56:28,109 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:56:28,109 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:56:28,491 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:56:28,491 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:56:28,491 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:56:28,491 - INFO - joeynmt.training - \tHypothesis: Magidanta yana da kyau kuma yana da kyau a dukan iyalin .\n",
            "2021-05-04 15:56:28,491 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:56:28,491 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:56:28,491 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:56:28,491 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da rayuwa mai ma’ana ko kuma ya ceci rai , Allah zai “ kawar da ” muguwar mutane masu kyau da za su more rayuwa a duniya .\n",
            "2021-05-04 15:56:28,491 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:56:28,492 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:56:28,492 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:56:28,492 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:56:28,492 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:56:28,492 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:56:28,492 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:56:28,492 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 15:56:28,492 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    23000: bleu:  25.20, loss: 43022.9219, ppl:   5.5284, duration: 12.5343s\n",
            "2021-05-04 15:56:38,364 - INFO - joeynmt.training - Epoch  10, Step:    23100, Batch Loss:     1.861885, Tokens per Sec:    21592, Lr: 0.000300\n",
            "2021-05-04 15:56:48,144 - INFO - joeynmt.training - Epoch  10, Step:    23200, Batch Loss:     1.846450, Tokens per Sec:    21492, Lr: 0.000300\n",
            "2021-05-04 15:56:58,053 - INFO - joeynmt.training - Epoch  10, Step:    23300, Batch Loss:     1.897753, Tokens per Sec:    21839, Lr: 0.000300\n",
            "2021-05-04 15:57:08,051 - INFO - joeynmt.training - Epoch  10, Step:    23400, Batch Loss:     1.818404, Tokens per Sec:    21557, Lr: 0.000300\n",
            "2021-05-04 15:57:17,969 - INFO - joeynmt.training - Epoch  10, Step:    23500, Batch Loss:     1.920619, Tokens per Sec:    21562, Lr: 0.000300\n",
            "2021-05-04 15:57:27,865 - INFO - joeynmt.training - Epoch  10, Step:    23600, Batch Loss:     1.593203, Tokens per Sec:    21534, Lr: 0.000300\n",
            "2021-05-04 15:57:37,761 - INFO - joeynmt.training - Epoch  10, Step:    23700, Batch Loss:     1.857657, Tokens per Sec:    21547, Lr: 0.000300\n",
            "2021-05-04 15:57:47,808 - INFO - joeynmt.training - Epoch  10, Step:    23800, Batch Loss:     2.033134, Tokens per Sec:    21618, Lr: 0.000300\n",
            "2021-05-04 15:57:57,740 - INFO - joeynmt.training - Epoch  10, Step:    23900, Batch Loss:     1.835043, Tokens per Sec:    21568, Lr: 0.000300\n",
            "2021-05-04 15:58:07,693 - INFO - joeynmt.training - Epoch  10, Step:    24000, Batch Loss:     1.970732, Tokens per Sec:    21068, Lr: 0.000300\n",
            "2021-05-04 15:58:18,394 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 15:58:18,394 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 15:58:18,394 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 15:58:18,639 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 15:58:18,639 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 15:58:19,001 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 15:58:19,002 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 15:58:19,002 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 15:58:19,002 - INFO - joeynmt.training - \tHypothesis: Magidanta yana da daɗi kuma yana da kyau a dukan iyali .\n",
            "2021-05-04 15:58:19,002 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 15:58:19,002 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 15:58:19,002 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 15:58:19,002 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da rayuwa ko kuma ceton rai , Allah zai “ kawar ” miyagun mutane masu kyau da za su more rayuwa a duniya .\n",
            "2021-05-04 15:58:19,002 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 15:58:19,002 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 15:58:19,002 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:58:19,002 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da mizanan Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 15:58:19,002 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 15:58:19,003 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 15:58:19,003 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 15:58:19,003 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan duniya za ya yi tsaro a gareshi . ”\n",
            "2021-05-04 15:58:19,003 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    24000: bleu:  25.20, loss: 42573.8633, ppl:   5.4306, duration: 11.3091s\n",
            "2021-05-04 15:58:28,942 - INFO - joeynmt.training - Epoch  10, Step:    24100, Batch Loss:     1.947188, Tokens per Sec:    21826, Lr: 0.000300\n",
            "2021-05-04 15:58:38,858 - INFO - joeynmt.training - Epoch  10, Step:    24200, Batch Loss:     1.516068, Tokens per Sec:    21326, Lr: 0.000300\n",
            "2021-05-04 15:58:48,845 - INFO - joeynmt.training - Epoch  10, Step:    24300, Batch Loss:     1.970888, Tokens per Sec:    21870, Lr: 0.000300\n",
            "2021-05-04 15:58:58,763 - INFO - joeynmt.training - Epoch  10, Step:    24400, Batch Loss:     1.979913, Tokens per Sec:    21274, Lr: 0.000300\n",
            "2021-05-04 15:59:08,699 - INFO - joeynmt.training - Epoch  10, Step:    24500, Batch Loss:     1.771482, Tokens per Sec:    22088, Lr: 0.000300\n",
            "2021-05-04 15:59:18,679 - INFO - joeynmt.training - Epoch  10, Step:    24600, Batch Loss:     1.712439, Tokens per Sec:    21814, Lr: 0.000300\n",
            "2021-05-04 15:59:28,541 - INFO - joeynmt.training - Epoch  10, Step:    24700, Batch Loss:     2.106413, Tokens per Sec:    21473, Lr: 0.000300\n",
            "2021-05-04 15:59:38,551 - INFO - joeynmt.training - Epoch  10, Step:    24800, Batch Loss:     1.968477, Tokens per Sec:    21978, Lr: 0.000300\n",
            "2021-05-04 15:59:48,501 - INFO - joeynmt.training - Epoch  10, Step:    24900, Batch Loss:     1.945156, Tokens per Sec:    21118, Lr: 0.000300\n",
            "2021-05-04 15:59:56,618 - INFO - joeynmt.training - Epoch  10: total training loss 4794.20\n",
            "2021-05-04 15:59:56,618 - INFO - joeynmt.training - EPOCH 11\n",
            "2021-05-04 15:59:58,734 - INFO - joeynmt.training - Epoch  11, Step:    25000, Batch Loss:     1.928810, Tokens per Sec:    18844, Lr: 0.000300\n",
            "2021-05-04 16:00:10,228 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:00:10,229 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:00:10,229 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:00:10,510 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:00:10,510 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:00:10,851 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:00:10,851 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:00:10,851 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:00:10,851 - INFO - joeynmt.training - \tHypothesis: Iyali tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:00:10,851 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:00:10,852 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:00:10,852 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:00:10,852 - INFO - joeynmt.training - \tHypothesis: Kamar yadda aka yi nasara a duniya zai iya kawar da rayuwa mai haƙuri , Allah zai “ kawar da ” miyagun mutane masu kirki da za su more rayuwa a duniya .\n",
            "2021-05-04 16:00:10,852 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:00:10,852 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:00:10,852 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:00:10,852 - INFO - joeynmt.training - \tHypothesis: Sun sami kwanciyar hankali a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:00:10,852 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:00:10,852 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:00:10,852 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:00:10,852 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:00:10,852 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    25000: bleu:  25.94, loss: 42334.5547, ppl:   5.3792, duration: 12.1184s\n",
            "2021-05-04 16:00:20,736 - INFO - joeynmt.training - Epoch  11, Step:    25100, Batch Loss:     1.856171, Tokens per Sec:    21648, Lr: 0.000300\n",
            "2021-05-04 16:00:30,639 - INFO - joeynmt.training - Epoch  11, Step:    25200, Batch Loss:     1.783175, Tokens per Sec:    21317, Lr: 0.000300\n",
            "2021-05-04 16:00:40,617 - INFO - joeynmt.training - Epoch  11, Step:    25300, Batch Loss:     1.827937, Tokens per Sec:    21389, Lr: 0.000300\n",
            "2021-05-04 16:00:50,561 - INFO - joeynmt.training - Epoch  11, Step:    25400, Batch Loss:     1.984054, Tokens per Sec:    21485, Lr: 0.000300\n",
            "2021-05-04 16:01:00,587 - INFO - joeynmt.training - Epoch  11, Step:    25500, Batch Loss:     1.811305, Tokens per Sec:    21659, Lr: 0.000300\n",
            "2021-05-04 16:01:10,484 - INFO - joeynmt.training - Epoch  11, Step:    25600, Batch Loss:     1.845318, Tokens per Sec:    21608, Lr: 0.000300\n",
            "2021-05-04 16:01:20,376 - INFO - joeynmt.training - Epoch  11, Step:    25700, Batch Loss:     1.911483, Tokens per Sec:    21429, Lr: 0.000300\n",
            "2021-05-04 16:01:30,343 - INFO - joeynmt.training - Epoch  11, Step:    25800, Batch Loss:     1.744284, Tokens per Sec:    21734, Lr: 0.000300\n",
            "2021-05-04 16:01:40,328 - INFO - joeynmt.training - Epoch  11, Step:    25900, Batch Loss:     1.689547, Tokens per Sec:    21730, Lr: 0.000300\n",
            "2021-05-04 16:01:50,210 - INFO - joeynmt.training - Epoch  11, Step:    26000, Batch Loss:     2.106220, Tokens per Sec:    21444, Lr: 0.000300\n",
            "2021-05-04 16:02:00,901 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:02:00,901 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:02:00,901 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:02:01,150 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:02:01,150 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:02:01,511 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:02:01,512 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:02:01,512 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:02:01,512 - INFO - joeynmt.training - \tHypothesis: Magidanta yana da kyau kuma yana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:02:01,512 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:02:01,512 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:02:01,512 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:02:01,512 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da lahani ko kuma ya ceci rai na haƙuri , Allah zai “ kawar ” mugayen mutane masu kirki da za su more rayuwa a duniya .\n",
            "2021-05-04 16:02:01,512 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:02:01,512 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:02:01,512 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:02:01,512 - INFO - joeynmt.training - \tHypothesis: Sun shaida salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:02:01,512 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:02:01,513 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:02:01,513 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:02:01,513 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:02:01,513 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    26000: bleu:  26.31, loss: 42125.4688, ppl:   5.3347, duration: 11.3020s\n",
            "2021-05-04 16:02:11,422 - INFO - joeynmt.training - Epoch  11, Step:    26100, Batch Loss:     1.529627, Tokens per Sec:    21367, Lr: 0.000300\n",
            "2021-05-04 16:02:21,300 - INFO - joeynmt.training - Epoch  11, Step:    26200, Batch Loss:     2.790512, Tokens per Sec:    21841, Lr: 0.000300\n",
            "2021-05-04 16:02:31,322 - INFO - joeynmt.training - Epoch  11, Step:    26300, Batch Loss:     1.617825, Tokens per Sec:    21429, Lr: 0.000300\n",
            "2021-05-04 16:02:41,171 - INFO - joeynmt.training - Epoch  11, Step:    26400, Batch Loss:     1.999793, Tokens per Sec:    21616, Lr: 0.000300\n",
            "2021-05-04 16:02:51,066 - INFO - joeynmt.training - Epoch  11, Step:    26500, Batch Loss:     1.449824, Tokens per Sec:    21636, Lr: 0.000300\n",
            "2021-05-04 16:03:01,005 - INFO - joeynmt.training - Epoch  11, Step:    26600, Batch Loss:     1.341604, Tokens per Sec:    21408, Lr: 0.000300\n",
            "2021-05-04 16:03:11,090 - INFO - joeynmt.training - Epoch  11, Step:    26700, Batch Loss:     1.976137, Tokens per Sec:    22186, Lr: 0.000300\n",
            "2021-05-04 16:03:21,016 - INFO - joeynmt.training - Epoch  11, Step:    26800, Batch Loss:     2.030224, Tokens per Sec:    21577, Lr: 0.000300\n",
            "2021-05-04 16:03:30,974 - INFO - joeynmt.training - Epoch  11, Step:    26900, Batch Loss:     2.000749, Tokens per Sec:    21409, Lr: 0.000300\n",
            "2021-05-04 16:03:41,009 - INFO - joeynmt.training - Epoch  11, Step:    27000, Batch Loss:     1.527549, Tokens per Sec:    21379, Lr: 0.000300\n",
            "2021-05-04 16:03:51,821 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:03:51,821 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:03:51,822 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:03:52,074 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:03:52,074 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:03:52,431 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:03:52,432 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:03:52,432 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:03:52,432 - INFO - joeynmt.training - \tHypothesis: Iyali tana da kyau kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:03:52,432 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:03:52,432 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:03:52,432 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:03:52,432 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya cire ransa ko kuma ya ceci rai , Allah zai “ rufe ” mugayen mutane masu kirki da za su more rayuwa a duniya .\n",
            "2021-05-04 16:03:52,432 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:03:52,432 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:03:52,432 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:03:52,432 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:03:52,432 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:03:52,433 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:03:52,433 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:03:52,433 - INFO - joeynmt.training - \tHypothesis: * A dukan duniya zan yi masa biyayya . ”\n",
            "2021-05-04 16:03:52,433 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    27000: bleu:  26.01, loss: 41617.2227, ppl:   5.2280, duration: 11.4232s\n",
            "2021-05-04 16:04:02,322 - INFO - joeynmt.training - Epoch  11, Step:    27100, Batch Loss:     1.881864, Tokens per Sec:    21566, Lr: 0.000300\n",
            "2021-05-04 16:04:12,405 - INFO - joeynmt.training - Epoch  11, Step:    27200, Batch Loss:     1.895695, Tokens per Sec:    22160, Lr: 0.000300\n",
            "2021-05-04 16:04:22,330 - INFO - joeynmt.training - Epoch  11, Step:    27300, Batch Loss:     1.875539, Tokens per Sec:    21395, Lr: 0.000300\n",
            "2021-05-04 16:04:32,273 - INFO - joeynmt.training - Epoch  11, Step:    27400, Batch Loss:     2.073608, Tokens per Sec:    22090, Lr: 0.000300\n",
            "2021-05-04 16:04:39,756 - INFO - joeynmt.training - Epoch  11: total training loss 4677.29\n",
            "2021-05-04 16:04:39,756 - INFO - joeynmt.training - EPOCH 12\n",
            "2021-05-04 16:04:42,520 - INFO - joeynmt.training - Epoch  12, Step:    27500, Batch Loss:     2.117628, Tokens per Sec:    19504, Lr: 0.000300\n",
            "2021-05-04 16:04:52,280 - INFO - joeynmt.training - Epoch  12, Step:    27600, Batch Loss:     1.679453, Tokens per Sec:    20719, Lr: 0.000300\n",
            "2021-05-04 16:05:02,125 - INFO - joeynmt.training - Epoch  12, Step:    27700, Batch Loss:     1.537197, Tokens per Sec:    21515, Lr: 0.000300\n",
            "2021-05-04 16:05:11,977 - INFO - joeynmt.training - Epoch  12, Step:    27800, Batch Loss:     1.874943, Tokens per Sec:    21326, Lr: 0.000300\n",
            "2021-05-04 16:05:21,951 - INFO - joeynmt.training - Epoch  12, Step:    27900, Batch Loss:     2.060803, Tokens per Sec:    21805, Lr: 0.000300\n",
            "2021-05-04 16:05:31,890 - INFO - joeynmt.training - Epoch  12, Step:    28000, Batch Loss:     1.938463, Tokens per Sec:    21518, Lr: 0.000300\n",
            "2021-05-04 16:05:41,862 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:05:41,862 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:05:41,862 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:05:42,471 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:05:42,472 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:05:42,472 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:05:42,472 - INFO - joeynmt.training - \tHypothesis: Iyali tana da kyau kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:05:42,472 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:05:42,472 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:05:42,473 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:05:42,473 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da rayuwa mai ma’ana ko kuma ceton rai , Allah zai “ kawar ” miyagu don mutane masu kirki za su more rayuwa a duniya .\n",
            "2021-05-04 16:05:42,473 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:05:42,473 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:05:42,473 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:05:42,473 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:05:42,473 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:05:42,473 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:05:42,473 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:05:42,473 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a bisansa . ”\n",
            "2021-05-04 16:05:42,474 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    28000: bleu:  26.30, loss: 41695.3477, ppl:   5.2443, duration: 10.5836s\n",
            "2021-05-04 16:05:52,423 - INFO - joeynmt.training - Epoch  12, Step:    28100, Batch Loss:     1.691797, Tokens per Sec:    21464, Lr: 0.000300\n",
            "2021-05-04 16:06:02,303 - INFO - joeynmt.training - Epoch  12, Step:    28200, Batch Loss:     1.877126, Tokens per Sec:    21525, Lr: 0.000300\n",
            "2021-05-04 16:06:12,259 - INFO - joeynmt.training - Epoch  12, Step:    28300, Batch Loss:     2.087367, Tokens per Sec:    21840, Lr: 0.000300\n",
            "2021-05-04 16:06:22,158 - INFO - joeynmt.training - Epoch  12, Step:    28400, Batch Loss:     1.553289, Tokens per Sec:    21844, Lr: 0.000300\n",
            "2021-05-04 16:06:32,041 - INFO - joeynmt.training - Epoch  12, Step:    28500, Batch Loss:     1.989691, Tokens per Sec:    21621, Lr: 0.000300\n",
            "2021-05-04 16:06:42,073 - INFO - joeynmt.training - Epoch  12, Step:    28600, Batch Loss:     2.023407, Tokens per Sec:    21780, Lr: 0.000300\n",
            "2021-05-04 16:06:52,074 - INFO - joeynmt.training - Epoch  12, Step:    28700, Batch Loss:     1.635228, Tokens per Sec:    21904, Lr: 0.000300\n",
            "2021-05-04 16:07:02,075 - INFO - joeynmt.training - Epoch  12, Step:    28800, Batch Loss:     1.902021, Tokens per Sec:    21766, Lr: 0.000300\n",
            "2021-05-04 16:07:11,908 - INFO - joeynmt.training - Epoch  12, Step:    28900, Batch Loss:     1.545189, Tokens per Sec:    21619, Lr: 0.000300\n",
            "2021-05-04 16:07:21,927 - INFO - joeynmt.training - Epoch  12, Step:    29000, Batch Loss:     1.955046, Tokens per Sec:    21743, Lr: 0.000300\n",
            "2021-05-04 16:07:33,871 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:07:33,871 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:07:33,871 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:07:34,117 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:07:34,117 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:07:34,540 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:07:34,540 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:07:34,540 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:07:34,541 - INFO - joeynmt.training - \tHypothesis: Iyali tana da kyau kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:07:34,541 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:07:34,541 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:07:34,541 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:07:34,541 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da wannan dabba ko kuma ya ceci rai na haƙuri , Allah zai “ kawar ” mugayen mutane masu kirki da za su more rayuwa a duniya .\n",
            "2021-05-04 16:07:34,541 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:07:34,541 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:07:34,541 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:07:34,541 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:07:34,541 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:07:34,542 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:07:34,542 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:07:34,542 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan duniya , zan yi masa biyayya . ”\n",
            "2021-05-04 16:07:34,542 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    29000: bleu:  26.48, loss: 41050.9531, ppl:   5.1117, duration: 12.6145s\n",
            "2021-05-04 16:07:44,466 - INFO - joeynmt.training - Epoch  12, Step:    29100, Batch Loss:     1.587650, Tokens per Sec:    20851, Lr: 0.000300\n",
            "2021-05-04 16:07:54,495 - INFO - joeynmt.training - Epoch  12, Step:    29200, Batch Loss:     1.691222, Tokens per Sec:    22048, Lr: 0.000300\n",
            "2021-05-04 16:08:04,485 - INFO - joeynmt.training - Epoch  12, Step:    29300, Batch Loss:     1.654082, Tokens per Sec:    21457, Lr: 0.000300\n",
            "2021-05-04 16:08:14,458 - INFO - joeynmt.training - Epoch  12, Step:    29400, Batch Loss:     1.937521, Tokens per Sec:    21854, Lr: 0.000300\n",
            "2021-05-04 16:08:24,352 - INFO - joeynmt.training - Epoch  12, Step:    29500, Batch Loss:     1.952367, Tokens per Sec:    21698, Lr: 0.000300\n",
            "2021-05-04 16:08:34,244 - INFO - joeynmt.training - Epoch  12, Step:    29600, Batch Loss:     1.946966, Tokens per Sec:    21431, Lr: 0.000300\n",
            "2021-05-04 16:08:44,228 - INFO - joeynmt.training - Epoch  12, Step:    29700, Batch Loss:     2.054073, Tokens per Sec:    21520, Lr: 0.000300\n",
            "2021-05-04 16:08:54,203 - INFO - joeynmt.training - Epoch  12, Step:    29800, Batch Loss:     2.132208, Tokens per Sec:    21674, Lr: 0.000300\n",
            "2021-05-04 16:09:04,190 - INFO - joeynmt.training - Epoch  12, Step:    29900, Batch Loss:     1.632016, Tokens per Sec:    22091, Lr: 0.000300\n",
            "2021-05-04 16:09:11,145 - INFO - joeynmt.training - Epoch  12: total training loss 4605.11\n",
            "2021-05-04 16:09:11,145 - INFO - joeynmt.training - EPOCH 13\n",
            "2021-05-04 16:09:14,419 - INFO - joeynmt.training - Epoch  13, Step:    30000, Batch Loss:     1.684104, Tokens per Sec:    20044, Lr: 0.000300\n",
            "2021-05-04 16:09:25,985 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:09:25,985 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:09:25,985 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:09:26,238 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:09:26,239 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:09:26,602 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:09:26,602 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:09:26,602 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:09:26,602 - INFO - joeynmt.training - \tHypothesis: Iyali tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:09:26,602 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:09:26,602 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:09:26,602 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:09:26,603 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da haɗarin rayuwa da haƙuri , Allah zai “ datse ” saboda miyagu masu kyau da za su more rayuwa a duniya .\n",
            "2021-05-04 16:09:26,603 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:09:26,603 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:09:26,603 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:09:26,603 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:09:26,603 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:09:26,603 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:09:26,603 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:09:26,603 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:09:26,603 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    30000: bleu:  26.90, loss: 40887.8203, ppl:   5.0787, duration: 12.1839s\n",
            "2021-05-04 16:09:36,444 - INFO - joeynmt.training - Epoch  13, Step:    30100, Batch Loss:     1.729154, Tokens per Sec:    21319, Lr: 0.000300\n",
            "2021-05-04 16:09:46,382 - INFO - joeynmt.training - Epoch  13, Step:    30200, Batch Loss:     1.991434, Tokens per Sec:    21799, Lr: 0.000300\n",
            "2021-05-04 16:09:56,288 - INFO - joeynmt.training - Epoch  13, Step:    30300, Batch Loss:     1.964409, Tokens per Sec:    21706, Lr: 0.000300\n",
            "2021-05-04 16:10:06,377 - INFO - joeynmt.training - Epoch  13, Step:    30400, Batch Loss:     1.755393, Tokens per Sec:    22220, Lr: 0.000300\n",
            "2021-05-04 16:10:16,279 - INFO - joeynmt.training - Epoch  13, Step:    30500, Batch Loss:     1.514147, Tokens per Sec:    21446, Lr: 0.000300\n",
            "2021-05-04 16:10:26,143 - INFO - joeynmt.training - Epoch  13, Step:    30600, Batch Loss:     2.062849, Tokens per Sec:    21540, Lr: 0.000300\n",
            "2021-05-04 16:10:36,011 - INFO - joeynmt.training - Epoch  13, Step:    30700, Batch Loss:     2.063288, Tokens per Sec:    21463, Lr: 0.000300\n",
            "2021-05-04 16:10:45,918 - INFO - joeynmt.training - Epoch  13, Step:    30800, Batch Loss:     1.863227, Tokens per Sec:    21439, Lr: 0.000300\n",
            "2021-05-04 16:10:55,881 - INFO - joeynmt.training - Epoch  13, Step:    30900, Batch Loss:     1.851488, Tokens per Sec:    21402, Lr: 0.000300\n",
            "2021-05-04 16:11:05,730 - INFO - joeynmt.training - Epoch  13, Step:    31000, Batch Loss:     1.820991, Tokens per Sec:    21618, Lr: 0.000300\n",
            "2021-05-04 16:11:16,851 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:11:16,851 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:11:16,851 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:11:17,101 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:11:17,102 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:11:17,488 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:11:17,489 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:11:17,489 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:11:17,489 - INFO - joeynmt.training - \tHypothesis: Iyali tana da kyau kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:11:17,489 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:11:17,489 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:11:17,489 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:11:17,489 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da lahani ko kuma a ceci rai na haƙuri , Allah zai “ datse ” saboda miyagun mutane masu kirki da gaske za su more rayuwa a duniya .\n",
            "2021-05-04 16:11:17,489 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:11:17,489 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:11:17,489 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:11:17,489 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:11:17,489 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:11:17,490 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:11:17,490 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:11:17,490 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:11:17,490 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    31000: bleu:  26.70, loss: 40622.0352, ppl:   5.0253, duration: 11.7598s\n",
            "2021-05-04 16:11:27,332 - INFO - joeynmt.training - Epoch  13, Step:    31100, Batch Loss:     1.792526, Tokens per Sec:    21697, Lr: 0.000300\n",
            "2021-05-04 16:11:37,228 - INFO - joeynmt.training - Epoch  13, Step:    31200, Batch Loss:     1.806828, Tokens per Sec:    21825, Lr: 0.000300\n",
            "2021-05-04 16:11:46,942 - INFO - joeynmt.training - Epoch  13, Step:    31300, Batch Loss:     1.766774, Tokens per Sec:    21349, Lr: 0.000300\n",
            "2021-05-04 16:11:56,856 - INFO - joeynmt.training - Epoch  13, Step:    31400, Batch Loss:     1.864583, Tokens per Sec:    21395, Lr: 0.000300\n",
            "2021-05-04 16:12:06,784 - INFO - joeynmt.training - Epoch  13, Step:    31500, Batch Loss:     1.568767, Tokens per Sec:    22129, Lr: 0.000300\n",
            "2021-05-04 16:12:16,700 - INFO - joeynmt.training - Epoch  13, Step:    31600, Batch Loss:     2.063701, Tokens per Sec:    21870, Lr: 0.000300\n",
            "2021-05-04 16:12:26,668 - INFO - joeynmt.training - Epoch  13, Step:    31700, Batch Loss:     1.741797, Tokens per Sec:    21588, Lr: 0.000300\n",
            "2021-05-04 16:12:36,647 - INFO - joeynmt.training - Epoch  13, Step:    31800, Batch Loss:     2.283075, Tokens per Sec:    21597, Lr: 0.000300\n",
            "2021-05-04 16:12:46,515 - INFO - joeynmt.training - Epoch  13, Step:    31900, Batch Loss:     1.851554, Tokens per Sec:    21616, Lr: 0.000300\n",
            "2021-05-04 16:12:56,502 - INFO - joeynmt.training - Epoch  13, Step:    32000, Batch Loss:     2.090498, Tokens per Sec:    21704, Lr: 0.000300\n",
            "2021-05-04 16:13:07,308 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:13:07,308 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:13:07,308 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:13:07,563 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:13:07,563 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:13:07,944 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:13:07,944 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:13:07,944 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:13:07,944 - INFO - joeynmt.training - \tHypothesis: Iyali tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:13:07,944 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:13:07,945 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:13:07,945 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:13:07,945 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da haɗarin rayuwa ko kuma ya ceci rai na haƙuri , Allah zai “ kawar ” mugayen mutane masu kirki don su more rayuwa a duniya .\n",
            "2021-05-04 16:13:07,945 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:13:07,945 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:13:07,945 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:13:07,945 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:13:07,945 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:13:07,945 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:13:07,945 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:13:07,945 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:13:07,945 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    32000: bleu:  27.56, loss: 40448.9922, ppl:   4.9909, duration: 11.4432s\n",
            "2021-05-04 16:13:17,850 - INFO - joeynmt.training - Epoch  13, Step:    32100, Batch Loss:     1.726259, Tokens per Sec:    21897, Lr: 0.000300\n",
            "2021-05-04 16:13:27,692 - INFO - joeynmt.training - Epoch  13, Step:    32200, Batch Loss:     2.228115, Tokens per Sec:    21404, Lr: 0.000300\n",
            "2021-05-04 16:13:37,726 - INFO - joeynmt.training - Epoch  13, Step:    32300, Batch Loss:     1.994442, Tokens per Sec:    21301, Lr: 0.000300\n",
            "2021-05-04 16:13:47,598 - INFO - joeynmt.training - Epoch  13, Step:    32400, Batch Loss:     1.743020, Tokens per Sec:    21586, Lr: 0.000300\n",
            "2021-05-04 16:13:54,623 - INFO - joeynmt.training - Epoch  13: total training loss 4546.44\n",
            "2021-05-04 16:13:54,623 - INFO - joeynmt.training - EPOCH 14\n",
            "2021-05-04 16:13:57,787 - INFO - joeynmt.training - Epoch  14, Step:    32500, Batch Loss:     1.825763, Tokens per Sec:    20703, Lr: 0.000300\n",
            "2021-05-04 16:14:07,707 - INFO - joeynmt.training - Epoch  14, Step:    32600, Batch Loss:     1.985405, Tokens per Sec:    21189, Lr: 0.000300\n",
            "2021-05-04 16:14:17,634 - INFO - joeynmt.training - Epoch  14, Step:    32700, Batch Loss:     2.463704, Tokens per Sec:    21577, Lr: 0.000300\n",
            "2021-05-04 16:14:27,573 - INFO - joeynmt.training - Epoch  14, Step:    32800, Batch Loss:     1.841434, Tokens per Sec:    21700, Lr: 0.000300\n",
            "2021-05-04 16:14:37,583 - INFO - joeynmt.training - Epoch  14, Step:    32900, Batch Loss:     1.919929, Tokens per Sec:    22032, Lr: 0.000300\n",
            "2021-05-04 16:14:47,525 - INFO - joeynmt.training - Epoch  14, Step:    33000, Batch Loss:     1.686941, Tokens per Sec:    21519, Lr: 0.000300\n",
            "2021-05-04 16:14:59,741 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:14:59,741 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:14:59,741 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:14:59,988 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:14:59,989 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:15:00,378 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:15:00,378 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:15:00,378 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:15:00,378 - INFO - joeynmt.training - \tHypothesis: Iyali tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:15:00,378 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:15:00,378 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:15:00,378 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:15:00,378 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da lahani ko kuma a ceci rai na haƙuri , Allah zai “ datse ” mugayen mutane masu kirki don su more rayuwa a duniya .\n",
            "2021-05-04 16:15:00,379 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:15:00,379 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:15:00,379 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:15:00,379 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:15:00,379 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:15:00,379 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:15:00,379 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:15:00,379 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:15:00,380 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    33000: bleu:  27.07, loss: 40200.3320, ppl:   4.9418, duration: 12.8541s\n",
            "2021-05-04 16:15:10,137 - INFO - joeynmt.training - Epoch  14, Step:    33100, Batch Loss:     1.766221, Tokens per Sec:    21653, Lr: 0.000300\n",
            "2021-05-04 16:15:20,170 - INFO - joeynmt.training - Epoch  14, Step:    33200, Batch Loss:     1.495773, Tokens per Sec:    21489, Lr: 0.000300\n",
            "2021-05-04 16:15:29,973 - INFO - joeynmt.training - Epoch  14, Step:    33300, Batch Loss:     1.814197, Tokens per Sec:    21590, Lr: 0.000300\n",
            "2021-05-04 16:15:39,763 - INFO - joeynmt.training - Epoch  14, Step:    33400, Batch Loss:     1.858214, Tokens per Sec:    20983, Lr: 0.000300\n",
            "2021-05-04 16:15:49,741 - INFO - joeynmt.training - Epoch  14, Step:    33500, Batch Loss:     1.943235, Tokens per Sec:    21861, Lr: 0.000300\n",
            "2021-05-04 16:15:59,634 - INFO - joeynmt.training - Epoch  14, Step:    33600, Batch Loss:     1.663784, Tokens per Sec:    21553, Lr: 0.000300\n",
            "2021-05-04 16:16:09,504 - INFO - joeynmt.training - Epoch  14, Step:    33700, Batch Loss:     1.826861, Tokens per Sec:    21706, Lr: 0.000300\n",
            "2021-05-04 16:16:19,394 - INFO - joeynmt.training - Epoch  14, Step:    33800, Batch Loss:     1.670701, Tokens per Sec:    21432, Lr: 0.000300\n",
            "2021-05-04 16:16:29,269 - INFO - joeynmt.training - Epoch  14, Step:    33900, Batch Loss:     2.015603, Tokens per Sec:    21807, Lr: 0.000300\n",
            "2021-05-04 16:16:39,169 - INFO - joeynmt.training - Epoch  14, Step:    34000, Batch Loss:     1.414882, Tokens per Sec:    21841, Lr: 0.000300\n",
            "2021-05-04 16:16:50,427 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:16:50,427 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:16:50,427 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:16:50,688 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:16:50,688 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:16:51,080 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:16:51,080 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:16:51,080 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:16:51,080 - INFO - joeynmt.training - \tHypothesis: Iyali tana da kyau kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:16:51,080 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:16:51,081 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:16:51,081 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:16:51,081 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da abin da zai sa mutum ya tsira daga rayuwa mai haƙuri , Allah zai “ datse ” saboda miyagu masu kyau da mutane za su more rayuwa a duniya .\n",
            "2021-05-04 16:16:51,081 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:16:51,081 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:16:51,081 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:16:51,081 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:16:51,081 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:16:51,081 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:16:51,081 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:16:51,081 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:16:51,082 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    34000: bleu:  27.95, loss: 39970.6562, ppl:   4.8969, duration: 11.9122s\n",
            "2021-05-04 16:17:01,027 - INFO - joeynmt.training - Epoch  14, Step:    34100, Batch Loss:     1.912466, Tokens per Sec:    21464, Lr: 0.000300\n",
            "2021-05-04 16:17:11,054 - INFO - joeynmt.training - Epoch  14, Step:    34200, Batch Loss:     1.511829, Tokens per Sec:    21710, Lr: 0.000300\n",
            "2021-05-04 16:17:20,942 - INFO - joeynmt.training - Epoch  14, Step:    34300, Batch Loss:     1.745403, Tokens per Sec:    21815, Lr: 0.000300\n",
            "2021-05-04 16:17:30,908 - INFO - joeynmt.training - Epoch  14, Step:    34400, Batch Loss:     1.708656, Tokens per Sec:    21913, Lr: 0.000300\n",
            "2021-05-04 16:17:40,841 - INFO - joeynmt.training - Epoch  14, Step:    34500, Batch Loss:     1.966371, Tokens per Sec:    21620, Lr: 0.000300\n",
            "2021-05-04 16:17:50,784 - INFO - joeynmt.training - Epoch  14, Step:    34600, Batch Loss:     1.722321, Tokens per Sec:    21568, Lr: 0.000300\n",
            "2021-05-04 16:18:00,686 - INFO - joeynmt.training - Epoch  14, Step:    34700, Batch Loss:     1.598999, Tokens per Sec:    20901, Lr: 0.000300\n",
            "2021-05-04 16:18:10,730 - INFO - joeynmt.training - Epoch  14, Step:    34800, Batch Loss:     1.907256, Tokens per Sec:    21966, Lr: 0.000300\n",
            "2021-05-04 16:18:20,619 - INFO - joeynmt.training - Epoch  14, Step:    34900, Batch Loss:     1.621302, Tokens per Sec:    21203, Lr: 0.000300\n",
            "2021-05-04 16:18:27,842 - INFO - joeynmt.training - Epoch  14: total training loss 4481.04\n",
            "2021-05-04 16:18:27,843 - INFO - joeynmt.training - EPOCH 15\n",
            "2021-05-04 16:18:30,862 - INFO - joeynmt.training - Epoch  15, Step:    35000, Batch Loss:     1.827920, Tokens per Sec:    20279, Lr: 0.000300\n",
            "2021-05-04 16:18:41,241 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:18:41,241 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:18:41,241 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:18:41,507 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:18:41,507 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:18:41,873 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:18:41,874 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:18:41,874 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:18:41,874 - INFO - joeynmt.training - \tHypothesis: A gida gida yana da kyau kuma yana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:18:41,874 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:18:41,874 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:18:41,874 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:18:41,874 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da haɗarin da zai sa mutum ya tsira daga rayuwa mai haƙuri , Allah zai “ datse ” mugayen mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 16:18:41,874 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:18:41,875 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:18:41,875 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:18:41,875 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:18:41,875 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:18:41,875 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:18:41,875 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:18:41,875 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:18:41,875 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    35000: bleu:  27.57, loss: 39745.0625, ppl:   4.8532, duration: 11.0127s\n",
            "2021-05-04 16:18:51,840 - INFO - joeynmt.training - Epoch  15, Step:    35100, Batch Loss:     1.508126, Tokens per Sec:    21562, Lr: 0.000300\n",
            "2021-05-04 16:19:01,802 - INFO - joeynmt.training - Epoch  15, Step:    35200, Batch Loss:     1.961915, Tokens per Sec:    21442, Lr: 0.000300\n",
            "2021-05-04 16:19:11,710 - INFO - joeynmt.training - Epoch  15, Step:    35300, Batch Loss:     1.724428, Tokens per Sec:    21672, Lr: 0.000300\n",
            "2021-05-04 16:19:21,668 - INFO - joeynmt.training - Epoch  15, Step:    35400, Batch Loss:     1.714865, Tokens per Sec:    21637, Lr: 0.000300\n",
            "2021-05-04 16:19:31,497 - INFO - joeynmt.training - Epoch  15, Step:    35500, Batch Loss:     1.935175, Tokens per Sec:    21321, Lr: 0.000300\n",
            "2021-05-04 16:19:41,526 - INFO - joeynmt.training - Epoch  15, Step:    35600, Batch Loss:     2.158331, Tokens per Sec:    22069, Lr: 0.000300\n",
            "2021-05-04 16:19:51,480 - INFO - joeynmt.training - Epoch  15, Step:    35700, Batch Loss:     1.576079, Tokens per Sec:    21885, Lr: 0.000300\n",
            "2021-05-04 16:20:01,438 - INFO - joeynmt.training - Epoch  15, Step:    35800, Batch Loss:     2.004291, Tokens per Sec:    22038, Lr: 0.000300\n",
            "2021-05-04 16:20:11,465 - INFO - joeynmt.training - Epoch  15, Step:    35900, Batch Loss:     1.809662, Tokens per Sec:    21639, Lr: 0.000300\n",
            "2021-05-04 16:20:21,338 - INFO - joeynmt.training - Epoch  15, Step:    36000, Batch Loss:     1.836302, Tokens per Sec:    21807, Lr: 0.000300\n",
            "2021-05-04 16:20:33,042 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:20:33,043 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:20:33,043 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:20:33,297 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:20:33,297 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:20:33,722 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:20:33,722 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:20:33,722 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:20:33,722 - INFO - joeynmt.training - \tHypothesis: Iyali tana da kyau kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:20:33,722 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:20:33,722 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:20:33,722 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:20:33,722 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da abin da zai iya sa mutum ya tsira daga rayuwa mai haƙuri , Allah zai “ kawar ” mugayen mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 16:20:33,722 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:20:33,723 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:20:33,723 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:20:33,723 - INFO - joeynmt.training - \tHypothesis: Sun sami kwanciyar hankali a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:20:33,723 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:20:33,723 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:20:33,723 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:20:33,723 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:20:33,723 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    36000: bleu:  27.52, loss: 39569.2305, ppl:   4.8194, duration: 12.3850s\n",
            "2021-05-04 16:20:43,698 - INFO - joeynmt.training - Epoch  15, Step:    36100, Batch Loss:     1.661433, Tokens per Sec:    21757, Lr: 0.000300\n",
            "2021-05-04 16:20:53,593 - INFO - joeynmt.training - Epoch  15, Step:    36200, Batch Loss:     1.839261, Tokens per Sec:    21626, Lr: 0.000300\n",
            "2021-05-04 16:21:03,484 - INFO - joeynmt.training - Epoch  15, Step:    36300, Batch Loss:     1.736275, Tokens per Sec:    21635, Lr: 0.000300\n",
            "2021-05-04 16:21:13,337 - INFO - joeynmt.training - Epoch  15, Step:    36400, Batch Loss:     1.833633, Tokens per Sec:    21763, Lr: 0.000300\n",
            "2021-05-04 16:21:23,316 - INFO - joeynmt.training - Epoch  15, Step:    36500, Batch Loss:     1.693671, Tokens per Sec:    21707, Lr: 0.000300\n",
            "2021-05-04 16:21:33,193 - INFO - joeynmt.training - Epoch  15, Step:    36600, Batch Loss:     2.140065, Tokens per Sec:    21484, Lr: 0.000300\n",
            "2021-05-04 16:21:43,061 - INFO - joeynmt.training - Epoch  15, Step:    36700, Batch Loss:     1.510070, Tokens per Sec:    21726, Lr: 0.000300\n",
            "2021-05-04 16:21:53,026 - INFO - joeynmt.training - Epoch  15, Step:    36800, Batch Loss:     1.922113, Tokens per Sec:    21609, Lr: 0.000300\n",
            "2021-05-04 16:22:02,941 - INFO - joeynmt.training - Epoch  15, Step:    36900, Batch Loss:     1.869678, Tokens per Sec:    21346, Lr: 0.000300\n",
            "2021-05-04 16:22:12,778 - INFO - joeynmt.training - Epoch  15, Step:    37000, Batch Loss:     1.890508, Tokens per Sec:    21660, Lr: 0.000300\n",
            "2021-05-04 16:22:24,289 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:22:24,289 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:22:24,289 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:22:24,534 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:22:24,534 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:22:24,881 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:22:24,881 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:22:24,881 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:22:24,881 - INFO - joeynmt.training - \tHypothesis: Iyalinmu yana da kyau kuma yana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:22:24,881 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:22:24,881 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:22:24,881 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:22:24,881 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da lahani ko kuma ya ceci rai na haƙuri , Allah zai “ kawar ” mugayen mutane masu kirki don mutane su more rayuwa a duniya .\n",
            "2021-05-04 16:22:24,882 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:22:24,882 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:22:24,882 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:22:24,882 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:22:24,882 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:22:24,882 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:22:24,882 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:22:24,882 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan duniya zan yi tsaro a kansa . ”\n",
            "2021-05-04 16:22:24,882 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    37000: bleu:  28.09, loss: 39473.6289, ppl:   4.8011, duration: 12.1043s\n",
            "2021-05-04 16:22:34,764 - INFO - joeynmt.training - Epoch  15, Step:    37100, Batch Loss:     1.572598, Tokens per Sec:    21522, Lr: 0.000300\n",
            "2021-05-04 16:22:44,632 - INFO - joeynmt.training - Epoch  15, Step:    37200, Batch Loss:     1.674066, Tokens per Sec:    21593, Lr: 0.000300\n",
            "2021-05-04 16:22:54,500 - INFO - joeynmt.training - Epoch  15, Step:    37300, Batch Loss:     1.543402, Tokens per Sec:    21439, Lr: 0.000300\n",
            "2021-05-04 16:23:04,416 - INFO - joeynmt.training - Epoch  15, Step:    37400, Batch Loss:     1.425480, Tokens per Sec:    21578, Lr: 0.000300\n",
            "2021-05-04 16:23:10,966 - INFO - joeynmt.training - Epoch  15: total training loss 4409.84\n",
            "2021-05-04 16:23:10,966 - INFO - joeynmt.training - EPOCH 16\n",
            "2021-05-04 16:23:14,532 - INFO - joeynmt.training - Epoch  16, Step:    37500, Batch Loss:     1.662908, Tokens per Sec:    19592, Lr: 0.000300\n",
            "2021-05-04 16:23:24,416 - INFO - joeynmt.training - Epoch  16, Step:    37600, Batch Loss:     1.823063, Tokens per Sec:    21791, Lr: 0.000300\n",
            "2021-05-04 16:23:34,291 - INFO - joeynmt.training - Epoch  16, Step:    37700, Batch Loss:     1.463978, Tokens per Sec:    21643, Lr: 0.000300\n",
            "2021-05-04 16:23:44,099 - INFO - joeynmt.training - Epoch  16, Step:    37800, Batch Loss:     2.015748, Tokens per Sec:    22022, Lr: 0.000300\n",
            "2021-05-04 16:23:53,828 - INFO - joeynmt.training - Epoch  16, Step:    37900, Batch Loss:     1.883674, Tokens per Sec:    21648, Lr: 0.000300\n",
            "2021-05-04 16:24:03,820 - INFO - joeynmt.training - Epoch  16, Step:    38000, Batch Loss:     1.661737, Tokens per Sec:    21950, Lr: 0.000300\n",
            "2021-05-04 16:24:15,008 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:24:15,008 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:24:15,008 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:24:15,290 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:24:15,290 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:24:15,740 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:24:15,740 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:24:15,740 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:24:15,740 - INFO - joeynmt.training - \tHypothesis: Iyali tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:24:15,740 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:24:15,740 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:24:15,741 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:24:15,741 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da wannan dabarar ko kuma a ceci rai na haƙuri , Allah zai “ kawar ” mugayen mutane don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 16:24:15,741 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:24:15,741 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:24:15,741 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:24:15,741 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:24:15,741 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:24:15,741 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:24:15,741 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:24:15,741 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:24:15,741 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    38000: bleu:  27.91, loss: 39278.5000, ppl:   4.7640, duration: 11.9208s\n",
            "2021-05-04 16:24:25,686 - INFO - joeynmt.training - Epoch  16, Step:    38100, Batch Loss:     1.482840, Tokens per Sec:    21549, Lr: 0.000300\n",
            "2021-05-04 16:24:35,508 - INFO - joeynmt.training - Epoch  16, Step:    38200, Batch Loss:     1.646836, Tokens per Sec:    21660, Lr: 0.000300\n",
            "2021-05-04 16:24:45,533 - INFO - joeynmt.training - Epoch  16, Step:    38300, Batch Loss:     1.767278, Tokens per Sec:    22249, Lr: 0.000300\n",
            "2021-05-04 16:24:55,464 - INFO - joeynmt.training - Epoch  16, Step:    38400, Batch Loss:     2.000640, Tokens per Sec:    21546, Lr: 0.000300\n",
            "2021-05-04 16:25:05,295 - INFO - joeynmt.training - Epoch  16, Step:    38500, Batch Loss:     1.781948, Tokens per Sec:    21319, Lr: 0.000300\n",
            "2021-05-04 16:25:15,137 - INFO - joeynmt.training - Epoch  16, Step:    38600, Batch Loss:     1.491624, Tokens per Sec:    21625, Lr: 0.000300\n",
            "2021-05-04 16:25:25,110 - INFO - joeynmt.training - Epoch  16, Step:    38700, Batch Loss:     1.943022, Tokens per Sec:    22409, Lr: 0.000300\n",
            "2021-05-04 16:25:34,943 - INFO - joeynmt.training - Epoch  16, Step:    38800, Batch Loss:     2.113335, Tokens per Sec:    21544, Lr: 0.000300\n",
            "2021-05-04 16:25:44,759 - INFO - joeynmt.training - Epoch  16, Step:    38900, Batch Loss:     2.014447, Tokens per Sec:    21778, Lr: 0.000300\n",
            "2021-05-04 16:25:54,619 - INFO - joeynmt.training - Epoch  16, Step:    39000, Batch Loss:     1.995669, Tokens per Sec:    22040, Lr: 0.000300\n",
            "2021-05-04 16:26:05,752 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:26:05,753 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:26:05,753 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:26:06,354 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:26:06,355 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:26:06,355 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:26:06,355 - INFO - joeynmt.training - \tHypothesis: Iyali tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:26:06,355 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:26:06,355 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:26:06,355 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:26:06,355 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da lahani ko kuma a ceci rai na haƙuri , Allah zai “ datse ” mugayen mutane masu kirki don su more rayuwa a duniya .\n",
            "2021-05-04 16:26:06,355 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:26:06,355 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:26:06,355 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:26:06,355 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:26:06,355 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:26:06,356 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:26:06,356 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:26:06,356 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:26:06,356 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    39000: bleu:  27.57, loss: 39304.0547, ppl:   4.7688, duration: 11.7360s\n",
            "2021-05-04 16:26:16,214 - INFO - joeynmt.training - Epoch  16, Step:    39100, Batch Loss:     1.824054, Tokens per Sec:    21913, Lr: 0.000300\n",
            "2021-05-04 16:26:26,091 - INFO - joeynmt.training - Epoch  16, Step:    39200, Batch Loss:     1.981394, Tokens per Sec:    21603, Lr: 0.000300\n",
            "2021-05-04 16:26:35,904 - INFO - joeynmt.training - Epoch  16, Step:    39300, Batch Loss:     2.254913, Tokens per Sec:    21982, Lr: 0.000300\n",
            "2021-05-04 16:26:45,801 - INFO - joeynmt.training - Epoch  16, Step:    39400, Batch Loss:     1.761566, Tokens per Sec:    21429, Lr: 0.000300\n",
            "2021-05-04 16:26:55,652 - INFO - joeynmt.training - Epoch  16, Step:    39500, Batch Loss:     1.638094, Tokens per Sec:    22266, Lr: 0.000300\n",
            "2021-05-04 16:27:05,462 - INFO - joeynmt.training - Epoch  16, Step:    39600, Batch Loss:     1.702401, Tokens per Sec:    21739, Lr: 0.000300\n",
            "2021-05-04 16:27:15,255 - INFO - joeynmt.training - Epoch  16, Step:    39700, Batch Loss:     1.710731, Tokens per Sec:    22153, Lr: 0.000300\n",
            "2021-05-04 16:27:25,105 - INFO - joeynmt.training - Epoch  16, Step:    39800, Batch Loss:     1.458017, Tokens per Sec:    21448, Lr: 0.000300\n",
            "2021-05-04 16:27:34,862 - INFO - joeynmt.training - Epoch  16, Step:    39900, Batch Loss:     1.864929, Tokens per Sec:    21603, Lr: 0.000300\n",
            "2021-05-04 16:27:40,764 - INFO - joeynmt.training - Epoch  16: total training loss 4362.13\n",
            "2021-05-04 16:27:40,764 - INFO - joeynmt.training - EPOCH 17\n",
            "2021-05-04 16:27:44,949 - INFO - joeynmt.training - Epoch  17, Step:    40000, Batch Loss:     1.844005, Tokens per Sec:    19999, Lr: 0.000300\n",
            "2021-05-04 16:27:56,582 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:27:56,582 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:27:56,582 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:27:56,831 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:27:56,832 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:27:57,222 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:27:57,222 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:27:57,222 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:27:57,223 - INFO - joeynmt.training - \tHypothesis: Iyali tana da kyau kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:27:57,223 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:27:57,223 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:27:57,223 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:27:57,223 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da abin da zai iya sa mutum ya tsira daga rayuwa mai haƙuri , Allah zai “ datse ” mugayen mutane don su more rayuwa a duniya .\n",
            "2021-05-04 16:27:57,223 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:27:57,223 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:27:57,223 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:27:57,223 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:27:57,224 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:27:57,224 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:27:57,224 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:27:57,224 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:27:57,224 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    40000: bleu:  27.95, loss: 39027.3867, ppl:   4.7167, duration: 12.2747s\n",
            "2021-05-04 16:28:07,123 - INFO - joeynmt.training - Epoch  17, Step:    40100, Batch Loss:     1.657462, Tokens per Sec:    21599, Lr: 0.000300\n",
            "2021-05-04 16:28:16,949 - INFO - joeynmt.training - Epoch  17, Step:    40200, Batch Loss:     1.495948, Tokens per Sec:    21834, Lr: 0.000300\n",
            "2021-05-04 16:28:26,892 - INFO - joeynmt.training - Epoch  17, Step:    40300, Batch Loss:     1.912698, Tokens per Sec:    21955, Lr: 0.000300\n",
            "2021-05-04 16:28:36,725 - INFO - joeynmt.training - Epoch  17, Step:    40400, Batch Loss:     1.444802, Tokens per Sec:    21894, Lr: 0.000300\n",
            "2021-05-04 16:28:46,582 - INFO - joeynmt.training - Epoch  17, Step:    40500, Batch Loss:     1.742284, Tokens per Sec:    21460, Lr: 0.000300\n",
            "2021-05-04 16:28:56,388 - INFO - joeynmt.training - Epoch  17, Step:    40600, Batch Loss:     1.771678, Tokens per Sec:    21701, Lr: 0.000300\n",
            "2021-05-04 16:29:06,363 - INFO - joeynmt.training - Epoch  17, Step:    40700, Batch Loss:     1.661631, Tokens per Sec:    21980, Lr: 0.000300\n",
            "2021-05-04 16:29:16,097 - INFO - joeynmt.training - Epoch  17, Step:    40800, Batch Loss:     1.798684, Tokens per Sec:    21230, Lr: 0.000300\n",
            "2021-05-04 16:29:25,934 - INFO - joeynmt.training - Epoch  17, Step:    40900, Batch Loss:     1.702436, Tokens per Sec:    22147, Lr: 0.000300\n",
            "2021-05-04 16:29:35,837 - INFO - joeynmt.training - Epoch  17, Step:    41000, Batch Loss:     1.407776, Tokens per Sec:    21735, Lr: 0.000300\n",
            "2021-05-04 16:29:46,615 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:29:46,615 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:29:46,615 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:29:46,859 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:29:46,859 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:29:47,250 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:29:47,250 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:29:47,250 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:29:47,250 - INFO - joeynmt.training - \tHypothesis: Iyali tana da daɗi kuma tana da kyau ga dukan iyalai .\n",
            "2021-05-04 16:29:47,250 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:29:47,251 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:29:47,251 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:29:47,251 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da lahani ko kuma a ceci rai na haƙuri , Allah zai “ datse ” mugayen mutane don mutane masu kirki za su more rayuwa a duniya .\n",
            "2021-05-04 16:29:47,251 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:29:47,251 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:29:47,251 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:29:47,251 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:29:47,251 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:29:47,251 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:29:47,251 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:29:47,251 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:29:47,251 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    41000: bleu:  27.82, loss: 38848.7539, ppl:   4.6833, duration: 11.4139s\n",
            "2021-05-04 16:29:57,011 - INFO - joeynmt.training - Epoch  17, Step:    41100, Batch Loss:     1.643612, Tokens per Sec:    21492, Lr: 0.000300\n",
            "2021-05-04 16:30:06,813 - INFO - joeynmt.training - Epoch  17, Step:    41200, Batch Loss:     1.473391, Tokens per Sec:    21625, Lr: 0.000300\n",
            "2021-05-04 16:30:16,680 - INFO - joeynmt.training - Epoch  17, Step:    41300, Batch Loss:     1.735819, Tokens per Sec:    21739, Lr: 0.000300\n",
            "2021-05-04 16:30:26,549 - INFO - joeynmt.training - Epoch  17, Step:    41400, Batch Loss:     1.607003, Tokens per Sec:    21842, Lr: 0.000300\n",
            "2021-05-04 16:30:36,446 - INFO - joeynmt.training - Epoch  17, Step:    41500, Batch Loss:     1.697105, Tokens per Sec:    21598, Lr: 0.000300\n",
            "2021-05-04 16:30:46,410 - INFO - joeynmt.training - Epoch  17, Step:    41600, Batch Loss:     1.707839, Tokens per Sec:    22153, Lr: 0.000300\n",
            "2021-05-04 16:30:56,301 - INFO - joeynmt.training - Epoch  17, Step:    41700, Batch Loss:     1.619225, Tokens per Sec:    22099, Lr: 0.000300\n",
            "2021-05-04 16:31:06,096 - INFO - joeynmt.training - Epoch  17, Step:    41800, Batch Loss:     1.602705, Tokens per Sec:    21439, Lr: 0.000300\n",
            "2021-05-04 16:31:15,967 - INFO - joeynmt.training - Epoch  17, Step:    41900, Batch Loss:     1.757605, Tokens per Sec:    22003, Lr: 0.000300\n",
            "2021-05-04 16:31:25,799 - INFO - joeynmt.training - Epoch  17, Step:    42000, Batch Loss:     1.589415, Tokens per Sec:    21540, Lr: 0.000300\n",
            "2021-05-04 16:31:37,007 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:31:37,007 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:31:37,007 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:31:37,259 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:31:37,259 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:31:37,601 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:31:37,602 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:31:37,602 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:31:37,602 - INFO - joeynmt.training - \tHypothesis: A gida yana da kyau kuma yana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:31:37,602 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:31:37,602 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:31:37,602 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:31:37,602 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da lahani ko kuma a ceci rayuwar mai haƙuri , Allah zai “ datse ” mugayen mugayen mutane don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 16:31:37,602 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:31:37,603 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:31:37,603 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:31:37,603 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:31:37,603 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:31:37,603 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:31:37,603 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:31:37,603 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:31:37,603 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    42000: bleu:  28.78, loss: 38672.8672, ppl:   4.6507, duration: 11.8036s\n",
            "2021-05-04 16:31:47,493 - INFO - joeynmt.training - Epoch  17, Step:    42100, Batch Loss:     1.614719, Tokens per Sec:    21252, Lr: 0.000300\n",
            "2021-05-04 16:31:57,461 - INFO - joeynmt.training - Epoch  17, Step:    42200, Batch Loss:     1.584198, Tokens per Sec:    21840, Lr: 0.000300\n",
            "2021-05-04 16:32:07,333 - INFO - joeynmt.training - Epoch  17, Step:    42300, Batch Loss:     1.885691, Tokens per Sec:    21831, Lr: 0.000300\n",
            "2021-05-04 16:32:17,224 - INFO - joeynmt.training - Epoch  17, Step:    42400, Batch Loss:     1.849872, Tokens per Sec:    21382, Lr: 0.000300\n",
            "2021-05-04 16:32:22,977 - INFO - joeynmt.training - Epoch  17: total training loss 4318.07\n",
            "2021-05-04 16:32:22,978 - INFO - joeynmt.training - EPOCH 18\n",
            "2021-05-04 16:32:27,460 - INFO - joeynmt.training - Epoch  18, Step:    42500, Batch Loss:     1.770935, Tokens per Sec:    20698, Lr: 0.000300\n",
            "2021-05-04 16:32:37,268 - INFO - joeynmt.training - Epoch  18, Step:    42600, Batch Loss:     1.627548, Tokens per Sec:    21764, Lr: 0.000300\n",
            "2021-05-04 16:32:47,084 - INFO - joeynmt.training - Epoch  18, Step:    42700, Batch Loss:     1.906363, Tokens per Sec:    21605, Lr: 0.000300\n",
            "2021-05-04 16:32:56,932 - INFO - joeynmt.training - Epoch  18, Step:    42800, Batch Loss:     1.189938, Tokens per Sec:    21923, Lr: 0.000300\n",
            "2021-05-04 16:33:06,763 - INFO - joeynmt.training - Epoch  18, Step:    42900, Batch Loss:     1.703916, Tokens per Sec:    21664, Lr: 0.000300\n",
            "2021-05-04 16:33:16,662 - INFO - joeynmt.training - Epoch  18, Step:    43000, Batch Loss:     1.553960, Tokens per Sec:    22029, Lr: 0.000300\n",
            "2021-05-04 16:33:27,502 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:33:27,502 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:33:27,502 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:33:27,749 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:33:27,749 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:33:28,109 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:33:28,109 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:33:28,110 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:33:28,110 - INFO - joeynmt.training - \tHypothesis: A gida gida gida yana da daɗi kuma yana da kyau ga dukan iyali .\n",
            "2021-05-04 16:33:28,110 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:33:28,110 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:33:28,110 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:33:28,110 - INFO - joeynmt.training - \tHypothesis: Kamar yadda wani abin da zai iya sa mutum ya yi tuntuɓe ko kuma ya ceci rai na haƙuri , Allah zai “ datse ” mugayen mugayen mutane don su more rayuwa a duniya .\n",
            "2021-05-04 16:33:28,110 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:33:28,110 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:33:28,110 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:33:28,110 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:33:28,110 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:33:28,111 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:33:28,111 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:33:28,111 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:33:28,111 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    43000: bleu:  28.57, loss: 38422.9727, ppl:   4.6047, duration: 11.4484s\n",
            "2021-05-04 16:33:37,954 - INFO - joeynmt.training - Epoch  18, Step:    43100, Batch Loss:     1.682520, Tokens per Sec:    21733, Lr: 0.000300\n",
            "2021-05-04 16:33:47,837 - INFO - joeynmt.training - Epoch  18, Step:    43200, Batch Loss:     1.791245, Tokens per Sec:    21735, Lr: 0.000300\n",
            "2021-05-04 16:33:57,685 - INFO - joeynmt.training - Epoch  18, Step:    43300, Batch Loss:     1.590622, Tokens per Sec:    22051, Lr: 0.000300\n",
            "2021-05-04 16:34:07,511 - INFO - joeynmt.training - Epoch  18, Step:    43400, Batch Loss:     1.501480, Tokens per Sec:    21947, Lr: 0.000300\n",
            "2021-05-04 16:34:17,239 - INFO - joeynmt.training - Epoch  18, Step:    43500, Batch Loss:     1.933014, Tokens per Sec:    21634, Lr: 0.000300\n",
            "2021-05-04 16:34:27,076 - INFO - joeynmt.training - Epoch  18, Step:    43600, Batch Loss:     1.701743, Tokens per Sec:    21725, Lr: 0.000300\n",
            "2021-05-04 16:34:36,943 - INFO - joeynmt.training - Epoch  18, Step:    43700, Batch Loss:     1.807137, Tokens per Sec:    21705, Lr: 0.000300\n",
            "2021-05-04 16:34:46,893 - INFO - joeynmt.training - Epoch  18, Step:    43800, Batch Loss:     1.264115, Tokens per Sec:    21662, Lr: 0.000300\n",
            "2021-05-04 16:34:56,666 - INFO - joeynmt.training - Epoch  18, Step:    43900, Batch Loss:     1.650091, Tokens per Sec:    21669, Lr: 0.000300\n",
            "2021-05-04 16:35:06,673 - INFO - joeynmt.training - Epoch  18, Step:    44000, Batch Loss:     1.389027, Tokens per Sec:    22548, Lr: 0.000300\n",
            "2021-05-04 16:35:17,532 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:35:17,532 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:35:17,532 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:35:18,115 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:35:18,115 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:35:18,116 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:35:18,116 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:35:18,116 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:35:18,116 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:35:18,116 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:35:18,116 - INFO - joeynmt.training - \tHypothesis: Kamar yadda wani abin da zai iya sa mutum ya yi tuntuɓe ko kuma ya ceci rayuwar mai haƙuri , Allah zai “ kawar ” miyagu domin mutane masu kirki za su more rayuwa a duniya .\n",
            "2021-05-04 16:35:18,116 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:35:18,116 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:35:18,116 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:35:18,116 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:35:18,116 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:35:18,116 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:35:18,117 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:35:18,117 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abin da zan yi masa . ”\n",
            "2021-05-04 16:35:18,117 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    44000: bleu:  28.70, loss: 38500.8242, ppl:   4.6190, duration: 11.4431s\n",
            "2021-05-04 16:35:27,943 - INFO - joeynmt.training - Epoch  18, Step:    44100, Batch Loss:     1.698657, Tokens per Sec:    22119, Lr: 0.000300\n",
            "2021-05-04 16:35:37,768 - INFO - joeynmt.training - Epoch  18, Step:    44200, Batch Loss:     2.136918, Tokens per Sec:    21546, Lr: 0.000300\n",
            "2021-05-04 16:35:47,728 - INFO - joeynmt.training - Epoch  18, Step:    44300, Batch Loss:     1.628232, Tokens per Sec:    22195, Lr: 0.000300\n",
            "2021-05-04 16:35:57,445 - INFO - joeynmt.training - Epoch  18, Step:    44400, Batch Loss:     1.766439, Tokens per Sec:    20728, Lr: 0.000300\n",
            "2021-05-04 16:36:07,422 - INFO - joeynmt.training - Epoch  18, Step:    44500, Batch Loss:     1.879616, Tokens per Sec:    21960, Lr: 0.000300\n",
            "2021-05-04 16:36:17,268 - INFO - joeynmt.training - Epoch  18, Step:    44600, Batch Loss:     1.923931, Tokens per Sec:    21876, Lr: 0.000300\n",
            "2021-05-04 16:36:27,142 - INFO - joeynmt.training - Epoch  18, Step:    44700, Batch Loss:     1.513207, Tokens per Sec:    21751, Lr: 0.000300\n",
            "2021-05-04 16:36:37,011 - INFO - joeynmt.training - Epoch  18, Step:    44800, Batch Loss:     1.543258, Tokens per Sec:    21958, Lr: 0.000300\n",
            "2021-05-04 16:36:46,790 - INFO - joeynmt.training - Epoch  18, Step:    44900, Batch Loss:     1.467981, Tokens per Sec:    21321, Lr: 0.000300\n",
            "2021-05-04 16:36:51,961 - INFO - joeynmt.training - Epoch  18: total training loss 4280.26\n",
            "2021-05-04 16:36:51,961 - INFO - joeynmt.training - EPOCH 19\n",
            "2021-05-04 16:36:56,832 - INFO - joeynmt.training - Epoch  19, Step:    45000, Batch Loss:     1.821847, Tokens per Sec:    21182, Lr: 0.000300\n",
            "2021-05-04 16:37:07,729 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:37:07,729 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:37:07,729 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:37:07,991 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:37:07,991 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:37:08,368 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:37:08,368 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:37:08,368 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:37:08,368 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:37:08,368 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:37:08,368 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:37:08,368 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:37:08,369 - INFO - joeynmt.training - \tHypothesis: Kamar yadda abin da zai iya cire rayuwa mai ma’ana ko kuma ya ceci rai na haƙuri , Allah zai “ datse ” miyagu domin mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 16:37:08,369 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:37:08,369 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:37:08,369 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:37:08,369 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:37:08,369 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:37:08,369 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:37:08,369 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:37:08,369 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:37:08,369 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    45000: bleu:  29.18, loss: 38346.7422, ppl:   4.5908, duration: 11.5365s\n",
            "2021-05-04 16:37:18,255 - INFO - joeynmt.training - Epoch  19, Step:    45100, Batch Loss:     1.778814, Tokens per Sec:    21843, Lr: 0.000300\n",
            "2021-05-04 16:37:28,040 - INFO - joeynmt.training - Epoch  19, Step:    45200, Batch Loss:     2.472225, Tokens per Sec:    21522, Lr: 0.000300\n",
            "2021-05-04 16:37:37,865 - INFO - joeynmt.training - Epoch  19, Step:    45300, Batch Loss:     1.763195, Tokens per Sec:    21610, Lr: 0.000300\n",
            "2021-05-04 16:37:47,560 - INFO - joeynmt.training - Epoch  19, Step:    45400, Batch Loss:     1.815935, Tokens per Sec:    21333, Lr: 0.000300\n",
            "2021-05-04 16:37:57,379 - INFO - joeynmt.training - Epoch  19, Step:    45500, Batch Loss:     1.822281, Tokens per Sec:    22234, Lr: 0.000300\n",
            "2021-05-04 16:38:07,245 - INFO - joeynmt.training - Epoch  19, Step:    45600, Batch Loss:     1.514619, Tokens per Sec:    21714, Lr: 0.000300\n",
            "2021-05-04 16:38:16,907 - INFO - joeynmt.training - Epoch  19, Step:    45700, Batch Loss:     1.590047, Tokens per Sec:    21611, Lr: 0.000300\n",
            "2021-05-04 16:38:26,626 - INFO - joeynmt.training - Epoch  19, Step:    45800, Batch Loss:     1.618455, Tokens per Sec:    21280, Lr: 0.000300\n",
            "2021-05-04 16:38:36,574 - INFO - joeynmt.training - Epoch  19, Step:    45900, Batch Loss:     1.955210, Tokens per Sec:    22078, Lr: 0.000300\n",
            "2021-05-04 16:38:46,476 - INFO - joeynmt.training - Epoch  19, Step:    46000, Batch Loss:     1.908086, Tokens per Sec:    22012, Lr: 0.000300\n",
            "2021-05-04 16:38:57,682 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:38:57,682 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:38:57,682 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:38:57,927 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:38:57,927 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:38:58,311 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:38:58,311 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:38:58,311 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:38:58,311 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da kyau kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:38:58,311 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:38:58,311 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:38:58,311 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:38:58,311 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya cire wani abu mai kyau ko kuma ya ceci rayuwar mai haƙuri , Allah zai “ datse ” miyagu domin mutane masu kirki za su more rayuwa a duniya .\n",
            "2021-05-04 16:38:58,311 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:38:58,312 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:38:58,312 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:38:58,312 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:38:58,312 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:38:58,312 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:38:58,312 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:38:58,312 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a bisansa . ”\n",
            "2021-05-04 16:38:58,312 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    46000: bleu:  28.86, loss: 38067.6445, ppl:   4.5402, duration: 11.8355s\n",
            "2021-05-04 16:39:08,020 - INFO - joeynmt.training - Epoch  19, Step:    46100, Batch Loss:     1.133953, Tokens per Sec:    21518, Lr: 0.000300\n",
            "2021-05-04 16:39:17,836 - INFO - joeynmt.training - Epoch  19, Step:    46200, Batch Loss:     1.452193, Tokens per Sec:    21821, Lr: 0.000300\n",
            "2021-05-04 16:39:27,720 - INFO - joeynmt.training - Epoch  19, Step:    46300, Batch Loss:     1.487025, Tokens per Sec:    22141, Lr: 0.000300\n",
            "2021-05-04 16:39:37,448 - INFO - joeynmt.training - Epoch  19, Step:    46400, Batch Loss:     1.467669, Tokens per Sec:    21466, Lr: 0.000300\n",
            "2021-05-04 16:39:47,297 - INFO - joeynmt.training - Epoch  19, Step:    46500, Batch Loss:     1.463281, Tokens per Sec:    21925, Lr: 0.000300\n",
            "2021-05-04 16:39:57,101 - INFO - joeynmt.training - Epoch  19, Step:    46600, Batch Loss:     1.709244, Tokens per Sec:    21431, Lr: 0.000300\n",
            "2021-05-04 16:40:06,968 - INFO - joeynmt.training - Epoch  19, Step:    46700, Batch Loss:     1.689431, Tokens per Sec:    22412, Lr: 0.000300\n",
            "2021-05-04 16:40:16,867 - INFO - joeynmt.training - Epoch  19, Step:    46800, Batch Loss:     1.672673, Tokens per Sec:    21772, Lr: 0.000300\n",
            "2021-05-04 16:40:26,705 - INFO - joeynmt.training - Epoch  19, Step:    46900, Batch Loss:     1.629778, Tokens per Sec:    21833, Lr: 0.000300\n",
            "2021-05-04 16:40:36,383 - INFO - joeynmt.training - Epoch  19, Step:    47000, Batch Loss:     1.745448, Tokens per Sec:    21228, Lr: 0.000300\n",
            "2021-05-04 16:40:46,943 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:40:46,943 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:40:46,943 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:40:47,202 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:40:47,202 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:40:47,584 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:40:47,584 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:40:47,584 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:40:47,585 - INFO - joeynmt.training - \tHypothesis: Gidanta yana da daɗi kuma yana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:40:47,585 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:40:47,585 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:40:47,585 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:40:47,585 - INFO - joeynmt.training - \tHypothesis: Kamar yadda wani abin da zai iya cire ransa ko kuma ya ceci rayuwar mutum , Allah zai “ datse ” mugayen mutane masu kirki don su more rayuwa a duniya .\n",
            "2021-05-04 16:40:47,585 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:40:47,585 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:40:47,585 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:40:47,585 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:40:47,585 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:40:47,585 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:40:47,586 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:40:47,586 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi masa . ”\n",
            "2021-05-04 16:40:47,586 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    47000: bleu:  29.09, loss: 37988.3086, ppl:   4.5259, duration: 11.2020s\n",
            "2021-05-04 16:40:57,367 - INFO - joeynmt.training - Epoch  19, Step:    47100, Batch Loss:     1.638667, Tokens per Sec:    21703, Lr: 0.000300\n",
            "2021-05-04 16:41:07,238 - INFO - joeynmt.training - Epoch  19, Step:    47200, Batch Loss:     1.488394, Tokens per Sec:    21978, Lr: 0.000300\n",
            "2021-05-04 16:41:17,060 - INFO - joeynmt.training - Epoch  19, Step:    47300, Batch Loss:     1.753108, Tokens per Sec:    21949, Lr: 0.000300\n",
            "2021-05-04 16:41:26,905 - INFO - joeynmt.training - Epoch  19, Step:    47400, Batch Loss:     1.566195, Tokens per Sec:    22184, Lr: 0.000300\n",
            "2021-05-04 16:41:32,554 - INFO - joeynmt.training - Epoch  19: total training loss 4256.26\n",
            "2021-05-04 16:41:32,554 - INFO - joeynmt.training - EPOCH 20\n",
            "2021-05-04 16:41:37,061 - INFO - joeynmt.training - Epoch  20, Step:    47500, Batch Loss:     1.808345, Tokens per Sec:    21052, Lr: 0.000300\n",
            "2021-05-04 16:41:46,814 - INFO - joeynmt.training - Epoch  20, Step:    47600, Batch Loss:     1.426548, Tokens per Sec:    21577, Lr: 0.000300\n",
            "2021-05-04 16:41:56,596 - INFO - joeynmt.training - Epoch  20, Step:    47700, Batch Loss:     1.605508, Tokens per Sec:    21730, Lr: 0.000300\n",
            "2021-05-04 16:42:06,415 - INFO - joeynmt.training - Epoch  20, Step:    47800, Batch Loss:     1.792245, Tokens per Sec:    21885, Lr: 0.000300\n",
            "2021-05-04 16:42:16,211 - INFO - joeynmt.training - Epoch  20, Step:    47900, Batch Loss:     1.541816, Tokens per Sec:    21917, Lr: 0.000300\n",
            "2021-05-04 16:42:26,054 - INFO - joeynmt.training - Epoch  20, Step:    48000, Batch Loss:     2.157584, Tokens per Sec:    22478, Lr: 0.000300\n",
            "2021-05-04 16:42:37,517 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:42:37,517 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:42:37,517 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:42:38,124 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:42:38,124 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:42:38,124 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:42:38,124 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:42:38,124 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:42:38,125 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:42:38,125 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:42:38,125 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da abin da zai iya sa mutum ya tsira daga rayuwa mai haƙuri , Allah zai “ datse ” miyagu don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 16:42:38,125 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:42:38,125 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:42:38,125 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:42:38,125 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:42:38,125 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:42:38,125 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:42:38,125 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:42:38,126 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a bisansa . ”\n",
            "2021-05-04 16:42:38,126 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    48000: bleu:  28.74, loss: 38027.1445, ppl:   4.5329, duration: 12.0716s\n",
            "2021-05-04 16:42:47,986 - INFO - joeynmt.training - Epoch  20, Step:    48100, Batch Loss:     1.141789, Tokens per Sec:    21343, Lr: 0.000300\n",
            "2021-05-04 16:42:57,739 - INFO - joeynmt.training - Epoch  20, Step:    48200, Batch Loss:     1.589694, Tokens per Sec:    21473, Lr: 0.000300\n",
            "2021-05-04 16:43:07,563 - INFO - joeynmt.training - Epoch  20, Step:    48300, Batch Loss:     1.661890, Tokens per Sec:    21805, Lr: 0.000300\n",
            "2021-05-04 16:43:17,415 - INFO - joeynmt.training - Epoch  20, Step:    48400, Batch Loss:     1.801364, Tokens per Sec:    22174, Lr: 0.000300\n",
            "2021-05-04 16:43:27,213 - INFO - joeynmt.training - Epoch  20, Step:    48500, Batch Loss:     1.583953, Tokens per Sec:    21761, Lr: 0.000300\n",
            "2021-05-04 16:43:37,060 - INFO - joeynmt.training - Epoch  20, Step:    48600, Batch Loss:     1.761905, Tokens per Sec:    22000, Lr: 0.000300\n",
            "2021-05-04 16:43:46,821 - INFO - joeynmt.training - Epoch  20, Step:    48700, Batch Loss:     1.565407, Tokens per Sec:    21616, Lr: 0.000300\n",
            "2021-05-04 16:43:56,784 - INFO - joeynmt.training - Epoch  20, Step:    48800, Batch Loss:     1.912395, Tokens per Sec:    22064, Lr: 0.000300\n",
            "2021-05-04 16:44:06,636 - INFO - joeynmt.training - Epoch  20, Step:    48900, Batch Loss:     1.945768, Tokens per Sec:    22018, Lr: 0.000300\n",
            "2021-05-04 16:44:16,404 - INFO - joeynmt.training - Epoch  20, Step:    49000, Batch Loss:     1.835839, Tokens per Sec:    22125, Lr: 0.000300\n",
            "2021-05-04 16:44:26,788 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:44:26,788 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:44:26,788 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:44:27,034 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:44:27,034 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:44:27,400 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:44:27,400 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:44:27,400 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:44:27,400 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:44:27,400 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:44:27,400 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:44:27,400 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:44:27,400 - INFO - joeynmt.training - \tHypothesis: Kamar yadda abin da zai iya sa mutane su yi tuntuɓe ko kuma su tsira wa rayuwar da ta yi haƙuri , Allah zai “ datse ” miyagu don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 16:44:27,401 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:44:27,401 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:44:27,401 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:44:27,401 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:44:27,401 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:44:27,401 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:44:27,401 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:44:27,401 - INFO - joeynmt.training - \tHypothesis: * A dukan duniya zan ƙasƙantar da shi . ”\n",
            "2021-05-04 16:44:27,401 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    49000: bleu:  28.74, loss: 37871.1289, ppl:   4.5048, duration: 10.9973s\n",
            "2021-05-04 16:44:37,292 - INFO - joeynmt.training - Epoch  20, Step:    49100, Batch Loss:     1.697238, Tokens per Sec:    21557, Lr: 0.000300\n",
            "2021-05-04 16:44:47,168 - INFO - joeynmt.training - Epoch  20, Step:    49200, Batch Loss:     1.678937, Tokens per Sec:    21759, Lr: 0.000300\n",
            "2021-05-04 16:44:56,921 - INFO - joeynmt.training - Epoch  20, Step:    49300, Batch Loss:     1.815426, Tokens per Sec:    21117, Lr: 0.000300\n",
            "2021-05-04 16:45:06,740 - INFO - joeynmt.training - Epoch  20, Step:    49400, Batch Loss:     1.510708, Tokens per Sec:    21904, Lr: 0.000300\n",
            "2021-05-04 16:45:16,631 - INFO - joeynmt.training - Epoch  20, Step:    49500, Batch Loss:     1.773932, Tokens per Sec:    21903, Lr: 0.000300\n",
            "2021-05-04 16:45:26,512 - INFO - joeynmt.training - Epoch  20, Step:    49600, Batch Loss:     1.673322, Tokens per Sec:    21753, Lr: 0.000300\n",
            "2021-05-04 16:45:36,447 - INFO - joeynmt.training - Epoch  20, Step:    49700, Batch Loss:     1.363009, Tokens per Sec:    22033, Lr: 0.000300\n",
            "2021-05-04 16:45:46,333 - INFO - joeynmt.training - Epoch  20, Step:    49800, Batch Loss:     1.595271, Tokens per Sec:    21681, Lr: 0.000300\n",
            "2021-05-04 16:45:56,125 - INFO - joeynmt.training - Epoch  20, Step:    49900, Batch Loss:     1.451700, Tokens per Sec:    21649, Lr: 0.000300\n",
            "2021-05-04 16:46:01,549 - INFO - joeynmt.training - Epoch  20: total training loss 4208.91\n",
            "2021-05-04 16:46:01,549 - INFO - joeynmt.training - EPOCH 21\n",
            "2021-05-04 16:46:06,218 - INFO - joeynmt.training - Epoch  21, Step:    50000, Batch Loss:     1.314332, Tokens per Sec:    20749, Lr: 0.000300\n",
            "2021-05-04 16:46:16,648 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:46:16,648 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:46:16,648 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:46:16,899 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:46:16,900 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:46:17,265 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:46:17,265 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:46:17,265 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:46:17,265 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da kyau kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:46:17,265 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:46:17,266 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:46:17,266 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:46:17,266 - INFO - joeynmt.training - \tHypothesis: Kamar yadda abin da zai iya cire mutum mai basira ko kuma ya ceci rayuwar mutum , Allah zai “ datse ” mugayen mutane don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 16:46:17,266 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:46:17,266 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:46:17,266 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:46:17,266 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:46:17,266 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:46:17,266 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:46:17,266 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:46:17,266 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan duniya zan yi masa sujada . ”\n",
            "2021-05-04 16:46:17,266 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    50000: bleu:  28.86, loss: 37629.8320, ppl:   4.4618, duration: 11.0484s\n",
            "2021-05-04 16:46:27,006 - INFO - joeynmt.training - Epoch  21, Step:    50100, Batch Loss:     1.782601, Tokens per Sec:    20973, Lr: 0.000300\n",
            "2021-05-04 16:46:36,854 - INFO - joeynmt.training - Epoch  21, Step:    50200, Batch Loss:     1.688619, Tokens per Sec:    22057, Lr: 0.000300\n",
            "2021-05-04 16:46:46,800 - INFO - joeynmt.training - Epoch  21, Step:    50300, Batch Loss:     1.674006, Tokens per Sec:    22006, Lr: 0.000300\n",
            "2021-05-04 16:46:56,635 - INFO - joeynmt.training - Epoch  21, Step:    50400, Batch Loss:     1.741019, Tokens per Sec:    21942, Lr: 0.000300\n",
            "2021-05-04 16:47:06,447 - INFO - joeynmt.training - Epoch  21, Step:    50500, Batch Loss:     1.579797, Tokens per Sec:    21493, Lr: 0.000300\n",
            "2021-05-04 16:47:16,359 - INFO - joeynmt.training - Epoch  21, Step:    50600, Batch Loss:     1.624062, Tokens per Sec:    22075, Lr: 0.000300\n",
            "2021-05-04 16:47:26,132 - INFO - joeynmt.training - Epoch  21, Step:    50700, Batch Loss:     1.853761, Tokens per Sec:    21653, Lr: 0.000300\n",
            "2021-05-04 16:47:35,973 - INFO - joeynmt.training - Epoch  21, Step:    50800, Batch Loss:     1.341451, Tokens per Sec:    21835, Lr: 0.000300\n",
            "2021-05-04 16:47:45,996 - INFO - joeynmt.training - Epoch  21, Step:    50900, Batch Loss:     1.626705, Tokens per Sec:    22095, Lr: 0.000300\n",
            "2021-05-04 16:47:55,747 - INFO - joeynmt.training - Epoch  21, Step:    51000, Batch Loss:     1.526718, Tokens per Sec:    22008, Lr: 0.000300\n",
            "2021-05-04 16:48:06,224 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:48:06,224 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:48:06,224 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:48:06,470 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:48:06,471 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:48:06,830 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:48:06,830 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:48:06,830 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:48:06,830 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:48:06,830 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:48:06,831 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:48:06,831 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:48:06,831 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da lahani ko kuma ceton rayuwar mai haƙuri , Allah zai “ datse ” mugayen mutane masu kirki don su more rayuwa a duniya .\n",
            "2021-05-04 16:48:06,831 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:48:06,831 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:48:06,831 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:48:06,831 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:48:06,831 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:48:06,831 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:48:06,832 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:48:06,832 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan duniya zan yi masa sujada . ”\n",
            "2021-05-04 16:48:06,832 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    51000: bleu:  29.06, loss: 37514.8906, ppl:   4.4415, duration: 11.0850s\n",
            "2021-05-04 16:48:16,696 - INFO - joeynmt.training - Epoch  21, Step:    51100, Batch Loss:     1.622439, Tokens per Sec:    21333, Lr: 0.000300\n",
            "2021-05-04 16:48:26,498 - INFO - joeynmt.training - Epoch  21, Step:    51200, Batch Loss:     1.933998, Tokens per Sec:    21786, Lr: 0.000300\n",
            "2021-05-04 16:48:36,458 - INFO - joeynmt.training - Epoch  21, Step:    51300, Batch Loss:     1.691098, Tokens per Sec:    21956, Lr: 0.000300\n",
            "2021-05-04 16:48:46,468 - INFO - joeynmt.training - Epoch  21, Step:    51400, Batch Loss:     1.468500, Tokens per Sec:    21308, Lr: 0.000300\n",
            "2021-05-04 16:48:56,370 - INFO - joeynmt.training - Epoch  21, Step:    51500, Batch Loss:     1.882442, Tokens per Sec:    21728, Lr: 0.000300\n",
            "2021-05-04 16:49:06,248 - INFO - joeynmt.training - Epoch  21, Step:    51600, Batch Loss:     1.676639, Tokens per Sec:    21863, Lr: 0.000300\n",
            "2021-05-04 16:49:16,083 - INFO - joeynmt.training - Epoch  21, Step:    51700, Batch Loss:     1.917242, Tokens per Sec:    21973, Lr: 0.000300\n",
            "2021-05-04 16:49:25,939 - INFO - joeynmt.training - Epoch  21, Step:    51800, Batch Loss:     1.498540, Tokens per Sec:    22088, Lr: 0.000300\n",
            "2021-05-04 16:49:35,874 - INFO - joeynmt.training - Epoch  21, Step:    51900, Batch Loss:     1.463780, Tokens per Sec:    21780, Lr: 0.000300\n",
            "2021-05-04 16:49:45,772 - INFO - joeynmt.training - Epoch  21, Step:    52000, Batch Loss:     1.852001, Tokens per Sec:    21841, Lr: 0.000300\n",
            "2021-05-04 16:49:56,383 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:49:56,383 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:49:56,383 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:49:56,630 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:49:56,630 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:49:56,987 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:49:56,988 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:49:56,988 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:49:56,988 - INFO - joeynmt.training - \tHypothesis: A gida gida gida yana da kyau kuma yana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:49:56,988 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:49:56,988 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:49:56,988 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:49:56,988 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da wani abu mai kyau ko kuma ya ceci rai na haƙuri , Allah zai “ datse ” miyagu domin mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 16:49:56,988 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:49:56,988 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:49:56,988 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:49:56,988 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:49:56,988 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:49:56,989 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:49:56,989 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:49:56,989 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abu zan yi masa albarka . ”\n",
            "2021-05-04 16:49:56,989 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    52000: bleu:  29.18, loss: 37348.4062, ppl:   4.4122, duration: 11.2159s\n",
            "2021-05-04 16:50:06,769 - INFO - joeynmt.training - Epoch  21, Step:    52100, Batch Loss:     1.620383, Tokens per Sec:    21209, Lr: 0.000300\n",
            "2021-05-04 16:50:16,852 - INFO - joeynmt.training - Epoch  21, Step:    52200, Batch Loss:     1.407669, Tokens per Sec:    21651, Lr: 0.000300\n",
            "2021-05-04 16:50:26,814 - INFO - joeynmt.training - Epoch  21, Step:    52300, Batch Loss:     1.669403, Tokens per Sec:    21366, Lr: 0.000300\n",
            "2021-05-04 16:50:36,743 - INFO - joeynmt.training - Epoch  21, Step:    52400, Batch Loss:     1.407698, Tokens per Sec:    21536, Lr: 0.000300\n",
            "2021-05-04 16:50:41,715 - INFO - joeynmt.training - Epoch  21: total training loss 4171.94\n",
            "2021-05-04 16:50:41,716 - INFO - joeynmt.training - EPOCH 22\n",
            "2021-05-04 16:50:46,967 - INFO - joeynmt.training - Epoch  22, Step:    52500, Batch Loss:     1.419830, Tokens per Sec:    20357, Lr: 0.000300\n",
            "2021-05-04 16:50:56,965 - INFO - joeynmt.training - Epoch  22, Step:    52600, Batch Loss:     1.878611, Tokens per Sec:    21710, Lr: 0.000300\n",
            "2021-05-04 16:51:06,894 - INFO - joeynmt.training - Epoch  22, Step:    52700, Batch Loss:     1.900522, Tokens per Sec:    21550, Lr: 0.000300\n",
            "2021-05-04 16:51:16,804 - INFO - joeynmt.training - Epoch  22, Step:    52800, Batch Loss:     1.675593, Tokens per Sec:    21729, Lr: 0.000300\n",
            "2021-05-04 16:51:26,749 - INFO - joeynmt.training - Epoch  22, Step:    52900, Batch Loss:     1.413232, Tokens per Sec:    21699, Lr: 0.000300\n",
            "2021-05-04 16:51:36,712 - INFO - joeynmt.training - Epoch  22, Step:    53000, Batch Loss:     1.135697, Tokens per Sec:    21677, Lr: 0.000300\n",
            "2021-05-04 16:51:47,889 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:51:47,889 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:51:47,889 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:51:48,489 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:51:48,490 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:51:48,490 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:51:48,490 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:51:48,490 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:51:48,490 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:51:48,490 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:51:48,490 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya cire wani abu mai kyau ko kuma ya ceci rayuwar mai haƙuri , Allah zai “ datse ” mugayen mutane don su more rayuwa a duniya .\n",
            "2021-05-04 16:51:48,490 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:51:48,490 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:51:48,491 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:51:48,491 - INFO - joeynmt.training - \tHypothesis: Sun sami kwanciyar hankali a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:51:48,491 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:51:48,491 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:51:48,491 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:51:48,491 - INFO - joeynmt.training - \tHypothesis: * Zan yi masa sujada . ”\n",
            "2021-05-04 16:51:48,491 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    53000: bleu:  28.85, loss: 37350.7891, ppl:   4.4126, duration: 11.7782s\n",
            "2021-05-04 16:51:58,395 - INFO - joeynmt.training - Epoch  22, Step:    53100, Batch Loss:     1.607061, Tokens per Sec:    21626, Lr: 0.000300\n",
            "2021-05-04 16:52:08,430 - INFO - joeynmt.training - Epoch  22, Step:    53200, Batch Loss:     1.772935, Tokens per Sec:    21606, Lr: 0.000300\n",
            "2021-05-04 16:52:18,373 - INFO - joeynmt.training - Epoch  22, Step:    53300, Batch Loss:     1.711808, Tokens per Sec:    21642, Lr: 0.000300\n",
            "2021-05-04 16:52:28,186 - INFO - joeynmt.training - Epoch  22, Step:    53400, Batch Loss:     1.968810, Tokens per Sec:    21567, Lr: 0.000300\n",
            "2021-05-04 16:52:38,209 - INFO - joeynmt.training - Epoch  22, Step:    53500, Batch Loss:     1.898408, Tokens per Sec:    21879, Lr: 0.000300\n",
            "2021-05-04 16:52:48,264 - INFO - joeynmt.training - Epoch  22, Step:    53600, Batch Loss:     1.364020, Tokens per Sec:    21636, Lr: 0.000300\n",
            "2021-05-04 16:52:58,172 - INFO - joeynmt.training - Epoch  22, Step:    53700, Batch Loss:     1.715822, Tokens per Sec:    21654, Lr: 0.000300\n",
            "2021-05-04 16:53:08,124 - INFO - joeynmt.training - Epoch  22, Step:    53800, Batch Loss:     1.912760, Tokens per Sec:    21728, Lr: 0.000300\n",
            "2021-05-04 16:53:18,046 - INFO - joeynmt.training - Epoch  22, Step:    53900, Batch Loss:     2.014135, Tokens per Sec:    21701, Lr: 0.000300\n",
            "2021-05-04 16:53:27,971 - INFO - joeynmt.training - Epoch  22, Step:    54000, Batch Loss:     1.776118, Tokens per Sec:    21685, Lr: 0.000300\n",
            "2021-05-04 16:53:38,570 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:53:38,570 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:53:38,571 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:53:38,816 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:53:38,816 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:53:39,214 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:53:39,214 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:53:39,214 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:53:39,214 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:53:39,214 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:53:39,214 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:53:39,215 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:53:39,215 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da tuntuɓe ko kuma ya ceci rayuwar mai haƙuri , Allah zai “ datse ” miyagu don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 16:53:39,215 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:53:39,215 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:53:39,215 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:53:39,215 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:53:39,215 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:53:39,215 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:53:39,215 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:53:39,215 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan duniya zan yi tsaro a kansa . ”\n",
            "2021-05-04 16:53:39,216 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    54000: bleu:  29.03, loss: 37320.1992, ppl:   4.4073, duration: 11.2437s\n",
            "2021-05-04 16:53:49,069 - INFO - joeynmt.training - Epoch  22, Step:    54100, Batch Loss:     1.792476, Tokens per Sec:    21002, Lr: 0.000300\n",
            "2021-05-04 16:53:58,999 - INFO - joeynmt.training - Epoch  22, Step:    54200, Batch Loss:     1.799221, Tokens per Sec:    21619, Lr: 0.000300\n",
            "2021-05-04 16:54:08,820 - INFO - joeynmt.training - Epoch  22, Step:    54300, Batch Loss:     1.442319, Tokens per Sec:    21336, Lr: 0.000300\n",
            "2021-05-04 16:54:18,828 - INFO - joeynmt.training - Epoch  22, Step:    54400, Batch Loss:     2.016652, Tokens per Sec:    21862, Lr: 0.000300\n",
            "2021-05-04 16:54:28,661 - INFO - joeynmt.training - Epoch  22, Step:    54500, Batch Loss:     1.523798, Tokens per Sec:    21410, Lr: 0.000300\n",
            "2021-05-04 16:54:38,605 - INFO - joeynmt.training - Epoch  22, Step:    54600, Batch Loss:     2.041361, Tokens per Sec:    21618, Lr: 0.000300\n",
            "2021-05-04 16:54:48,518 - INFO - joeynmt.training - Epoch  22, Step:    54700, Batch Loss:     1.140094, Tokens per Sec:    21449, Lr: 0.000300\n",
            "2021-05-04 16:54:58,360 - INFO - joeynmt.training - Epoch  22, Step:    54800, Batch Loss:     1.777810, Tokens per Sec:    21443, Lr: 0.000300\n",
            "2021-05-04 16:55:08,240 - INFO - joeynmt.training - Epoch  22, Step:    54900, Batch Loss:     1.870777, Tokens per Sec:    21636, Lr: 0.000300\n",
            "2021-05-04 16:55:13,146 - INFO - joeynmt.training - Epoch  22: total training loss 4145.98\n",
            "2021-05-04 16:55:13,146 - INFO - joeynmt.training - EPOCH 23\n",
            "2021-05-04 16:55:18,499 - INFO - joeynmt.training - Epoch  23, Step:    55000, Batch Loss:     1.787489, Tokens per Sec:    20470, Lr: 0.000300\n",
            "2021-05-04 16:55:30,045 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:55:30,045 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:55:30,045 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:55:30,295 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:55:30,295 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:55:30,676 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:55:30,677 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:55:30,677 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:55:30,677 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:55:30,677 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:55:30,677 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:55:30,677 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:55:30,677 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da wani abu mai kyau don ya ceci rayuwar mai haƙuri , Allah zai “ datse ” miyagu don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 16:55:30,677 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:55:30,677 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:55:30,677 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:55:30,678 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:55:30,678 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:55:30,678 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:55:30,678 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:55:30,678 - INFO - joeynmt.training - \tHypothesis: * Zan yi masa biyayya . ”\n",
            "2021-05-04 16:55:30,678 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    55000: bleu:  29.57, loss: 37230.0781, ppl:   4.3915, duration: 12.1784s\n",
            "2021-05-04 16:55:40,535 - INFO - joeynmt.training - Epoch  23, Step:    55100, Batch Loss:     1.323253, Tokens per Sec:    21619, Lr: 0.000300\n",
            "2021-05-04 16:55:50,471 - INFO - joeynmt.training - Epoch  23, Step:    55200, Batch Loss:     1.523114, Tokens per Sec:    21981, Lr: 0.000300\n",
            "2021-05-04 16:56:00,464 - INFO - joeynmt.training - Epoch  23, Step:    55300, Batch Loss:     1.395352, Tokens per Sec:    21725, Lr: 0.000300\n",
            "2021-05-04 16:56:10,431 - INFO - joeynmt.training - Epoch  23, Step:    55400, Batch Loss:     1.569578, Tokens per Sec:    21609, Lr: 0.000300\n",
            "2021-05-04 16:56:20,319 - INFO - joeynmt.training - Epoch  23, Step:    55500, Batch Loss:     1.534738, Tokens per Sec:    21566, Lr: 0.000300\n",
            "2021-05-04 16:56:30,263 - INFO - joeynmt.training - Epoch  23, Step:    55600, Batch Loss:     1.912783, Tokens per Sec:    21589, Lr: 0.000300\n",
            "2021-05-04 16:56:40,078 - INFO - joeynmt.training - Epoch  23, Step:    55700, Batch Loss:     1.275679, Tokens per Sec:    21671, Lr: 0.000300\n",
            "2021-05-04 16:56:50,083 - INFO - joeynmt.training - Epoch  23, Step:    55800, Batch Loss:     1.761040, Tokens per Sec:    21492, Lr: 0.000300\n",
            "2021-05-04 16:57:00,048 - INFO - joeynmt.training - Epoch  23, Step:    55900, Batch Loss:     1.652397, Tokens per Sec:    21836, Lr: 0.000300\n",
            "2021-05-04 16:57:09,985 - INFO - joeynmt.training - Epoch  23, Step:    56000, Batch Loss:     1.584521, Tokens per Sec:    21521, Lr: 0.000300\n",
            "2021-05-04 16:57:21,296 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:57:21,296 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:57:21,296 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:57:21,545 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:57:21,545 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:57:21,903 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:57:21,903 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:57:21,903 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:57:21,904 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:57:21,904 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:57:21,904 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:57:21,904 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:57:21,904 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da wani abu mai kyau don ya ceci rayuwar mai haƙuri , Allah zai “ datse ” miyagu domin mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 16:57:21,904 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:57:21,904 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:57:21,904 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:57:21,904 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:57:21,904 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:57:21,905 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:57:21,905 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:57:21,905 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi a kansa . ”\n",
            "2021-05-04 16:57:21,905 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    56000: bleu:  29.27, loss: 37218.1484, ppl:   4.3894, duration: 11.9197s\n",
            "2021-05-04 16:57:31,858 - INFO - joeynmt.training - Epoch  23, Step:    56100, Batch Loss:     1.324863, Tokens per Sec:    21192, Lr: 0.000300\n",
            "2021-05-04 16:57:41,777 - INFO - joeynmt.training - Epoch  23, Step:    56200, Batch Loss:     1.747943, Tokens per Sec:    21652, Lr: 0.000300\n",
            "2021-05-04 16:57:51,741 - INFO - joeynmt.training - Epoch  23, Step:    56300, Batch Loss:     1.721653, Tokens per Sec:    21774, Lr: 0.000300\n",
            "2021-05-04 16:58:01,616 - INFO - joeynmt.training - Epoch  23, Step:    56400, Batch Loss:     1.740433, Tokens per Sec:    21434, Lr: 0.000300\n",
            "2021-05-04 16:58:11,627 - INFO - joeynmt.training - Epoch  23, Step:    56500, Batch Loss:     1.435357, Tokens per Sec:    21510, Lr: 0.000300\n",
            "2021-05-04 16:58:21,527 - INFO - joeynmt.training - Epoch  23, Step:    56600, Batch Loss:     1.482083, Tokens per Sec:    21532, Lr: 0.000300\n",
            "2021-05-04 16:58:31,407 - INFO - joeynmt.training - Epoch  23, Step:    56700, Batch Loss:     1.797782, Tokens per Sec:    21474, Lr: 0.000300\n",
            "2021-05-04 16:58:41,347 - INFO - joeynmt.training - Epoch  23, Step:    56800, Batch Loss:     1.684814, Tokens per Sec:    21399, Lr: 0.000300\n",
            "2021-05-04 16:58:51,429 - INFO - joeynmt.training - Epoch  23, Step:    56900, Batch Loss:     1.375050, Tokens per Sec:    21835, Lr: 0.000300\n",
            "2021-05-04 16:59:01,283 - INFO - joeynmt.training - Epoch  23, Step:    57000, Batch Loss:     1.777112, Tokens per Sec:    21375, Lr: 0.000300\n",
            "2021-05-04 16:59:12,178 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 16:59:12,179 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 16:59:12,179 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 16:59:12,433 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 16:59:12,433 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 16:59:12,802 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 16:59:12,803 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 16:59:12,803 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 16:59:12,803 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da kyau kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 16:59:12,803 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 16:59:12,803 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 16:59:12,803 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 16:59:12,803 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya cire wani abu mai kyau don ya ceci rayuwar mai haƙuri , Allah zai “ datse ” mugayen mutane don su more rayuwa a duniya .\n",
            "2021-05-04 16:59:12,803 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 16:59:12,804 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 16:59:12,804 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:59:12,804 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 16:59:12,804 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 16:59:12,804 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 16:59:12,804 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 16:59:12,804 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi masa . ”\n",
            "2021-05-04 16:59:12,804 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    57000: bleu:  29.60, loss: 37015.5000, ppl:   4.3542, duration: 11.5206s\n",
            "2021-05-04 16:59:22,745 - INFO - joeynmt.training - Epoch  23, Step:    57100, Batch Loss:     1.691192, Tokens per Sec:    21921, Lr: 0.000300\n",
            "2021-05-04 16:59:32,606 - INFO - joeynmt.training - Epoch  23, Step:    57200, Batch Loss:     1.295387, Tokens per Sec:    21574, Lr: 0.000300\n",
            "2021-05-04 16:59:42,431 - INFO - joeynmt.training - Epoch  23, Step:    57300, Batch Loss:     1.881335, Tokens per Sec:    21365, Lr: 0.000300\n",
            "2021-05-04 16:59:52,418 - INFO - joeynmt.training - Epoch  23, Step:    57400, Batch Loss:     1.713363, Tokens per Sec:    21719, Lr: 0.000300\n",
            "2021-05-04 16:59:57,154 - INFO - joeynmt.training - Epoch  23: total training loss 4115.59\n",
            "2021-05-04 16:59:57,154 - INFO - joeynmt.training - EPOCH 24\n",
            "2021-05-04 17:00:02,692 - INFO - joeynmt.training - Epoch  24, Step:    57500, Batch Loss:     1.379839, Tokens per Sec:    20296, Lr: 0.000300\n",
            "2021-05-04 17:00:12,674 - INFO - joeynmt.training - Epoch  24, Step:    57600, Batch Loss:     1.479220, Tokens per Sec:    21994, Lr: 0.000300\n",
            "2021-05-04 17:00:22,709 - INFO - joeynmt.training - Epoch  24, Step:    57700, Batch Loss:     1.564495, Tokens per Sec:    21680, Lr: 0.000300\n",
            "2021-05-04 17:00:32,654 - INFO - joeynmt.training - Epoch  24, Step:    57800, Batch Loss:     1.610091, Tokens per Sec:    21842, Lr: 0.000300\n",
            "2021-05-04 17:00:42,537 - INFO - joeynmt.training - Epoch  24, Step:    57900, Batch Loss:     1.396949, Tokens per Sec:    21776, Lr: 0.000300\n",
            "2021-05-04 17:00:52,537 - INFO - joeynmt.training - Epoch  24, Step:    58000, Batch Loss:     1.671902, Tokens per Sec:    21600, Lr: 0.000300\n",
            "2021-05-04 17:01:03,257 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:01:03,257 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:01:03,257 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:01:03,877 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:01:03,877 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:01:03,877 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:01:03,877 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da daɗi kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 17:01:03,877 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:01:03,877 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:01:03,877 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:01:03,877 - INFO - joeynmt.training - \tHypothesis: Kamar yadda wani abin da zai iya cire ko kuma ya ceci rayuwar mai haƙuri , Allah zai “ datse ” miyagu don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 17:01:03,878 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:01:03,878 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:01:03,878 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:01:03,878 - INFO - joeynmt.training - \tHypothesis: Sun sami salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:01:03,878 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:01:03,878 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:01:03,878 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:01:03,878 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abu zan yi masa . ”\n",
            "2021-05-04 17:01:03,878 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    58000: bleu:  29.28, loss: 37019.1094, ppl:   4.3548, duration: 11.3413s\n",
            "2021-05-04 17:01:13,784 - INFO - joeynmt.training - Epoch  24, Step:    58100, Batch Loss:     1.775202, Tokens per Sec:    21437, Lr: 0.000300\n",
            "2021-05-04 17:01:23,700 - INFO - joeynmt.training - Epoch  24, Step:    58200, Batch Loss:     1.727493, Tokens per Sec:    21678, Lr: 0.000300\n",
            "2021-05-04 17:01:33,643 - INFO - joeynmt.training - Epoch  24, Step:    58300, Batch Loss:     1.401288, Tokens per Sec:    21395, Lr: 0.000300\n",
            "2021-05-04 17:01:43,652 - INFO - joeynmt.training - Epoch  24, Step:    58400, Batch Loss:     1.465777, Tokens per Sec:    21753, Lr: 0.000300\n",
            "2021-05-04 17:01:53,538 - INFO - joeynmt.training - Epoch  24, Step:    58500, Batch Loss:     1.581133, Tokens per Sec:    21546, Lr: 0.000300\n",
            "2021-05-04 17:02:03,454 - INFO - joeynmt.training - Epoch  24, Step:    58600, Batch Loss:     1.354737, Tokens per Sec:    21377, Lr: 0.000300\n",
            "2021-05-04 17:02:13,393 - INFO - joeynmt.training - Epoch  24, Step:    58700, Batch Loss:     0.969094, Tokens per Sec:    21798, Lr: 0.000300\n",
            "2021-05-04 17:02:23,350 - INFO - joeynmt.training - Epoch  24, Step:    58800, Batch Loss:     1.401664, Tokens per Sec:    21815, Lr: 0.000300\n",
            "2021-05-04 17:02:33,301 - INFO - joeynmt.training - Epoch  24, Step:    58900, Batch Loss:     1.532438, Tokens per Sec:    21372, Lr: 0.000300\n",
            "2021-05-04 17:02:43,167 - INFO - joeynmt.training - Epoch  24, Step:    59000, Batch Loss:     1.355289, Tokens per Sec:    21415, Lr: 0.000300\n",
            "2021-05-04 17:02:54,032 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:02:54,032 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:02:54,032 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:02:54,286 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 17:02:54,286 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 17:02:54,665 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:02:54,666 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:02:54,666 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:02:54,666 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da kyau kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 17:02:54,666 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:02:54,666 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:02:54,666 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:02:54,666 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da tuntuɓe da zai ceci rayuwar mai haƙuri , Allah zai “ datse ” miyagu don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 17:02:54,667 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:02:54,667 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:02:54,667 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:02:54,667 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:02:54,667 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:02:54,667 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:02:54,667 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:02:54,667 - INFO - joeynmt.training - \tHypothesis: * Zan yi masa alheri . ”\n",
            "2021-05-04 17:02:54,667 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    59000: bleu:  29.54, loss: 36932.1992, ppl:   4.3398, duration: 11.4998s\n",
            "2021-05-04 17:03:04,723 - INFO - joeynmt.training - Epoch  24, Step:    59100, Batch Loss:     1.721047, Tokens per Sec:    21861, Lr: 0.000300\n",
            "2021-05-04 17:03:14,638 - INFO - joeynmt.training - Epoch  24, Step:    59200, Batch Loss:     1.670432, Tokens per Sec:    21775, Lr: 0.000300\n",
            "2021-05-04 17:03:24,555 - INFO - joeynmt.training - Epoch  24, Step:    59300, Batch Loss:     1.314061, Tokens per Sec:    21747, Lr: 0.000300\n",
            "2021-05-04 17:03:34,442 - INFO - joeynmt.training - Epoch  24, Step:    59400, Batch Loss:     1.717740, Tokens per Sec:    21540, Lr: 0.000300\n",
            "2021-05-04 17:03:44,402 - INFO - joeynmt.training - Epoch  24, Step:    59500, Batch Loss:     1.741382, Tokens per Sec:    21404, Lr: 0.000300\n",
            "2021-05-04 17:03:54,334 - INFO - joeynmt.training - Epoch  24, Step:    59600, Batch Loss:     1.460224, Tokens per Sec:    21062, Lr: 0.000300\n",
            "2021-05-04 17:04:04,336 - INFO - joeynmt.training - Epoch  24, Step:    59700, Batch Loss:     1.740052, Tokens per Sec:    21988, Lr: 0.000300\n",
            "2021-05-04 17:04:14,264 - INFO - joeynmt.training - Epoch  24, Step:    59800, Batch Loss:     1.551512, Tokens per Sec:    21531, Lr: 0.000300\n",
            "2021-05-04 17:04:24,186 - INFO - joeynmt.training - Epoch  24, Step:    59900, Batch Loss:     1.770037, Tokens per Sec:    22008, Lr: 0.000300\n",
            "2021-05-04 17:04:27,935 - INFO - joeynmt.training - Epoch  24: total training loss 4072.36\n",
            "2021-05-04 17:04:27,935 - INFO - joeynmt.training - EPOCH 25\n",
            "2021-05-04 17:04:34,346 - INFO - joeynmt.training - Epoch  25, Step:    60000, Batch Loss:     1.440286, Tokens per Sec:    20349, Lr: 0.000300\n",
            "2021-05-04 17:04:45,180 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:04:45,180 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:04:45,180 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:04:45,434 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 17:04:45,434 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 17:04:45,838 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:04:45,839 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:04:45,839 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:04:45,839 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da kyau kuma tana da kyau ga dukan iyalinta .\n",
            "2021-05-04 17:04:45,839 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:04:45,839 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:04:45,839 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:04:45,839 - INFO - joeynmt.training - \tHypothesis: Kamar yadda wani gefen gefe zai iya cire tuntuɓe na gaske don ya ceci rayuwar mai haƙuri , Allah zai “ datse ” mugayen mutane don su more rayuwa a duniya .\n",
            "2021-05-04 17:04:45,839 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:04:45,839 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:04:45,839 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:04:45,839 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:04:45,839 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:04:45,840 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:04:45,840 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:04:45,840 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abu zan yi masa jinƙai . ”\n",
            "2021-05-04 17:04:45,840 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    60000: bleu:  29.34, loss: 36858.8008, ppl:   4.3272, duration: 11.4935s\n",
            "2021-05-04 17:04:55,812 - INFO - joeynmt.training - Epoch  25, Step:    60100, Batch Loss:     1.701102, Tokens per Sec:    21595, Lr: 0.000300\n",
            "2021-05-04 17:05:05,705 - INFO - joeynmt.training - Epoch  25, Step:    60200, Batch Loss:     1.799906, Tokens per Sec:    21321, Lr: 0.000300\n",
            "2021-05-04 17:05:15,657 - INFO - joeynmt.training - Epoch  25, Step:    60300, Batch Loss:     1.559779, Tokens per Sec:    21623, Lr: 0.000300\n",
            "2021-05-04 17:05:25,564 - INFO - joeynmt.training - Epoch  25, Step:    60400, Batch Loss:     1.726894, Tokens per Sec:    21240, Lr: 0.000300\n",
            "2021-05-04 17:05:35,586 - INFO - joeynmt.training - Epoch  25, Step:    60500, Batch Loss:     1.434466, Tokens per Sec:    21871, Lr: 0.000300\n",
            "2021-05-04 17:05:45,618 - INFO - joeynmt.training - Epoch  25, Step:    60600, Batch Loss:     1.716005, Tokens per Sec:    21346, Lr: 0.000300\n",
            "2021-05-04 17:05:55,767 - INFO - joeynmt.training - Epoch  25, Step:    60700, Batch Loss:     1.512060, Tokens per Sec:    21271, Lr: 0.000300\n",
            "2021-05-04 17:06:05,783 - INFO - joeynmt.training - Epoch  25, Step:    60800, Batch Loss:     1.554347, Tokens per Sec:    21616, Lr: 0.000300\n",
            "2021-05-04 17:06:15,763 - INFO - joeynmt.training - Epoch  25, Step:    60900, Batch Loss:     1.571328, Tokens per Sec:    21883, Lr: 0.000300\n",
            "2021-05-04 17:06:25,829 - INFO - joeynmt.training - Epoch  25, Step:    61000, Batch Loss:     1.828635, Tokens per Sec:    21676, Lr: 0.000300\n",
            "2021-05-04 17:06:36,321 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:06:36,321 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:06:36,322 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:06:36,922 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:06:36,922 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:06:36,922 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:06:36,922 - INFO - joeynmt.training - \tHypothesis: Iyalinta wuri ne mai kyau kuma mai kyau ga dukan iyalin .\n",
            "2021-05-04 17:06:36,922 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:06:36,922 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:06:36,922 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:06:36,922 - INFO - joeynmt.training - \tHypothesis: Kamar yadda abin da zai iya cire tuntuɓe ko kuma ya ceci rayuwar haƙuri , Allah zai “ datse ” miyagu don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 17:06:36,923 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:06:36,923 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:06:36,923 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:06:36,923 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:06:36,923 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:06:36,923 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:06:36,923 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:06:36,923 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abu zan yi masa suwu . ”\n",
            "2021-05-04 17:06:36,923 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    61000: bleu:  29.64, loss: 36870.9492, ppl:   4.3293, duration: 11.0935s\n",
            "2021-05-04 17:06:46,927 - INFO - joeynmt.training - Epoch  25, Step:    61100, Batch Loss:     1.695674, Tokens per Sec:    21576, Lr: 0.000300\n",
            "2021-05-04 17:06:56,801 - INFO - joeynmt.training - Epoch  25, Step:    61200, Batch Loss:     1.563813, Tokens per Sec:    21652, Lr: 0.000300\n",
            "2021-05-04 17:07:06,753 - INFO - joeynmt.training - Epoch  25, Step:    61300, Batch Loss:     1.793811, Tokens per Sec:    21470, Lr: 0.000300\n",
            "2021-05-04 17:07:16,654 - INFO - joeynmt.training - Epoch  25, Step:    61400, Batch Loss:     1.503145, Tokens per Sec:    21230, Lr: 0.000300\n",
            "2021-05-04 17:07:26,614 - INFO - joeynmt.training - Epoch  25, Step:    61500, Batch Loss:     1.768046, Tokens per Sec:    21568, Lr: 0.000300\n",
            "2021-05-04 17:07:36,472 - INFO - joeynmt.training - Epoch  25, Step:    61600, Batch Loss:     1.948119, Tokens per Sec:    21375, Lr: 0.000300\n",
            "2021-05-04 17:07:46,373 - INFO - joeynmt.training - Epoch  25, Step:    61700, Batch Loss:     1.389713, Tokens per Sec:    21154, Lr: 0.000300\n",
            "2021-05-04 17:07:56,321 - INFO - joeynmt.training - Epoch  25, Step:    61800, Batch Loss:     1.579595, Tokens per Sec:    21809, Lr: 0.000300\n",
            "2021-05-04 17:08:06,289 - INFO - joeynmt.training - Epoch  25, Step:    61900, Batch Loss:     1.529806, Tokens per Sec:    21697, Lr: 0.000300\n",
            "2021-05-04 17:08:16,196 - INFO - joeynmt.training - Epoch  25, Step:    62000, Batch Loss:     1.675435, Tokens per Sec:    21591, Lr: 0.000300\n",
            "2021-05-04 17:08:27,471 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:08:27,471 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:08:27,471 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:08:27,719 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 17:08:27,719 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 17:08:28,137 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:08:28,137 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:08:28,137 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:08:28,137 - INFO - joeynmt.training - \tHypothesis: Iyalinta wuri ne mai kyau kuma mai kyau ga dukan iyalin .\n",
            "2021-05-04 17:08:28,138 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:08:28,138 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:08:28,138 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:08:28,138 - INFO - joeynmt.training - \tHypothesis: Kamar yadda dukiya za ta iya cire tuntuɓe mai kyau don ya ceci rayuwar mutum , Allah zai “ datse ” miyagu domin mutane masu kirki za su more rayuwa a duniya .\n",
            "2021-05-04 17:08:28,138 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:08:28,138 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:08:28,138 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:08:28,138 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:08:28,138 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:08:28,139 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:08:28,139 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:08:28,139 - INFO - joeynmt.training - \tHypothesis: * Ta dukan tafarki zan yi masa jinƙai . ”\n",
            "2021-05-04 17:08:28,139 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    62000: bleu:  29.18, loss: 36691.8164, ppl:   4.2986, duration: 11.9424s\n",
            "2021-05-04 17:08:38,131 - INFO - joeynmt.training - Epoch  25, Step:    62100, Batch Loss:     1.452342, Tokens per Sec:    21573, Lr: 0.000300\n",
            "2021-05-04 17:08:48,140 - INFO - joeynmt.training - Epoch  25, Step:    62200, Batch Loss:     1.522384, Tokens per Sec:    21439, Lr: 0.000300\n",
            "2021-05-04 17:08:58,067 - INFO - joeynmt.training - Epoch  25, Step:    62300, Batch Loss:     1.525110, Tokens per Sec:    21618, Lr: 0.000300\n",
            "2021-05-04 17:09:08,011 - INFO - joeynmt.training - Epoch  25, Step:    62400, Batch Loss:     1.807076, Tokens per Sec:    21583, Lr: 0.000300\n",
            "2021-05-04 17:09:11,799 - INFO - joeynmt.training - Epoch  25: total training loss 4069.32\n",
            "2021-05-04 17:09:11,799 - INFO - joeynmt.training - EPOCH 26\n",
            "2021-05-04 17:09:18,101 - INFO - joeynmt.training - Epoch  26, Step:    62500, Batch Loss:     1.575590, Tokens per Sec:    20533, Lr: 0.000300\n",
            "2021-05-04 17:09:28,012 - INFO - joeynmt.training - Epoch  26, Step:    62600, Batch Loss:     1.627568, Tokens per Sec:    21669, Lr: 0.000300\n",
            "2021-05-04 17:09:37,866 - INFO - joeynmt.training - Epoch  26, Step:    62700, Batch Loss:     1.469008, Tokens per Sec:    21317, Lr: 0.000300\n",
            "2021-05-04 17:09:47,817 - INFO - joeynmt.training - Epoch  26, Step:    62800, Batch Loss:     1.567339, Tokens per Sec:    21548, Lr: 0.000300\n",
            "2021-05-04 17:09:57,732 - INFO - joeynmt.training - Epoch  26, Step:    62900, Batch Loss:     1.752795, Tokens per Sec:    21460, Lr: 0.000300\n",
            "2021-05-04 17:10:07,656 - INFO - joeynmt.training - Epoch  26, Step:    63000, Batch Loss:     1.432240, Tokens per Sec:    21532, Lr: 0.000300\n",
            "2021-05-04 17:10:18,486 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:10:18,486 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:10:18,486 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:10:18,734 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 17:10:18,734 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 17:10:19,093 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:10:19,093 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:10:19,093 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:10:19,094 - INFO - joeynmt.training - \tHypothesis: A gidanta wuri ne mai kyau kuma mai kyau ga dukan iyalinta .\n",
            "2021-05-04 17:10:19,094 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:10:19,094 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:10:19,094 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:10:19,094 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya cire tuntuɓe mai kyau don ya ceci rayuwar haƙuri , Allah zai “ datse ” miyagu don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 17:10:19,094 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:10:19,094 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:10:19,094 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:10:19,094 - INFO - joeynmt.training - \tHypothesis: Suna da salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:10:19,094 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:10:19,095 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:10:19,095 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:10:19,095 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan mutane zan yi masa biyayya . ”\n",
            "2021-05-04 17:10:19,095 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    63000: bleu:  29.30, loss: 36568.4688, ppl:   4.2775, duration: 11.4389s\n",
            "2021-05-04 17:10:29,069 - INFO - joeynmt.training - Epoch  26, Step:    63100, Batch Loss:     1.664260, Tokens per Sec:    21669, Lr: 0.000300\n",
            "2021-05-04 17:10:39,028 - INFO - joeynmt.training - Epoch  26, Step:    63200, Batch Loss:     1.858335, Tokens per Sec:    21721, Lr: 0.000300\n",
            "2021-05-04 17:10:49,036 - INFO - joeynmt.training - Epoch  26, Step:    63300, Batch Loss:     1.565335, Tokens per Sec:    21423, Lr: 0.000300\n",
            "2021-05-04 17:10:58,938 - INFO - joeynmt.training - Epoch  26, Step:    63400, Batch Loss:     1.821850, Tokens per Sec:    21467, Lr: 0.000300\n",
            "2021-05-04 17:11:08,935 - INFO - joeynmt.training - Epoch  26, Step:    63500, Batch Loss:     1.577181, Tokens per Sec:    21743, Lr: 0.000300\n",
            "2021-05-04 17:11:18,898 - INFO - joeynmt.training - Epoch  26, Step:    63600, Batch Loss:     1.727123, Tokens per Sec:    21424, Lr: 0.000300\n",
            "2021-05-04 17:11:28,817 - INFO - joeynmt.training - Epoch  26, Step:    63700, Batch Loss:     1.604100, Tokens per Sec:    21657, Lr: 0.000300\n",
            "2021-05-04 17:11:38,815 - INFO - joeynmt.training - Epoch  26, Step:    63800, Batch Loss:     1.490348, Tokens per Sec:    21728, Lr: 0.000300\n",
            "2021-05-04 17:11:48,716 - INFO - joeynmt.training - Epoch  26, Step:    63900, Batch Loss:     1.597195, Tokens per Sec:    21336, Lr: 0.000300\n",
            "2021-05-04 17:11:58,635 - INFO - joeynmt.training - Epoch  26, Step:    64000, Batch Loss:     1.596835, Tokens per Sec:    21355, Lr: 0.000300\n",
            "2021-05-04 17:12:09,007 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:12:09,007 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:12:09,007 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:12:09,269 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 17:12:09,269 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 17:12:09,649 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:12:09,650 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:12:09,650 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:12:09,650 - INFO - joeynmt.training - \tHypothesis: Iyalinta wuri ne mai kyau kuma mai kyau ga dukan iyalinta .\n",
            "2021-05-04 17:12:09,650 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:12:09,650 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:12:09,650 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:12:09,650 - INFO - joeynmt.training - \tHypothesis: Kamar yadda wani gefen da zai iya cire tuntuɓe mai kyau don ya ceci rayuwar mai haƙuri , Allah zai “ datse ” mugayen mutane don su more rayuwa a duniya .\n",
            "2021-05-04 17:12:09,650 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:12:09,650 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:12:09,650 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:12:09,650 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:12:09,651 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:12:09,651 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:12:09,651 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:12:09,651 - INFO - joeynmt.training - \tHypothesis: * Ta dukan abin da zan yi a bisansa . ”\n",
            "2021-05-04 17:12:09,651 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    64000: bleu:  29.76, loss: 36545.1602, ppl:   4.2736, duration: 11.0160s\n",
            "2021-05-04 17:12:19,569 - INFO - joeynmt.training - Epoch  26, Step:    64100, Batch Loss:     1.586939, Tokens per Sec:    21803, Lr: 0.000300\n",
            "2021-05-04 17:12:29,521 - INFO - joeynmt.training - Epoch  26, Step:    64200, Batch Loss:     1.357806, Tokens per Sec:    21209, Lr: 0.000300\n",
            "2021-05-04 17:12:39,407 - INFO - joeynmt.training - Epoch  26, Step:    64300, Batch Loss:     1.843574, Tokens per Sec:    21795, Lr: 0.000300\n",
            "2021-05-04 17:12:49,353 - INFO - joeynmt.training - Epoch  26, Step:    64400, Batch Loss:     1.648648, Tokens per Sec:    21647, Lr: 0.000300\n",
            "2021-05-04 17:12:59,298 - INFO - joeynmt.training - Epoch  26, Step:    64500, Batch Loss:     1.368725, Tokens per Sec:    21418, Lr: 0.000300\n",
            "2021-05-04 17:13:09,290 - INFO - joeynmt.training - Epoch  26, Step:    64600, Batch Loss:     1.981081, Tokens per Sec:    21490, Lr: 0.000300\n",
            "2021-05-04 17:13:19,174 - INFO - joeynmt.training - Epoch  26, Step:    64700, Batch Loss:     1.923169, Tokens per Sec:    21605, Lr: 0.000300\n",
            "2021-05-04 17:13:29,150 - INFO - joeynmt.training - Epoch  26, Step:    64800, Batch Loss:     1.752982, Tokens per Sec:    22124, Lr: 0.000300\n",
            "2021-05-04 17:13:39,096 - INFO - joeynmt.training - Epoch  26, Step:    64900, Batch Loss:     1.319891, Tokens per Sec:    21612, Lr: 0.000300\n",
            "2021-05-04 17:13:42,928 - INFO - joeynmt.training - Epoch  26: total training loss 4047.98\n",
            "2021-05-04 17:13:42,928 - INFO - joeynmt.training - EPOCH 27\n",
            "2021-05-04 17:13:49,274 - INFO - joeynmt.training - Epoch  27, Step:    65000, Batch Loss:     1.789174, Tokens per Sec:    20166, Lr: 0.000300\n",
            "2021-05-04 17:14:01,114 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:14:01,114 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:14:01,115 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:14:01,723 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:14:01,723 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:14:01,723 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:14:01,723 - INFO - joeynmt.training - \tHypothesis: A gidanta , gidanta wuri ne mai kyau kuma mai kyau ga dukan iyalin .\n",
            "2021-05-04 17:14:01,723 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:14:01,724 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:14:01,724 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:14:01,724 - INFO - joeynmt.training - \tHypothesis: Kamar yadda wani abin da zai iya cire tuntuɓe mai kyau don ya ceci rayuwar mai haƙuri , Allah zai “ datse ” miyagu don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 17:14:01,724 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:14:01,724 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:14:01,724 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:14:01,724 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:14:01,724 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:14:01,725 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:14:01,725 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:14:01,725 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abin da zan yi a bisansa . ”\n",
            "2021-05-04 17:14:01,725 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    65000: bleu:  29.75, loss: 36580.7773, ppl:   4.2796, duration: 12.4507s\n",
            "2021-05-04 17:14:11,780 - INFO - joeynmt.training - Epoch  27, Step:    65100, Batch Loss:     1.810323, Tokens per Sec:    21737, Lr: 0.000300\n",
            "2021-05-04 17:14:21,801 - INFO - joeynmt.training - Epoch  27, Step:    65200, Batch Loss:     1.827492, Tokens per Sec:    21864, Lr: 0.000300\n",
            "2021-05-04 17:14:31,651 - INFO - joeynmt.training - Epoch  27, Step:    65300, Batch Loss:     1.897475, Tokens per Sec:    21159, Lr: 0.000300\n",
            "2021-05-04 17:14:41,649 - INFO - joeynmt.training - Epoch  27, Step:    65400, Batch Loss:     1.265861, Tokens per Sec:    21484, Lr: 0.000300\n",
            "2021-05-04 17:14:51,591 - INFO - joeynmt.training - Epoch  27, Step:    65500, Batch Loss:     1.594644, Tokens per Sec:    21122, Lr: 0.000300\n",
            "2021-05-04 17:15:01,483 - INFO - joeynmt.training - Epoch  27, Step:    65600, Batch Loss:     1.548988, Tokens per Sec:    21465, Lr: 0.000300\n",
            "2021-05-04 17:15:11,408 - INFO - joeynmt.training - Epoch  27, Step:    65700, Batch Loss:     1.384685, Tokens per Sec:    21493, Lr: 0.000300\n",
            "2021-05-04 17:15:21,326 - INFO - joeynmt.training - Epoch  27, Step:    65800, Batch Loss:     1.622060, Tokens per Sec:    21487, Lr: 0.000300\n",
            "2021-05-04 17:15:31,227 - INFO - joeynmt.training - Epoch  27, Step:    65900, Batch Loss:     1.636160, Tokens per Sec:    21448, Lr: 0.000300\n",
            "2021-05-04 17:15:41,149 - INFO - joeynmt.training - Epoch  27, Step:    66000, Batch Loss:     1.709029, Tokens per Sec:    21679, Lr: 0.000300\n",
            "2021-05-04 17:15:52,232 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:15:52,232 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:15:52,232 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:15:52,487 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 17:15:52,487 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 17:15:52,914 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:15:52,915 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:15:52,915 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:15:52,915 - INFO - joeynmt.training - \tHypothesis: Gidanta wuri ne mai kyau kuma mai kyau ga dukan iyalin .\n",
            "2021-05-04 17:15:52,915 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:15:52,915 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:15:52,915 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:15:52,915 - INFO - joeynmt.training - \tHypothesis: Kamar yadda wani gefen gefen zai iya cire tuntuɓe mai kyau don ya ceci rayuwar mutum , Allah zai “ datse ” mugayen mutane masu kirki don su more rayuwa a duniya .\n",
            "2021-05-04 17:15:52,915 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:15:52,915 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:15:52,915 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:15:52,916 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:15:52,916 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:15:52,916 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:15:52,916 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:15:52,916 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abu zan yi masa jinkiri . ”\n",
            "2021-05-04 17:15:52,916 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    66000: bleu:  30.10, loss: 36373.3164, ppl:   4.2445, duration: 11.7673s\n",
            "2021-05-04 17:16:02,845 - INFO - joeynmt.training - Epoch  27, Step:    66100, Batch Loss:     1.427861, Tokens per Sec:    21858, Lr: 0.000300\n",
            "2021-05-04 17:16:12,852 - INFO - joeynmt.training - Epoch  27, Step:    66200, Batch Loss:     1.591483, Tokens per Sec:    21585, Lr: 0.000300\n",
            "2021-05-04 17:16:22,801 - INFO - joeynmt.training - Epoch  27, Step:    66300, Batch Loss:     1.654229, Tokens per Sec:    21407, Lr: 0.000300\n",
            "2021-05-04 17:16:32,784 - INFO - joeynmt.training - Epoch  27, Step:    66400, Batch Loss:     1.716023, Tokens per Sec:    21363, Lr: 0.000300\n",
            "2021-05-04 17:16:42,744 - INFO - joeynmt.training - Epoch  27, Step:    66500, Batch Loss:     1.789463, Tokens per Sec:    21898, Lr: 0.000300\n",
            "2021-05-04 17:16:52,781 - INFO - joeynmt.training - Epoch  27, Step:    66600, Batch Loss:     1.691080, Tokens per Sec:    21828, Lr: 0.000300\n",
            "2021-05-04 17:17:02,659 - INFO - joeynmt.training - Epoch  27, Step:    66700, Batch Loss:     1.711130, Tokens per Sec:    21771, Lr: 0.000300\n",
            "2021-05-04 17:17:12,709 - INFO - joeynmt.training - Epoch  27, Step:    66800, Batch Loss:     1.621103, Tokens per Sec:    21867, Lr: 0.000300\n",
            "2021-05-04 17:17:22,624 - INFO - joeynmt.training - Epoch  27, Step:    66900, Batch Loss:     1.590670, Tokens per Sec:    21565, Lr: 0.000300\n",
            "2021-05-04 17:17:32,638 - INFO - joeynmt.training - Epoch  27, Step:    67000, Batch Loss:     1.754980, Tokens per Sec:    22001, Lr: 0.000300\n",
            "2021-05-04 17:17:43,502 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:17:43,502 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:17:43,502 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:17:43,761 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 17:17:43,761 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 17:17:44,130 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:17:44,131 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:17:44,131 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:17:44,131 - INFO - joeynmt.training - \tHypothesis: A gidanta wuri ne mai kyau kuma mai kyau ga dukan iyalinta .\n",
            "2021-05-04 17:17:44,131 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:17:44,131 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:17:44,131 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:17:44,131 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya cire wani abu mai kyau don ya ceci rayuwar mutum , Allah zai “ datse ” miyagu don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 17:17:44,131 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:17:44,132 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:17:44,132 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:17:44,132 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:17:44,132 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:17:44,132 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:17:44,132 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:17:44,132 - INFO - joeynmt.training - \tHypothesis: * Ta dukan al’amuran da zan yi masa . ”\n",
            "2021-05-04 17:17:44,132 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    67000: bleu:  30.00, loss: 36227.0117, ppl:   4.2199, duration: 11.4941s\n",
            "2021-05-04 17:17:54,021 - INFO - joeynmt.training - Epoch  27, Step:    67100, Batch Loss:     1.625993, Tokens per Sec:    21414, Lr: 0.000300\n",
            "2021-05-04 17:18:03,987 - INFO - joeynmt.training - Epoch  27, Step:    67200, Batch Loss:     1.664670, Tokens per Sec:    21257, Lr: 0.000300\n",
            "2021-05-04 17:18:13,994 - INFO - joeynmt.training - Epoch  27, Step:    67300, Batch Loss:     1.355492, Tokens per Sec:    21742, Lr: 0.000300\n",
            "2021-05-04 17:18:23,916 - INFO - joeynmt.training - Epoch  27, Step:    67400, Batch Loss:     1.572567, Tokens per Sec:    21511, Lr: 0.000300\n",
            "2021-05-04 17:18:27,348 - INFO - joeynmt.training - Epoch  27: total training loss 4021.19\n",
            "2021-05-04 17:18:27,349 - INFO - joeynmt.training - EPOCH 28\n",
            "2021-05-04 17:18:34,122 - INFO - joeynmt.training - Epoch  28, Step:    67500, Batch Loss:     1.857735, Tokens per Sec:    20792, Lr: 0.000300\n",
            "2021-05-04 17:18:44,212 - INFO - joeynmt.training - Epoch  28, Step:    67600, Batch Loss:     1.358644, Tokens per Sec:    21540, Lr: 0.000300\n",
            "2021-05-04 17:18:54,240 - INFO - joeynmt.training - Epoch  28, Step:    67700, Batch Loss:     1.529093, Tokens per Sec:    21862, Lr: 0.000300\n",
            "2021-05-04 17:19:04,203 - INFO - joeynmt.training - Epoch  28, Step:    67800, Batch Loss:     1.531490, Tokens per Sec:    21461, Lr: 0.000300\n",
            "2021-05-04 17:19:14,220 - INFO - joeynmt.training - Epoch  28, Step:    67900, Batch Loss:     1.749499, Tokens per Sec:    21139, Lr: 0.000300\n",
            "2021-05-04 17:19:24,221 - INFO - joeynmt.training - Epoch  28, Step:    68000, Batch Loss:     1.730994, Tokens per Sec:    21549, Lr: 0.000300\n",
            "2021-05-04 17:19:34,577 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:19:34,577 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:19:34,577 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:19:35,227 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:19:35,227 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:19:35,227 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:19:35,227 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da kyau kuma tana da kyau ga dukan iyalinta .\n",
            "2021-05-04 17:19:35,227 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:19:35,228 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:19:35,228 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:19:35,228 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya cire tuntuɓe mai kyau ko kuma ya ceci rayuwar mai haƙuri , Allah zai “ datse ” miyagu domin mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 17:19:35,228 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:19:35,228 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:19:35,228 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:19:35,228 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:19:35,228 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:19:35,228 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:19:35,229 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:19:35,229 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abu zan yi masa horo . ”\n",
            "2021-05-04 17:19:35,229 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    68000: bleu:  30.19, loss: 36437.5156, ppl:   4.2553, duration: 11.0078s\n",
            "2021-05-04 17:19:45,233 - INFO - joeynmt.training - Epoch  28, Step:    68100, Batch Loss:     1.307721, Tokens per Sec:    21527, Lr: 0.000300\n",
            "2021-05-04 17:19:55,180 - INFO - joeynmt.training - Epoch  28, Step:    68200, Batch Loss:     1.708248, Tokens per Sec:    21746, Lr: 0.000300\n",
            "2021-05-04 17:20:05,132 - INFO - joeynmt.training - Epoch  28, Step:    68300, Batch Loss:     1.550951, Tokens per Sec:    21963, Lr: 0.000300\n",
            "2021-05-04 17:20:15,172 - INFO - joeynmt.training - Epoch  28, Step:    68400, Batch Loss:     1.741435, Tokens per Sec:    21614, Lr: 0.000300\n",
            "2021-05-04 17:20:25,159 - INFO - joeynmt.training - Epoch  28, Step:    68500, Batch Loss:     1.346187, Tokens per Sec:    21773, Lr: 0.000300\n",
            "2021-05-04 17:20:35,040 - INFO - joeynmt.training - Epoch  28, Step:    68600, Batch Loss:     1.714166, Tokens per Sec:    21796, Lr: 0.000300\n",
            "2021-05-04 17:20:45,063 - INFO - joeynmt.training - Epoch  28, Step:    68700, Batch Loss:     1.314036, Tokens per Sec:    21576, Lr: 0.000300\n",
            "2021-05-04 17:20:54,966 - INFO - joeynmt.training - Epoch  28, Step:    68800, Batch Loss:     1.464921, Tokens per Sec:    21269, Lr: 0.000300\n",
            "2021-05-04 17:21:04,809 - INFO - joeynmt.training - Epoch  28, Step:    68900, Batch Loss:     1.911710, Tokens per Sec:    21328, Lr: 0.000300\n",
            "2021-05-04 17:21:14,807 - INFO - joeynmt.training - Epoch  28, Step:    69000, Batch Loss:     1.688747, Tokens per Sec:    21936, Lr: 0.000300\n",
            "2021-05-04 17:21:25,510 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:21:25,511 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:21:25,511 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:21:25,759 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 17:21:25,759 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 17:21:26,171 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:21:26,171 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:21:26,171 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:21:26,171 - INFO - joeynmt.training - \tHypothesis: Iyalinta wuri ne mai kyau kuma mai kyau ga dukan iyalin .\n",
            "2021-05-04 17:21:26,171 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:21:26,171 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:21:26,171 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:21:26,171 - INFO - joeynmt.training - \tHypothesis: Kamar yadda wani gefen gefen zai iya cire tuntuɓe mai zafi don ya ceci rayuwar mutum na haƙuri , Allah zai “ datse ” miyagu domin mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 17:21:26,171 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:21:26,172 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:21:26,172 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:21:26,172 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:21:26,172 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:21:26,172 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:21:26,172 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:21:26,172 - INFO - joeynmt.training - \tHypothesis: * Ta dukan al’amuran da zan yi a bisansa . ”\n",
            "2021-05-04 17:21:26,172 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    69000: bleu:  30.23, loss: 36196.9766, ppl:   4.2149, duration: 11.3646s\n",
            "2021-05-04 17:21:36,067 - INFO - joeynmt.training - Epoch  28, Step:    69100, Batch Loss:     1.536000, Tokens per Sec:    21104, Lr: 0.000300\n",
            "2021-05-04 17:21:46,060 - INFO - joeynmt.training - Epoch  28, Step:    69200, Batch Loss:     1.597770, Tokens per Sec:    21487, Lr: 0.000300\n",
            "2021-05-04 17:21:55,996 - INFO - joeynmt.training - Epoch  28, Step:    69300, Batch Loss:     1.725766, Tokens per Sec:    21580, Lr: 0.000300\n",
            "2021-05-04 17:22:05,938 - INFO - joeynmt.training - Epoch  28, Step:    69400, Batch Loss:     1.439678, Tokens per Sec:    21713, Lr: 0.000300\n",
            "2021-05-04 17:22:15,809 - INFO - joeynmt.training - Epoch  28, Step:    69500, Batch Loss:     1.556984, Tokens per Sec:    21513, Lr: 0.000300\n",
            "2021-05-04 17:22:25,690 - INFO - joeynmt.training - Epoch  28, Step:    69600, Batch Loss:     1.552019, Tokens per Sec:    21415, Lr: 0.000300\n",
            "2021-05-04 17:22:35,638 - INFO - joeynmt.training - Epoch  28, Step:    69700, Batch Loss:     1.365996, Tokens per Sec:    21535, Lr: 0.000300\n",
            "2021-05-04 17:22:45,589 - INFO - joeynmt.training - Epoch  28, Step:    69800, Batch Loss:     1.566308, Tokens per Sec:    21706, Lr: 0.000300\n",
            "2021-05-04 17:22:55,518 - INFO - joeynmt.training - Epoch  28, Step:    69900, Batch Loss:     1.463457, Tokens per Sec:    21342, Lr: 0.000300\n",
            "2021-05-04 17:22:58,398 - INFO - joeynmt.training - Epoch  28: total training loss 3996.56\n",
            "2021-05-04 17:22:58,399 - INFO - joeynmt.training - EPOCH 29\n",
            "2021-05-04 17:23:05,726 - INFO - joeynmt.training - Epoch  29, Step:    70000, Batch Loss:     1.439786, Tokens per Sec:    20627, Lr: 0.000300\n",
            "2021-05-04 17:23:16,417 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:23:16,417 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:23:16,418 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:23:16,666 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 17:23:16,666 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 17:23:17,066 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:23:17,066 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:23:17,066 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:23:17,066 - INFO - joeynmt.training - \tHypothesis: Iyalinta tana da kyau kuma tana da kyau ga dukan iyalin .\n",
            "2021-05-04 17:23:17,066 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:23:17,067 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:23:17,067 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:23:17,067 - INFO - joeynmt.training - \tHypothesis: Kamar yadda wani gefen gefen da zai iya cire wani abu mai kyau don ya ceci rayuwar mai haƙuri , Allah zai “ datse ” miyagu domin mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 17:23:17,067 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:23:17,067 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:23:17,067 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:23:17,067 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:23:17,067 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:23:17,067 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:23:17,067 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:23:17,067 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan abu zan yi masa jinƙai . ”\n",
            "2021-05-04 17:23:17,067 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    70000: bleu:  30.00, loss: 36142.8164, ppl:   4.2058, duration: 11.3406s\n",
            "2021-05-04 17:23:27,094 - INFO - joeynmt.training - Epoch  29, Step:    70100, Batch Loss:     1.583239, Tokens per Sec:    21683, Lr: 0.000300\n",
            "2021-05-04 17:23:36,981 - INFO - joeynmt.training - Epoch  29, Step:    70200, Batch Loss:     1.562262, Tokens per Sec:    21102, Lr: 0.000300\n",
            "2021-05-04 17:23:46,889 - INFO - joeynmt.training - Epoch  29, Step:    70300, Batch Loss:     1.282132, Tokens per Sec:    21137, Lr: 0.000300\n",
            "2021-05-04 17:23:56,869 - INFO - joeynmt.training - Epoch  29, Step:    70400, Batch Loss:     1.901215, Tokens per Sec:    21651, Lr: 0.000300\n",
            "2021-05-04 17:24:06,724 - INFO - joeynmt.training - Epoch  29, Step:    70500, Batch Loss:     1.545987, Tokens per Sec:    21326, Lr: 0.000300\n",
            "2021-05-04 17:24:16,657 - INFO - joeynmt.training - Epoch  29, Step:    70600, Batch Loss:     1.532688, Tokens per Sec:    21471, Lr: 0.000300\n",
            "2021-05-04 17:24:26,620 - INFO - joeynmt.training - Epoch  29, Step:    70700, Batch Loss:     1.640704, Tokens per Sec:    21555, Lr: 0.000300\n",
            "2021-05-04 17:24:36,655 - INFO - joeynmt.training - Epoch  29, Step:    70800, Batch Loss:     1.576110, Tokens per Sec:    21488, Lr: 0.000300\n",
            "2021-05-04 17:24:46,622 - INFO - joeynmt.training - Epoch  29, Step:    70900, Batch Loss:     1.702978, Tokens per Sec:    21340, Lr: 0.000300\n",
            "2021-05-04 17:24:56,553 - INFO - joeynmt.training - Epoch  29, Step:    71000, Batch Loss:     1.642469, Tokens per Sec:    21499, Lr: 0.000300\n",
            "2021-05-04 17:25:07,211 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:25:07,211 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:25:07,211 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:25:07,830 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:25:07,830 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:25:07,830 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:25:07,830 - INFO - joeynmt.training - \tHypothesis: gidanta wuri ne mai kyau kuma mai kyau ga dukan iyalin .\n",
            "2021-05-04 17:25:07,830 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:25:07,830 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:25:07,830 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:25:07,830 - INFO - joeynmt.training - \tHypothesis: Kamar yadda kewaye zai iya kawar da tuntuɓe mai kyau don ya ceci rayuwar mai haƙuri , Allah zai “ datse ” miyagu domin mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 17:25:07,830 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:25:07,831 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:25:07,831 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:25:07,831 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:25:07,831 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:25:07,831 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:25:07,831 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:25:07,831 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi masa . ”\n",
            "2021-05-04 17:25:07,831 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    71000: bleu:  29.86, loss: 36166.7266, ppl:   4.2098, duration: 11.2780s\n",
            "2021-05-04 17:25:17,742 - INFO - joeynmt.training - Epoch  29, Step:    71100, Batch Loss:     1.796915, Tokens per Sec:    21261, Lr: 0.000300\n",
            "2021-05-04 17:25:27,693 - INFO - joeynmt.training - Epoch  29, Step:    71200, Batch Loss:     1.545036, Tokens per Sec:    21912, Lr: 0.000300\n",
            "2021-05-04 17:25:37,638 - INFO - joeynmt.training - Epoch  29, Step:    71300, Batch Loss:     1.680763, Tokens per Sec:    21481, Lr: 0.000300\n",
            "2021-05-04 17:25:47,493 - INFO - joeynmt.training - Epoch  29, Step:    71400, Batch Loss:     1.916138, Tokens per Sec:    21244, Lr: 0.000300\n",
            "2021-05-04 17:25:57,351 - INFO - joeynmt.training - Epoch  29, Step:    71500, Batch Loss:     1.870258, Tokens per Sec:    21422, Lr: 0.000300\n",
            "2021-05-04 17:26:07,218 - INFO - joeynmt.training - Epoch  29, Step:    71600, Batch Loss:     1.509502, Tokens per Sec:    21362, Lr: 0.000300\n",
            "2021-05-04 17:26:17,233 - INFO - joeynmt.training - Epoch  29, Step:    71700, Batch Loss:     1.612948, Tokens per Sec:    21555, Lr: 0.000300\n",
            "2021-05-04 17:26:27,179 - INFO - joeynmt.training - Epoch  29, Step:    71800, Batch Loss:     1.621314, Tokens per Sec:    21526, Lr: 0.000300\n",
            "2021-05-04 17:26:37,090 - INFO - joeynmt.training - Epoch  29, Step:    71900, Batch Loss:     1.671482, Tokens per Sec:    22630, Lr: 0.000300\n",
            "2021-05-04 17:26:46,864 - INFO - joeynmt.training - Epoch  29, Step:    72000, Batch Loss:     1.590056, Tokens per Sec:    21788, Lr: 0.000300\n",
            "2021-05-04 17:26:57,526 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:26:57,526 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:26:57,526 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:26:57,779 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-05-04 17:26:57,779 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-05-04 17:26:58,727 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:26:58,728 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:26:58,728 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:26:58,728 - INFO - joeynmt.training - \tHypothesis: A gidanta , gidanta wuri ne mai kyau kuma mai kyau ne ga dukan iyalin .\n",
            "2021-05-04 17:26:58,728 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:26:58,728 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:26:58,728 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:26:58,728 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da mugun tunani don ya ceci rayuwar mutum ta haƙuri , Allah zai “ datse ” mugayen mutane don su more rayuwa a duniya .\n",
            "2021-05-04 17:26:58,728 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:26:58,729 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:26:58,729 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:26:58,729 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:26:58,729 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:26:58,729 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:26:58,729 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:26:58,729 - INFO - joeynmt.training - \tHypothesis: * Ta wurin dukan abin da zan yi masa . ”\n",
            "2021-05-04 17:26:58,729 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    72000: bleu:  30.05, loss: 35990.4727, ppl:   4.1804, duration: 11.8645s\n",
            "2021-05-04 17:27:08,674 - INFO - joeynmt.training - Epoch  29, Step:    72100, Batch Loss:     1.944429, Tokens per Sec:    22062, Lr: 0.000300\n",
            "2021-05-04 17:27:18,560 - INFO - joeynmt.training - Epoch  29, Step:    72200, Batch Loss:     1.497853, Tokens per Sec:    21909, Lr: 0.000300\n",
            "2021-05-04 17:27:28,535 - INFO - joeynmt.training - Epoch  29, Step:    72300, Batch Loss:     1.698526, Tokens per Sec:    22229, Lr: 0.000300\n",
            "2021-05-04 17:27:38,421 - INFO - joeynmt.training - Epoch  29, Step:    72400, Batch Loss:     1.597340, Tokens per Sec:    21756, Lr: 0.000300\n",
            "2021-05-04 17:27:41,246 - INFO - joeynmt.training - Epoch  29: total training loss 3985.10\n",
            "2021-05-04 17:27:41,246 - INFO - joeynmt.training - EPOCH 30\n",
            "2021-05-04 17:27:48,567 - INFO - joeynmt.training - Epoch  30, Step:    72500, Batch Loss:     1.568395, Tokens per Sec:    21151, Lr: 0.000300\n",
            "2021-05-04 17:27:58,551 - INFO - joeynmt.training - Epoch  30, Step:    72600, Batch Loss:     1.366800, Tokens per Sec:    21653, Lr: 0.000300\n",
            "2021-05-04 17:28:08,453 - INFO - joeynmt.training - Epoch  30, Step:    72700, Batch Loss:     1.639299, Tokens per Sec:    21795, Lr: 0.000300\n",
            "2021-05-04 17:28:18,265 - INFO - joeynmt.training - Epoch  30, Step:    72800, Batch Loss:     1.865153, Tokens per Sec:    21669, Lr: 0.000300\n",
            "2021-05-04 17:28:28,044 - INFO - joeynmt.training - Epoch  30, Step:    72900, Batch Loss:     1.564563, Tokens per Sec:    21661, Lr: 0.000300\n",
            "2021-05-04 17:28:37,808 - INFO - joeynmt.training - Epoch  30, Step:    73000, Batch Loss:     1.592453, Tokens per Sec:    20836, Lr: 0.000300\n",
            "2021-05-04 17:28:48,468 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:28:48,468 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:28:48,468 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:28:49,049 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:28:49,049 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:28:49,049 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:28:49,049 - INFO - joeynmt.training - \tHypothesis: A gidanta , gidanta wuri ne mai kyau kuma mai kyau ne ga dukan iyalin .\n",
            "2021-05-04 17:28:49,050 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:28:49,050 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:28:49,050 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:28:49,050 - INFO - joeynmt.training - \tHypothesis: Kamar yadda za a iya kawar da mugun abu don a ceci rayuwar mutum , Allah zai “ datse ” miyagu don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 17:28:49,050 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:28:49,050 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:28:49,050 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:28:49,050 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:28:49,050 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:28:49,051 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:28:49,051 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:28:49,051 - INFO - joeynmt.training - \tHypothesis: * A dukan hanya zan yi juyayi a kansa . ”\n",
            "2021-05-04 17:28:49,051 - INFO - joeynmt.training - Validation result (greedy) at epoch  30, step    73000: bleu:  30.29, loss: 36419.9141, ppl:   4.2524, duration: 11.2421s\n",
            "2021-05-04 17:28:58,979 - INFO - joeynmt.training - Epoch  30, Step:    73100, Batch Loss:     1.570551, Tokens per Sec:    22353, Lr: 0.000300\n",
            "2021-05-04 17:29:08,811 - INFO - joeynmt.training - Epoch  30, Step:    73200, Batch Loss:     1.701247, Tokens per Sec:    21620, Lr: 0.000300\n",
            "2021-05-04 17:29:18,887 - INFO - joeynmt.training - Epoch  30, Step:    73300, Batch Loss:     1.709316, Tokens per Sec:    22382, Lr: 0.000300\n",
            "2021-05-04 17:29:28,718 - INFO - joeynmt.training - Epoch  30, Step:    73400, Batch Loss:     1.834888, Tokens per Sec:    21556, Lr: 0.000300\n",
            "2021-05-04 17:29:38,484 - INFO - joeynmt.training - Epoch  30, Step:    73500, Batch Loss:     1.559858, Tokens per Sec:    21885, Lr: 0.000300\n",
            "2021-05-04 17:29:48,364 - INFO - joeynmt.training - Epoch  30, Step:    73600, Batch Loss:     1.657478, Tokens per Sec:    21839, Lr: 0.000300\n",
            "2021-05-04 17:29:58,315 - INFO - joeynmt.training - Epoch  30, Step:    73700, Batch Loss:     1.837882, Tokens per Sec:    21803, Lr: 0.000300\n",
            "2021-05-04 17:30:08,060 - INFO - joeynmt.training - Epoch  30, Step:    73800, Batch Loss:     1.470000, Tokens per Sec:    21232, Lr: 0.000300\n",
            "2021-05-04 17:30:17,954 - INFO - joeynmt.training - Epoch  30, Step:    73900, Batch Loss:     1.607312, Tokens per Sec:    22090, Lr: 0.000300\n",
            "2021-05-04 17:30:27,699 - INFO - joeynmt.training - Epoch  30, Step:    74000, Batch Loss:     1.744756, Tokens per Sec:    21705, Lr: 0.000300\n",
            "2021-05-04 17:30:38,681 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:30:38,681 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:30:38,682 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:30:39,323 - INFO - joeynmt.training - Example #0\n",
            "2021-05-04 17:30:39,323 - INFO - joeynmt.training - \tSource:     Her home is a pleasant and comfortable place for the entire family .\n",
            "2021-05-04 17:30:39,323 - INFO - joeynmt.training - \tReference:  14 : 1 ) Gidanta wuri ne na farin ciki da kwanciyar hankali ga dukan iyalin .\n",
            "2021-05-04 17:30:39,324 - INFO - joeynmt.training - \tHypothesis: Iyalinta wuri ne mai kyau kuma mai kyau da dukan iyalin suke da shi .\n",
            "2021-05-04 17:30:39,324 - INFO - joeynmt.training - Example #1\n",
            "2021-05-04 17:30:39,324 - INFO - joeynmt.training - \tSource:     Just as a surgeon might remove a cancerous tumor to save a patient’s life , God will “ cut off ” the wicked so that good people can truly enjoy life on earth .\n",
            "2021-05-04 17:30:39,324 - INFO - joeynmt.training - \tReference:  Za a iya kwatanta wannan da yadda likitar fiɗa yakan yi wa marar lafiya aiki saboda ya cire inda cutar kansa take a jikin marar lafiya don ya sami lafiya . Hakan ma Allah zai cire ko “ datse ” miyagu don nagargarun mutane su ji daɗin zama a duniya .\n",
            "2021-05-04 17:30:39,324 - INFO - joeynmt.training - \tHypothesis: Kamar yadda wani gefen zai iya cire wani abu mai kyau don ya ceci rayuwar haƙuri , Allah zai “ datse ” miyagu don mutane masu kirki su more rayuwa a duniya .\n",
            "2021-05-04 17:30:39,324 - INFO - joeynmt.training - Example #2\n",
            "2021-05-04 17:30:39,324 - INFO - joeynmt.training - \tSource:     They experience peace in their lives by applying Bible principles . ​ — Isaiah 48 : 18 .\n",
            "2021-05-04 17:30:39,324 - INFO - joeynmt.training - \tReference:  ( Romawa 12 : 18 ) Kuma za su sami kwanciyar hankali don suna bin ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:30:39,324 - INFO - joeynmt.training - \tHypothesis: Suna samun salama a rayuwarsu ta wajen yin amfani da ƙa’idodin Littafi Mai Tsarki . — Ishaya 48 : 18 .\n",
            "2021-05-04 17:30:39,324 - INFO - joeynmt.training - Example #3\n",
            "2021-05-04 17:30:39,324 - INFO - joeynmt.training - \tSource:     * By all means I shall have pity upon him . ”\n",
            "2021-05-04 17:30:39,325 - INFO - joeynmt.training - \tReference:  ( Aya ta 20 ) Jehobah yana begen sake ganin yaransa .\n",
            "2021-05-04 17:30:39,325 - INFO - joeynmt.training - \tHypothesis: * A cikin dukan al’amuran da zan yi masa . ”\n",
            "2021-05-04 17:30:39,325 - INFO - joeynmt.training - Validation result (greedy) at epoch  30, step    74000: bleu:  30.23, loss: 36056.3242, ppl:   4.1914, duration: 11.6256s\n",
            "2021-05-04 17:30:49,205 - INFO - joeynmt.training - Epoch  30, Step:    74100, Batch Loss:     1.423258, Tokens per Sec:    21605, Lr: 0.000300\n",
            "2021-05-04 17:30:59,138 - INFO - joeynmt.training - Epoch  30, Step:    74200, Batch Loss:     1.627774, Tokens per Sec:    22359, Lr: 0.000300\n",
            "2021-05-04 17:31:08,971 - INFO - joeynmt.training - Epoch  30, Step:    74300, Batch Loss:     1.594593, Tokens per Sec:    22023, Lr: 0.000300\n",
            "2021-05-04 17:31:18,805 - INFO - joeynmt.training - Epoch  30, Step:    74400, Batch Loss:     1.173608, Tokens per Sec:    21588, Lr: 0.000300\n",
            "2021-05-04 17:31:28,687 - INFO - joeynmt.training - Epoch  30, Step:    74500, Batch Loss:     1.636855, Tokens per Sec:    22042, Lr: 0.000300\n",
            "2021-05-04 17:31:38,511 - INFO - joeynmt.training - Epoch  30, Step:    74600, Batch Loss:     1.542871, Tokens per Sec:    21982, Lr: 0.000300\n",
            "2021-05-04 17:31:48,473 - INFO - joeynmt.training - Epoch  30, Step:    74700, Batch Loss:     1.853380, Tokens per Sec:    21831, Lr: 0.000300\n",
            "2021-05-04 17:31:58,344 - INFO - joeynmt.training - Epoch  30, Step:    74800, Batch Loss:     1.805484, Tokens per Sec:    21663, Lr: 0.000300\n",
            "2021-05-04 17:32:08,227 - INFO - joeynmt.training - Epoch  30, Step:    74900, Batch Loss:     1.446367, Tokens per Sec:    22029, Lr: 0.000300\n",
            "2021-05-04 17:32:10,057 - INFO - joeynmt.training - Epoch  30: total training loss 3947.10\n",
            "2021-05-04 17:32:10,057 - INFO - joeynmt.training - Training ended after  30 epochs.\n",
            "2021-05-04 17:32:10,057 - INFO - joeynmt.training - Best validation result (greedy) at step    72000:   4.18 ppl.\n",
            "2021-05-04 17:32:10,074 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 1, batch_size per device: 18000 (with beam_size)\n",
            "2021-05-04 17:32:10,224 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
            "2021-05-04 17:32:10,410 - INFO - joeynmt.model - Enc-dec model built.\n",
            "2021-05-04 17:32:10,470 - INFO - joeynmt.prediction - Decoding on dev set (data/enha/dev.bpe.ha)...\n",
            "2021-05-04 17:32:24,642 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:32:24,642 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:32:24,642 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:32:24,894 - INFO - joeynmt.prediction -  dev bleu[13a]:  30.54 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2021-05-04 17:32:24,895 - INFO - joeynmt.prediction - Translations saved to: models/enha_transformer/00072000.hyps.dev\n",
            "2021-05-04 17:32:24,895 - INFO - joeynmt.prediction - Decoding on test set (data/enha/test.bpe.ha)...\n",
            "2021-05-04 17:33:04,131 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 17:33:04,131 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 17:33:04,132 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 17:33:04,979 - INFO - joeynmt.prediction - test bleu[13a]:  32.70 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2021-05-04 17:33:04,981 - INFO - joeynmt.prediction - Translations saved to: models/enha_transformer/00072000.hyps.test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "MBoDS09JM807"
      },
      "source": [
        "# Copy the created models from the notebook storage to google drive for persistant storage \n",
        "!cp -r joeynmt/models/${src}${tgt}_transformer/* \"$gdrive_path/models/${src}${tgt}_transformer/\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "n94wlrCjVc17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d1272f-2266-41ad-9775-9dc89a1f1be5"
      },
      "source": [
        "# Output our validation accuracy\n",
        "! cat \"$gdrive_path/models/${src}${tgt}_transformer/validations.txt\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps: 1000\tLoss: 95550.13281\tPPL: 44.59177\tbleu: 1.29115\tLR: 0.00030000\t*\n",
            "Steps: 2000\tLoss: 81565.06250\tPPL: 25.57783\tbleu: 3.43028\tLR: 0.00030000\t*\n",
            "Steps: 3000\tLoss: 73370.53906\tPPL: 18.46805\tbleu: 6.78752\tLR: 0.00030000\t*\n",
            "Steps: 4000\tLoss: 68123.66406\tPPL: 14.99190\tbleu: 8.88514\tLR: 0.00030000\t*\n",
            "Steps: 5000\tLoss: 63590.62500\tPPL: 12.52027\tbleu: 11.90724\tLR: 0.00030000\t*\n",
            "Steps: 6000\tLoss: 60572.60938\tPPL: 11.10506\tbleu: 14.53174\tLR: 0.00030000\t*\n",
            "Steps: 7000\tLoss: 58054.21094\tPPL: 10.04736\tbleu: 15.90478\tLR: 0.00030000\t*\n",
            "Steps: 8000\tLoss: 56168.58594\tPPL: 9.32191\tbleu: 17.44216\tLR: 0.00030000\t*\n",
            "Steps: 9000\tLoss: 54043.51562\tPPL: 8.56692\tbleu: 18.71990\tLR: 0.00030000\t*\n",
            "Steps: 10000\tLoss: 52418.21094\tPPL: 8.03102\tbleu: 19.22068\tLR: 0.00030000\t*\n",
            "Steps: 11000\tLoss: 51041.77344\tPPL: 7.60348\tbleu: 20.11009\tLR: 0.00030000\t*\n",
            "Steps: 12000\tLoss: 50055.09375\tPPL: 7.31109\tbleu: 20.57364\tLR: 0.00030000\t*\n",
            "Steps: 13000\tLoss: 49093.66406\tPPL: 7.03699\tbleu: 21.58137\tLR: 0.00030000\t*\n",
            "Steps: 14000\tLoss: 48136.87500\tPPL: 6.77442\tbleu: 21.96381\tLR: 0.00030000\t*\n",
            "Steps: 15000\tLoss: 47430.95703\tPPL: 6.58700\tbleu: 22.21264\tLR: 0.00030000\t*\n",
            "Steps: 16000\tLoss: 46602.22266\tPPL: 6.37358\tbleu: 22.54269\tLR: 0.00030000\t*\n",
            "Steps: 17000\tLoss: 46469.92969\tPPL: 6.34015\tbleu: 22.74094\tLR: 0.00030000\t*\n",
            "Steps: 18000\tLoss: 45306.69531\tPPL: 6.05371\tbleu: 23.50918\tLR: 0.00030000\t*\n",
            "Steps: 19000\tLoss: 44839.25000\tPPL: 5.94228\tbleu: 23.94091\tLR: 0.00030000\t*\n",
            "Steps: 20000\tLoss: 44355.12109\tPPL: 5.82904\tbleu: 24.49772\tLR: 0.00030000\t*\n",
            "Steps: 21000\tLoss: 43949.36328\tPPL: 5.73579\tbleu: 24.33514\tLR: 0.00030000\t*\n",
            "Steps: 22000\tLoss: 43371.02344\tPPL: 5.60545\tbleu: 24.98322\tLR: 0.00030000\t*\n",
            "Steps: 23000\tLoss: 43022.92188\tPPL: 5.52844\tbleu: 25.19967\tLR: 0.00030000\t*\n",
            "Steps: 24000\tLoss: 42573.86328\tPPL: 5.43064\tbleu: 25.19743\tLR: 0.00030000\t*\n",
            "Steps: 25000\tLoss: 42334.55469\tPPL: 5.37924\tbleu: 25.93680\tLR: 0.00030000\t*\n",
            "Steps: 26000\tLoss: 42125.46875\tPPL: 5.33472\tbleu: 26.31201\tLR: 0.00030000\t*\n",
            "Steps: 27000\tLoss: 41617.22266\tPPL: 5.22804\tbleu: 26.00845\tLR: 0.00030000\t*\n",
            "Steps: 28000\tLoss: 41695.34766\tPPL: 5.24430\tbleu: 26.30463\tLR: 0.00030000\t\n",
            "Steps: 29000\tLoss: 41050.95312\tPPL: 5.11170\tbleu: 26.48096\tLR: 0.00030000\t*\n",
            "Steps: 30000\tLoss: 40887.82031\tPPL: 5.07866\tbleu: 26.89604\tLR: 0.00030000\t*\n",
            "Steps: 31000\tLoss: 40622.03516\tPPL: 5.02530\tbleu: 26.70297\tLR: 0.00030000\t*\n",
            "Steps: 32000\tLoss: 40448.99219\tPPL: 4.99085\tbleu: 27.56324\tLR: 0.00030000\t*\n",
            "Steps: 33000\tLoss: 40200.33203\tPPL: 4.94177\tbleu: 27.06999\tLR: 0.00030000\t*\n",
            "Steps: 34000\tLoss: 39970.65625\tPPL: 4.89687\tbleu: 27.94992\tLR: 0.00030000\t*\n",
            "Steps: 35000\tLoss: 39745.06250\tPPL: 4.85316\tbleu: 27.56661\tLR: 0.00030000\t*\n",
            "Steps: 36000\tLoss: 39569.23047\tPPL: 4.81936\tbleu: 27.52320\tLR: 0.00030000\t*\n",
            "Steps: 37000\tLoss: 39473.62891\tPPL: 4.80108\tbleu: 28.09019\tLR: 0.00030000\t*\n",
            "Steps: 38000\tLoss: 39278.50000\tPPL: 4.76400\tbleu: 27.91210\tLR: 0.00030000\t*\n",
            "Steps: 39000\tLoss: 39304.05469\tPPL: 4.76884\tbleu: 27.57410\tLR: 0.00030000\t\n",
            "Steps: 40000\tLoss: 39027.38672\tPPL: 4.71669\tbleu: 27.95143\tLR: 0.00030000\t*\n",
            "Steps: 41000\tLoss: 38848.75391\tPPL: 4.68332\tbleu: 27.82282\tLR: 0.00030000\t*\n",
            "Steps: 42000\tLoss: 38672.86719\tPPL: 4.65069\tbleu: 28.78486\tLR: 0.00030000\t*\n",
            "Steps: 43000\tLoss: 38422.97266\tPPL: 4.60473\tbleu: 28.56770\tLR: 0.00030000\t*\n",
            "Steps: 44000\tLoss: 38500.82422\tPPL: 4.61900\tbleu: 28.70477\tLR: 0.00030000\t\n",
            "Steps: 45000\tLoss: 38346.74219\tPPL: 4.59080\tbleu: 29.17640\tLR: 0.00030000\t*\n",
            "Steps: 46000\tLoss: 38067.64453\tPPL: 4.54016\tbleu: 28.85629\tLR: 0.00030000\t*\n",
            "Steps: 47000\tLoss: 37988.30859\tPPL: 4.52587\tbleu: 29.08602\tLR: 0.00030000\t*\n",
            "Steps: 48000\tLoss: 38027.14453\tPPL: 4.53286\tbleu: 28.74302\tLR: 0.00030000\t\n",
            "Steps: 49000\tLoss: 37871.12891\tPPL: 4.50484\tbleu: 28.73656\tLR: 0.00030000\t*\n",
            "Steps: 50000\tLoss: 37629.83203\tPPL: 4.46184\tbleu: 28.86258\tLR: 0.00030000\t*\n",
            "Steps: 51000\tLoss: 37514.89062\tPPL: 4.44151\tbleu: 29.05625\tLR: 0.00030000\t*\n",
            "Steps: 52000\tLoss: 37348.40625\tPPL: 4.41222\tbleu: 29.18480\tLR: 0.00030000\t*\n",
            "Steps: 53000\tLoss: 37350.78906\tPPL: 4.41263\tbleu: 28.84880\tLR: 0.00030000\t\n",
            "Steps: 54000\tLoss: 37320.19922\tPPL: 4.40727\tbleu: 29.03014\tLR: 0.00030000\t*\n",
            "Steps: 55000\tLoss: 37230.07812\tPPL: 4.39151\tbleu: 29.56809\tLR: 0.00030000\t*\n",
            "Steps: 56000\tLoss: 37218.14844\tPPL: 4.38943\tbleu: 29.27412\tLR: 0.00030000\t*\n",
            "Steps: 57000\tLoss: 37015.50000\tPPL: 4.35422\tbleu: 29.60024\tLR: 0.00030000\t*\n",
            "Steps: 58000\tLoss: 37019.10938\tPPL: 4.35485\tbleu: 29.28241\tLR: 0.00030000\t\n",
            "Steps: 59000\tLoss: 36932.19922\tPPL: 4.33983\tbleu: 29.53980\tLR: 0.00030000\t*\n",
            "Steps: 60000\tLoss: 36858.80078\tPPL: 4.32719\tbleu: 29.33599\tLR: 0.00030000\t*\n",
            "Steps: 61000\tLoss: 36870.94922\tPPL: 4.32928\tbleu: 29.63921\tLR: 0.00030000\t\n",
            "Steps: 62000\tLoss: 36691.81641\tPPL: 4.29857\tbleu: 29.18495\tLR: 0.00030000\t*\n",
            "Steps: 63000\tLoss: 36568.46875\tPPL: 4.27754\tbleu: 29.30402\tLR: 0.00030000\t*\n",
            "Steps: 64000\tLoss: 36545.16016\tPPL: 4.27358\tbleu: 29.76269\tLR: 0.00030000\t*\n",
            "Steps: 65000\tLoss: 36580.77734\tPPL: 4.27964\tbleu: 29.75250\tLR: 0.00030000\t\n",
            "Steps: 66000\tLoss: 36373.31641\tPPL: 4.24450\tbleu: 30.09699\tLR: 0.00030000\t*\n",
            "Steps: 67000\tLoss: 36227.01172\tPPL: 4.21989\tbleu: 29.99734\tLR: 0.00030000\t*\n",
            "Steps: 68000\tLoss: 36437.51562\tPPL: 4.25534\tbleu: 30.19281\tLR: 0.00030000\t\n",
            "Steps: 69000\tLoss: 36196.97656\tPPL: 4.21485\tbleu: 30.23266\tLR: 0.00030000\t*\n",
            "Steps: 70000\tLoss: 36142.81641\tPPL: 4.20579\tbleu: 29.99759\tLR: 0.00030000\t*\n",
            "Steps: 71000\tLoss: 36166.72656\tPPL: 4.20979\tbleu: 29.85724\tLR: 0.00030000\t\n",
            "Steps: 72000\tLoss: 35990.47266\tPPL: 4.18040\tbleu: 30.05275\tLR: 0.00030000\t*\n",
            "Steps: 73000\tLoss: 36419.91406\tPPL: 4.25236\tbleu: 30.29009\tLR: 0.00030000\t\n",
            "Steps: 74000\tLoss: 36056.32422\tPPL: 4.19136\tbleu: 30.22904\tLR: 0.00030000\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "66WhRE9lIhoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a015bf99-f890-48f4-8ed5-9389a4bc3677"
      },
      "source": [
        "# Test our model\n",
        "! cd joeynmt; python3 -m joeynmt test \"$gdrive_path/models/${src}${tgt}_transformer/config.yaml\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-04 18:02:41,869 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n",
            "2021-05-04 18:02:41,870 - INFO - joeynmt.data - Building vocabulary...\n",
            "2021-05-04 18:02:42,137 - INFO - joeynmt.data - Loading dev data...\n",
            "2021-05-04 18:02:42,147 - INFO - joeynmt.data - Loading test data...\n",
            "2021-05-04 18:02:42,173 - INFO - joeynmt.data - Data loaded.\n",
            "2021-05-04 18:02:42,202 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 1, batch_size per device: 18000 (with beam_size)\n",
            "2021-05-04 18:02:44,679 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
            "2021-05-04 18:02:44,901 - INFO - joeynmt.model - Enc-dec model built.\n",
            "2021-05-04 18:02:44,969 - INFO - joeynmt.prediction - Decoding on dev set (data/enha/dev.bpe.ha)...\n",
            "2021-05-04 18:02:59,109 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 18:02:59,109 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 18:02:59,110 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 18:02:59,352 - INFO - joeynmt.prediction -  dev bleu[13a]:  30.77 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2021-05-04 18:02:59,352 - INFO - joeynmt.prediction - Decoding on test set (data/enha/test.bpe.ha)...\n",
            "2021-05-04 18:03:38,386 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
            "2021-05-04 18:03:38,387 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "2021-05-04 18:03:38,387 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
            "2021-05-04 18:03:39,232 - INFO - joeynmt.prediction - test bleu[13a]:  32.31 [Beam search decoding with beam size = 5 and alpha = 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVhvWJIWkopk"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "This marks the end of my task - training an english to hausa language baseline model, using joeynmt.\n",
        "\n",
        "Training completed: Tuesday, May 4, 2021\n",
        "\n",
        "Training duration: 2 hours 21 minutes on GPU for 30 epochs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lstnoMPcoywo"
      },
      "source": [
        "# Acknowledgements\n",
        "\n",
        "Thank you, Colin Leong, for guiding this task.\n",
        "\n",
        "Thank you joeynmt team for joeynmt\n",
        "\n",
        "Thank you Masakhane github team for the starter notebook.\n",
        "\n",
        "\n",
        "**Author**: Tunde Ajayi"
      ]
    }
  ]
}